I"<!-- more -->
<p>研究表明，对于一些基分类器来说，与不均衡的数据集相比一个均衡的数据集可以提高全局的分类性能。数据层面的处理方法是处理不均衡数据分类问题的重要途径之一，它的实现方法主要分为对多数类样本的欠抽样和对少数类样本的过抽样学习两种。其主要思想是通过合理的删减或者增加一些样本来实现数据均衡的目的，进而降低数据不均衡给分类器带来的负面影响。
按照对样本数量的影响又可分为：
过抽样，即合理地增加少数类的样本
欠抽样，即合理地删减多数类样本
随机过抽样和欠抽样
随机过抽样
随机过抽样是一种按照下面的描述从少数类中速记抽样生成子集合 E 的方法。
首先在少数类 Smin 集合中随机选中一些少数类样本
然后通过复制所选样本生成样本集合 E
将它们添加到 Smin 中来扩大原始数据集从而得到新的少数类集合 Smin−new
用这样方法，Smin 中的总样本数增加了 |E| 个新样本，且 Smin−new 的类分布均衡度进行相应的调整，如此操作可以改变类分布平衡度从而达到所需水平。
欠抽样
欠抽样技术是将数据从原始数据集中移除。
首先我们从 Smaj 中随机地选取一些多数类样本 E
将这些样本从 Smaj 中移除，就有 |Smaj−new|=|Smaj|−|E|
缺陷
初看，过抽样和欠抽样技术在功能上似乎是等价的，因为它们都能改变原始数据集的样本容量且能够获得一个相同比例的平衡。
但是，这个共同点只是表面现象，这是因为这两种方法都将会产生不同的降低分类器学习能力的负面效果。
对于欠抽样算法，将多数类样本删除有可能会导致分类器丢失有关多数类的重要信息。
对于过抽样算法，虽然只是简单地将复制后的数据添加到原始数据集中，且某些样本的多个实例都是“并列的”，但这样也可能会导致分类器学习出现过拟合现象，对于同一个样本的多个复本产生多个规则条例，这就使得规则过于具体化；虽然在这种情况下，分类器的训练精度会很高，但在位置样本的分类性能就会非常不理想。
informed 欠抽样
两个 informed 欠抽样算法：EasyEnsemble 和 BalanceCascade 算法，这两种方法克服了传统随机欠抽样方法导致的信息缺失的问题，且表现出较好的不均衡数据分类性能。
EasyEnsemble 和 BalanceCascade 算法介绍</p>
<ol>
  <li>EasyEnsemble 核心思想是：
首先通过从多数类中独立随机抽取出若干子集
将每个子集与少数类数据联合起来训练生成多个基分类器
最终将这些基分类器组合形成一个集成学习系统
EasyEnsemble 算法被认为是非监督学习算法，因此它每次都独立利用可放回随机抽样机制来提取多数类样本</li>
  <li>BalanceCascade 核心思想是：
使用之前已形成的集成分类器来为下一次训练选择多类样本
然后再进行欠抽样
最近邻规则（ENN）
因为随机欠抽样方法未考虑样本的分布情况，采样具有很大的随机性，可能会删除重要的多数类样本信息。针对以上的不足，Wilson 等人提出了一种最近邻规则(edited nearest neighbor: ENN)。
基本思想：删除那些类别与其最近的三个近邻样本中的两个或两个以上的样本类别不同的样本
缺点：因为大多数的多数类样本的样本附近都是多数类，所以该方法所能删除的多数类样本十分有限。
领域清理规则 (NCL)
Laur Ikkala J 等人在 ENN 的基础行提出了 领域清理规则 (neighborhod cleaning rule: NCL)。该算法的整体流程图如下所示：</li>
</ol>
:ET