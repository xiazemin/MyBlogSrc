I"T	<p>Kafka中的每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序号，用于partition唯一标识一条消息。</p>

<p>Offset记录着下一条将要发送给Consumer的消息的序号。</p>

<p>Offset从语义上来看拥有两种：Current Offset和Committed Offset。</p>

<p>Current Offset
Current Offset保存在Consumer客户端中，它表示Consumer希望收到的下一条消息的序号。它仅仅在poll()方法中使用。例如，Consumer第一次调用poll()方法后收到了20条消息，那么Current Offset就被设置为20。这样Consumer下一次调用poll()方法时，Kafka就知道应该从序号为21的消息开始读取。这样就能够保证每次Consumer poll消息时，都能够收到不重复的消息。</p>

<p>Committed Offset
Committed Offset保存在Broker上，它表示Consumer已经确认消费过的消息的序号</p>

<p>Kafka保存offset时并不直接为每个消费者保存，而是以groupid-topic-partition -&gt; offset的方式保存。</p>

<p>每个消息都带着本消息的offset，提交消息的时候只认最新的消息，不必每个消息都提交
https://www.jianshu.com/p/449074d97daf
https://juejin.cn/post/6844904016212656141
<!-- more -->
https://cloud.tencent.com/developer/article/1496273</p>

<p>We don’t roll back offset at this moment. Since the offset is a long, it can last for a really long time. If you write 1TB a day, you can keep going for about 4 million days.
Plus, you can always use more partitions (each partition has its own offset).</p>

<p>https://blog.csdn.net/sinat_42483341/article/details/113784208</p>

<p>Consumer 端有个参数叫 enable.auto.commit，如果值是 true，则 Consumer 在后台默默地为你定期提交位移，提交间隔由一个专属的参数 auto.commit.interval.ms来控制
它实际保证的是位移至少要隔一段时间才会提交，如果你是单线程处理消息，那么只有处理完消息后才会提交位移，可能远比你设置的间隔长，因为你的处理逻辑可能需要一定的时间</p>

<p>auto.commit.offset //重新分区或者退出的时候提交offset，一般设置成默认值true 
auto.store.offset //自动保存本地offset，pool的时候惰性提交
https://juejin.cn/post/6938234746837139463</p>
:ET