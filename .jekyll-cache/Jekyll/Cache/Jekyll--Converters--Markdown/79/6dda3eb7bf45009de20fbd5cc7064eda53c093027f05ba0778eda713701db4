I"$“<p>K8S åº•å±‚ç½‘ç»œæ‰€éœ€è¦è§£å†³çš„ä¸¤ä¸ªé—®é¢˜</p>

<p>ååŠ© k8s , ç»™æ¯ä¸ª NODEä¸Šçš„ docker å®¹å™¨éƒ½åˆ†é…äº’ç›¸ä¸å†²çªçš„ IP
åœ¨è¿™äº› IP åœ°å€ä¹‹é—´å»ºç«‹ä¸€ä¸ªè¦†ç›–ç½‘ç»œ(overlay Network), é€šè¿‡è¿™ä¸ªè¦†ç›–ç½‘ç»œ, å°†æ•°æ®åŒ…åŸå°ä¸åŠ¨åœ°ä¼ é€’åˆ°ç›®æ ‡å®¹å™¨å†….
<!-- more -->
Open vSwitch
Open vSwitch å¯ä»¥å»ºç«‹å¤šé’Ÿé€šä¿¡éš§é“, ä¾‹å¦‚Open vswitch with GRE/VXALN. åœ¨K8S åœºæ™¯ä¸‹, æˆ‘ä»¬ä¸»è¦å»ºç«‹ L3 åˆ° L3 çš„éš§é“.</p>

<p>éœ€è¦å®Œæˆçš„æ­¥éª¤å¦‚ä¸‹:</p>

<p>åˆ é™¤docker daemon åˆ›å»ºçš„ç½‘æ¡¥ docker0 å·²é¿å… docker0åœ°å€å†²çª.</p>

<p>æ‰‹å·¥åˆ›å»ºä¸€ä¸ªlinuxç½‘æ¡¥, æ‰‹åŠ¨é…ç½®ç½‘æ¡¥çš„ IP</p>

<p>å»ºç«‹ Open vswitch ç½‘æ¡¥ ovs-bridge, ä½¿ç”¨ ovs-vsctl ç»™ovs-bridge æ·»åŠ greç«¯å£, åœ¨æ·»åŠ ç«¯å£æ˜¯, éœ€è¦å°†ç›®æ ‡ NODE çš„ IP åœ°å€è®¾ç½®ä¸ºå¯¹ç«¯ IP åœ°å€. æ¯ä¸ªå¯¹ç«¯ IP åœ°å€éƒ½éœ€è¦è¿™ä¹ˆæ“ä½œ.</p>

<p>å°† ovs-bridge ä½œä¸ºç½‘ç»œæ¥å£, åŠ å…¥docker çš„ç½‘æ¡¥ä¸Š(docker0 æˆ–è‡ªå·±æ‰‹å·¥åˆ›å»ºçš„ç½‘æ¡¥)</p>

<p>é‡å¯ ovs-bridge ç½‘æ¡¥ å’Œ docker çš„ç½‘æ¡¥, å¹¶æ·»åŠ ä¸€ä¸ªdocker çš„ç½‘æ®µåˆ°docker ç½‘æ¡¥çš„è·¯ç”±è§„åˆ™ä¸­</p>

<p>ç½‘ç»œé€šä¿¡è¿‡ç¨‹
å½“å®¹å™¨å†…çš„åº”ç”¨è®¿é—®å¦ä¸€ä¸ªå®¹å™¨åœ°å€æ—¶, æ•°æ®åŒ…ä¼šé€šè¿‡å®¹å™¨å†…çš„é»˜è®¤è·¯ç”±å‘é€ç»™docker0ç½‘æ¡¥, ovsçš„ç½‘æ¡¥æ˜¯ä½œä¸ºdocker0 ç½‘æ¡¥çš„ç«¯å£å­˜åœ¨çš„, å®ƒä¼šå°†æ•°æ®å‘é€ç»™ovs ç½‘æ¡¥, ovs é€šè¿‡greéš§é“ é€è¾¾å¯¹ç«¯çš„node.
é…ç½®æ­¥éª¤
åœ¨ä¸¤ä¸ªèŠ‚ç‚¹éƒ½å®‰è£…ovs
å®‰è£…ovs
yum install openvswitch
å¤åˆ¶ä»£ç ç¦ç”¨selinux å¹¶é‡å¯
#vi /etc/selinux/conifg
SELINUX=disabled
å¤åˆ¶ä»£ç æŸ¥çœ‹ovsçŠ¶æ€
systemctl status openvswtich
å¤åˆ¶ä»£ç åˆ›å»ºç½‘æ¡¥å’Œ gre éš§é“
åœ¨æ¯ä¸ªnodeä¸Šåˆ›å»ºovs ç½‘æ¡¥ br0 ç„¶ååœ¨ç½‘æ¡¥ä¸Šåˆ›å»º gre éš§é“
#åˆ›å»ºovsç½‘æ¡¥
ovs-vsctl add-br br0</p>
<h1 id="åˆ›å»º-gre-éš§é“è¿æ¥å¯¹ç«¯-remote_ip-ä¸ºå¯¹ç«¯-eth0-çš„-ip-æ³¨æ„åœ¨å¦ä¸€å°æœºå™¨ä¸Šè®¾ç½®å¯¹ç«¯çš„æ—¶å€™ip-è¦æ”¹ä¸ºå½“å‰è¿™å°æœºå™¨çš„-ip">åˆ›å»º GRE éš§é“è¿æ¥å¯¹ç«¯, remote_ip ä¸ºå¯¹ç«¯ eth0 çš„ IP, æ³¨æ„åœ¨å¦ä¸€å°æœºå™¨ä¸Šè®¾ç½®å¯¹ç«¯çš„æ—¶å€™,IP è¦æ”¹ä¸ºå½“å‰è¿™å°æœºå™¨çš„ IP</h1>
<p>ovs-vsctl add-port br0 gre1 â€“ set interface gre1 type gre option:remote_ip=192.168.18.128</p>
<h1 id="æ·»åŠ br0-åˆ°æœ¬åœ°-docker0-ç½‘æ¡¥-ä½¿å¾—å®¹å™¨æµé‡é€šè¿‡-ovs-è¿›å…¥-tunnel">æ·»åŠ br0 åˆ°æœ¬åœ° docker0 ç½‘æ¡¥, ä½¿å¾—å®¹å™¨æµé‡é€šè¿‡ ovs è¿›å…¥ tunnel</h1>
<p>brctl addif docker0 br0
#å¯åŠ¨br0 docker0 ç½‘æ¡¥
ip link set dev br0 up
ip link set dev docker0 up
å¤åˆ¶ä»£ç ç”±äº128, 131 ipçš„ä¸¤å°æœºå™¨docker0 ç½‘æ®µåˆ†åˆ«æ˜¯172.17.43.0/24, 172.17.42.0/24, è¿™ä¸¤ä¸ªç½‘æ®µçš„è·¯ç”±éƒ½éœ€è¦ç»è¿‡æœ¬æœºdocker0ç½‘æ¡¥.å…¶ä¸­ä¸€ä¸ª24ç½‘æ®µé€šè¿‡ovsçš„gre éš§é“åˆ°è¾¾å¯¹ç«¯. å› æ­¤éœ€è¦åœ¨æ¯ä¸ªnodeä¸Šé…ç½®é€šè¿‡docker0 ç½‘æ¡¥çš„è·¯ç”±è§„åˆ™
ip route add 172.17.0.0/16 dev docker0
å¤åˆ¶ä»£ç æ¸…ç©º docker è‡ªå¸¦çš„iptables è§„åˆ™åŠlinux çš„è§„åˆ™, åè€…å­˜åœ¨æ‹’ç»ICMP ä¿æ¸©é€šè¿‡é˜²ç«å¢™çš„è§„åˆ™
iptables -t nat -F; iptalbes -F
å¤åˆ¶ä»£ç ç›´æ¥è·¯ç”±
ç½‘ç»œæ¨¡å‹
åœ¨é»˜è®¤æƒ…å†µä¸‹docker0 çš„IP åœ¨node ç½‘ç»œæ˜¯æ²¡æ³•æ„ŸçŸ¥åˆ°çš„, é€šè¿‡æ‰‹å·¥è®¾ç½®è·¯ç”±, å¯ä»¥è®©pod åœ¨ä¸åŒnode ä¹‹é—´äº’é€š.
å®ç°æ–¹å¼
é€šè¿‡éƒ¨ç½²multilayer switch (MLS) æ¥å®ç°
å‡è®¾ POD1 æ‰€åœ¨çš„ docker0 ç½‘æ¡¥çš„ IP ç½‘æ®µæ˜¯ 10.1.10.0 , NODE1 åœ°å€ä¸º 192. 168.1.128; è€Œ POD2 æ‰€åœ¨ docker0 ip ç½‘æ®µä¸º 10.1.20.0 NODE2 åœ°å€ä¸º 192.168.1.129
1 åœ¨NODE 1 ä¸Šæ·»åŠ ä¸€æ¡åˆ°node2 ä¸Š docker0 çš„é™æ€è·¯ç”±è§„åˆ™
route add -net 10.1.20.0 netmask 255.255.255.0 gw 192.168.1.129
å¤åˆ¶ä»£ç 2 åœ¨ NODE 2 ä¸Šæ·»åŠ ä¸€æ¡åˆ° NODE 1 ä¸Š docker0 çš„é™æ€è·¯ç”±è§„åˆ™
route add -net 10.1.10.0 netmask 255.255.255.0 gw 192.168.1.128
å¤åˆ¶ä»£ç 3 éªŒè¯è¿é€šæ€§, åœ¨ NODE1 ä¸Š ping node2 ä¸Šçš„ docker0 ç½‘ç»œ
ping 10.1.20.1
å¤åˆ¶ä»£ç å¤§è§„æ¨¡é›†ç¾¤ä¸‹çš„å®ç°æ–¹å¼, æ‰‹å·¥å»ºç«‹ linux bridge å·²é¿å… docker daemon å»ºç«‹docker0 é€ æˆ IP æ®µå†²çª, ç„¶åä½¿ç”¨docker çš„â€“bridge å‘½ä»¤æ¥æŒ‡å®šç½‘æ¡¥.
ç„¶ååœ¨æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œquagga è·¯ç”±å­¦ä¹ è½¯ä»¶.
calico
Calico å·¥ä½œæ–¹å¼
Calicoå¯ä»¥åˆ›å»ºå¹¶ç®¡ç†ä¸€ä¸ª3å±‚å¹³é¢ç½‘ç»œï¼Œä¸ºæ¯ä¸ªå·¥ä½œè´Ÿè½½åˆ†é…ä¸€ä¸ªå®Œå…¨å¯è·¯ç”±çš„IPåœ°å€ã€‚ å·¥ä½œè´Ÿè½½å¯ä»¥åœ¨æ²¡æœ‰IPå°è£…æˆ–ç½‘ç»œåœ°å€è½¬æ¢çš„æƒ…å†µä¸‹è¿›è¡Œé€šä¿¡ï¼Œä»¥å®ç°è£¸æœºæ€§èƒ½ï¼Œç®€åŒ–æ•…éšœæ’é™¤å’Œæä¾›æ›´å¥½çš„äº’æ“ä½œæ€§ã€‚ åœ¨éœ€è¦ä½¿ç”¨overlayç½‘ç»œçš„ç¯å¢ƒä¸­ï¼ŒCalicoæä¾›äº†IP-in-IPéš§é“æŠ€æœ¯ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥ä¸flannelç­‰å…¶ä»–overlayç½‘ç»œé…åˆä½¿ç”¨ã€‚
Calicoè¿˜æä¾›ç½‘ç»œå®‰å…¨è§„åˆ™çš„åŠ¨æ€é…ç½®ã€‚ ä½¿ç”¨Calicoçš„ç®€å•ç­–ç•¥è¯­è¨€ï¼Œå°±å¯ä»¥å®ç°å¯¹å®¹å™¨ã€è™šæ‹Ÿæœºå·¥ä½œè´Ÿè½½å’Œè£¸æœºä¸»æœºå„èŠ‚ç‚¹ä¹‹é—´é€šä¿¡çš„ç»†ç²’åº¦æ§åˆ¶ã€‚
Calico v3.4äº2018.12.10å·å‘å¸ƒï¼Œå¯ä¸Kubernetesã€OpenShiftå’ŒOpenStackè‰¯å¥½åœ°é›†æˆä½¿ç”¨ã€‚</p>

<p>æ³¨æ„: åœ¨Mesos, DC/OSå’ŒDocker orchestratorsä¸­ä½¿ç”¨Calicoæ—¶ï¼Œç›®å‰åªæ”¯æŒåˆ°äº† Calico v2.6.</p>

<p>Calicoçš„IPIPä¸BGPæ¨¡å¼</p>

<p>IPIPæ˜¯ä¸€ç§å°†å„Nodeçš„è·¯ç”±ä¹‹é—´åšä¸€ä¸ªtunnelï¼Œå†æŠŠä¸¤ä¸ªç½‘ç»œè¿æ¥èµ·æ¥çš„æ¨¡å¼ã€‚å¯ç”¨IPIPæ¨¡å¼æ—¶ï¼ŒCalicoå°†åœ¨å„Nodeä¸Šåˆ›å»ºä¸€ä¸ªåä¸ºâ€tunl0â€³çš„è™šæ‹Ÿç½‘ç»œæ¥å£ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
BGPæ¨¡å¼åˆ™ç›´æ¥ä½¿ç”¨ç‰©ç†æœºä½œä¸ºè™šæ‹Ÿè·¯ç”±è·¯ï¼ˆvRouterï¼‰ï¼Œä¸å†åˆ›å»ºé¢å¤–çš„tunnel</p>

<p>calico  åœ¨linux å†…æ ¸ä¸­å®ç°ä¸€ä¸ªvRouteræ¥è´Ÿè´£æ•°æ®è½¬å‘, é€šè¿‡ BGP åè®®,å°†node èŠ‚ç‚¹ä¸Šçš„è·¯ç”±ä¿¡æ¯åœ¨æ•´ä¸ªcalico ç½‘ç»œä¸­å¹¿æ’­, å¹¶è‡ªåŠ¨è®¾ç½®åˆ°è¾¾å…¶ä»–èŠ‚ç‚¹çš„è·¯ç”±è½¬å‘è§„åˆ™.</p>

<p>Calico BGPæ¨¡å¼åœ¨å°è§„æ¨¡é›†ç¾¤ä¸­å¯ä»¥ç›´æ¥äº’è”ï¼Œåœ¨å¤§è§„æ¨¡é›†ç¾¤ä¸­å¯ä»¥é€šè¿‡é¢å¤–çš„BGP route reflectoræ¥å®Œæˆã€‚
Calicoä¸»è¦ç»„ä»¶
Calicoåˆ©ç”¨äº†Linuxå†…æ ¸åŸç”Ÿçš„è·¯ç”±å’Œiptablesé˜²ç«å¢™åŠŸèƒ½ã€‚ è¿›å‡ºå„ä¸ªå®¹å™¨ã€è™šæ‹Ÿæœºå’Œç‰©ç†ä¸»æœºçš„æ‰€æœ‰æµé‡éƒ½ä¼šåœ¨è·¯ç”±åˆ°ç›®æ ‡ä¹‹å‰éå†è¿™äº›å†…æ ¸è§„åˆ™ã€‚</p>

<p>Felixï¼šä¸»è¦çš„Calicoä»£ç†agentï¼Œè¿è¡Œæ¯å°è®¡ç®—æœºä¸Šç®¡ç†endpointsèµ„æºã€‚
calicoctlï¼šå…è®¸ä»å‘½ä»¤è¡Œç•Œé¢é…ç½®å®ç°é«˜çº§ç­–ç•¥å’Œç½‘ç»œã€‚
orchestrator pluginsï¼šæä¾›ä¸å„ç§æµè¡Œçš„äº‘è®¡ç®—ç¼–æ’å·¥å…·çš„ç´§å¯†é›†æˆå’ŒåŒæ­¥æ”¯æŒã€‚
key/value storeï¼šå­˜å‚¨Calicoçš„ç­–ç•¥é…ç½®å’Œç½‘ç»œçŠ¶æ€ä¿¡æ¯ï¼Œç›®å‰ä¸»è¦ä½¿ç”¨etcdv3æˆ–k8s apiã€‚
calico/nodeï¼šåœ¨æ¯ä¸ªä¸»æœºä¸Šè¿è¡Œï¼Œä»key/valueå­˜å‚¨ä¸­è¯»å–ç›¸å…³çš„ç­–ç•¥å’Œç½‘ç»œé…ç½®ä¿¡æ¯ï¼Œå¹¶åœ¨Linuxå†…æ ¸ä¸­å®ç°å®ƒã€‚
Dikastes/Envoyï¼šå¯é€‰çš„Kubernetes sidecarsï¼Œå¯ä»¥é€šè¿‡ç›¸äº’TLSèº«ä»½éªŒè¯ä¿æŠ¤å·¥ä½œè´Ÿè½½åˆ°å·¥ä½œè´Ÿè½½çš„é€šä¿¡ï¼Œå¹¶å¢åŠ åº”ç”¨å±‚æ§åˆ¶ç­–ç•¥ã€‚</p>

<p>Felix
Felixæ˜¯ä¸€ä¸ªå®ˆæŠ¤ç¨‹åºï¼Œå®ƒåœ¨æ¯ä¸ªæä¾›endpointsèµ„æºçš„è®¡ç®—æœºä¸Šè¿è¡Œã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™æ„å‘³ç€å®ƒéœ€è¦åœ¨æ‰˜ç®¡å®¹å™¨æˆ–VMçš„å®¿ä¸»æœºèŠ‚ç‚¹ä¸Šè¿è¡Œã€‚ Felix è´Ÿè´£ç¼–åˆ¶è·¯ç”±å’ŒACLè§„åˆ™ä»¥åŠåœ¨è¯¥ä¸»æœºä¸Šæ‰€éœ€çš„ä»»ä½•å…¶ä»–å†…å®¹ï¼Œä»¥ä¾¿ä¸ºè¯¥ä¸»æœºä¸Šçš„endpointsèµ„æºæ­£å¸¸è¿è¡Œæä¾›æ‰€éœ€çš„ç½‘ç»œè¿æ¥ã€‚
æ ¹æ®ç‰¹å®šçš„ç¼–æ’ç¯å¢ƒï¼ŒFelixè´Ÿè´£ä»¥ä¸‹ä»»åŠ¡ï¼š</p>

<p>ç®¡ç†ç½‘ç»œæ¥å£ï¼ŒFelixå°†æœ‰å…³æ¥å£çš„ä¸€äº›ä¿¡æ¯ç¼–ç¨‹åˆ°å†…æ ¸ä¸­ï¼Œä»¥ä½¿å†…æ ¸èƒ½å¤Ÿæ­£ç¡®å¤„ç†è¯¥endpointå‘å‡ºçš„æµé‡ã€‚ ç‰¹åˆ«æ˜¯ï¼Œå®ƒå°†ç¡®ä¿ä¸»æœºæ­£ç¡®å“åº”æ¥è‡ªæ¯ä¸ªå·¥ä½œè´Ÿè½½çš„ARPè¯·æ±‚ï¼Œå¹¶å°†ä¸ºå…¶ç®¡ç†çš„æ¥å£å¯ç”¨IPè½¬å‘æ”¯æŒã€‚å®ƒè¿˜ç›‘è§†ç½‘ç»œæ¥å£çš„å‡ºç°å’Œæ¶ˆå¤±ï¼Œä»¥ä¾¿ç¡®ä¿é’ˆå¯¹è¿™äº›æ¥å£çš„ç¼–ç¨‹å¾—åˆ°äº†æ­£ç¡®çš„åº”ç”¨ã€‚
ç¼–å†™è·¯ç”±ï¼ŒFelixè´Ÿè´£å°†åˆ°å…¶ä¸»æœºä¸Šendpointsçš„è·¯ç”±ç¼–å†™åˆ°Linuxå†…æ ¸FIBï¼ˆè½¬å‘ä¿¡æ¯åº“ï¼‰ä¸­ã€‚ è¿™å¯ä»¥ç¡®ä¿é‚£äº›å‘å¾€ç›®æ ‡ä¸»æœºçš„endpointsçš„æ•°æ®åŒ…è¢«æ­£ç¡®åœ°è½¬å‘ã€‚
ç¼–å†™ACLsï¼ŒFelixè¿˜è´Ÿè´£å°†ACLsç¼–ç¨‹åˆ°Linuxå†…æ ¸ä¸­ã€‚ è¿™äº›ACLsç”¨äºç¡®ä¿åªèƒ½åœ¨endpointsä¹‹é—´å‘é€æœ‰æ•ˆçš„ç½‘ç»œæµé‡ï¼Œå¹¶ç¡®ä¿endpointsæ— æ³•ç»•è¿‡Calicoçš„å®‰å…¨æªæ–½ã€‚
æŠ¥å‘ŠçŠ¶æ€ï¼ŒFelixè´Ÿè´£æä¾›æœ‰å…³ç½‘ç»œå¥åº·çŠ¶å†µçš„æ•°æ®ã€‚ ç‰¹åˆ«æ˜¯ï¼Œå®ƒå°†æŠ¥å‘Šé…ç½®å…¶ä¸»æœºæ—¶å‘ç”Ÿçš„é”™è¯¯å’Œé—®é¢˜ã€‚ è¯¥æ•°æ®ä¼šè¢«å†™å…¥etcdï¼Œä»¥ä½¿å…¶å¯¹ç½‘ç»œä¸­çš„å…¶ä»–ç»„ä»¶å’Œæ“ä½œæ‰å¯è§ã€‚</p>

<p>Orchestrator Plugin
æ¯ä¸ªä¸»è¦çš„äº‘ç¼–æ’å¹³å°éƒ½æœ‰å•ç‹¬çš„Calicoç½‘ç»œæ’ä»¶ï¼ˆä¾‹å¦‚OpenStackï¼ŒKubernetesï¼‰ã€‚ è¿™äº›æ’ä»¶çš„ç›®çš„æ˜¯å°†Calicoæ›´ç´§å¯†åœ°ç»‘å®šåˆ°ç¼–æ’å·¥å…·ä¸­ï¼Œå…è®¸ç”¨æˆ·ç®¡ç†Calicoç½‘ç»œï¼Œå°±åƒä»–ä»¬ç®¡ç†ç¼–æ’å·¥å…·ä¸­å†…ç½®çš„ç½‘ç»œå·¥å…·ä¸€æ ·ã€‚
ä¸€ä¸ªå¥½çš„Orchestratoræ’ä»¶ç¤ºä¾‹æ˜¯Calico Neutron ML2 é©±åŠ¨ç¨‹åºã€‚ è¯¥æ’ä»¶ä¸Neutronçš„ML2æ’ä»¶é›†æˆï¼Œå…è®¸ç”¨æˆ·é€šè¿‡Neutron APIè°ƒç”¨æ¥é…ç½®Calicoç½‘ç»œï¼Œå®ç°äº†ä¸Neutronçš„æ— ç¼é›†æˆã€‚
Orchestratoræ’ä»¶è´Ÿè´£ä»¥ä¸‹ä»»åŠ¡ï¼š</p>

<p>API Translationï¼Œæ¯ä¸ªäº‘ç¼–æ’å·¥å…·éƒ½ä¸å¯é¿å…åœ°æ‹¥æœ‰è‡ªå·±çš„ä¸€å¥—ç”¨äºç®¡ç†ç½‘ç»œçš„APIæ¥å£è§„èŒƒï¼Œ Orchestratoræ’ä»¶çš„ä¸»è¦å·¥ä½œå°±æ˜¯å°†è¿™äº›APIè½¬æ¢ä¸ºCalicoçš„æ•°æ®æ¨¡å‹ï¼Œç„¶åå°†å…¶å­˜å‚¨åœ¨Calicoçš„æ•°æ®å­˜å‚¨åŒºä¸­ã€‚è¿™ç§è½¬æ¢ä¸­çš„ä¸€äº›å·¥ä½œå°†éå¸¸ç®€å•ï¼Œå…¶ä»–ä¸€éƒ¨åˆ†å¯èƒ½æ›´å¤æ‚ï¼Œä»¥ä¾¿å°†å•ä¸ªå¤æ‚æ“ä½œï¼ˆä¾‹å¦‚ï¼Œå®æ—¶è¿ç§»ï¼‰è½¬æ¢ä¸ºCalicoç½‘ç»œæœŸæœ›çš„ä¸€ç³»åˆ—æ›´ç®€å•çš„æ“ä½œã€‚
Feedbackï¼Œå¦‚æœ‰éœ€è¦ï¼Œorchestratoræ’ä»¶å°†ä»Calicoç½‘ç»œå‘ç¼–æ’å™¨æä¾›ç®¡ç†å‘½ä»¤çš„åé¦ˆä¿¡æ¯ã€‚ åŒ…æ‹¬æä¾›æœ‰å…³Felixå­˜æ´»çš„ä¿¡æ¯ï¼Œä»¥åŠå¦‚æœç½‘ç»œé…ç½®å¤±è´¥åˆ™å°†æŸäº›endpointsæ ‡è®°ä¸ºå¤±è´¥ã€‚</p>

<p>etcd
etcdæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼é”®å€¼å­˜å‚¨æ•°æ®åº“ï¼Œä¸“æ³¨äºå®ç°æ•°æ®å­˜å‚¨ä¸€è‡´æ€§ã€‚ Calicoä½¿ç”¨etcdæä¾›ç»„ä»¶ä¹‹é—´çš„æ•°æ®é€šä¿¡ï¼Œå¹¶ä½œä¸ºå¯ä»¥ä¿è¯ä¸€è‡´æ€§çš„æ•°æ®å­˜å‚¨ï¼Œä»¥ç¡®ä¿Calicoå§‹ç»ˆå¯ä»¥æ„å»ºå‡ºä¸€ä¸ªå‡†ç¡®çš„ç½‘ç»œã€‚
æ ¹æ®orchestratoræ’ä»¶çš„ä¸åŒï¼Œetcdæ—¢å¯ä»¥æ˜¯ä½œä¸ºä¸»æ•°æ®å­˜å‚¨ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªå•ç‹¬æ•°æ®å­˜å‚¨çš„è½»é‡çº§é•œåƒã€‚ä¾‹å¦‚ï¼Œåœ¨OpenStackéƒ¨ç½²ä¸­ï¼ŒOpenStackæ•°æ®åº“è¢«è®¤ä¸ºæ˜¯â€œçœŸå®é…ç½®ä¿¡æ¯çš„æ¥æºâ€ï¼Œè€Œetcdç”¨äºé•œåƒå…¶ä¸­æœ‰å…³ç½‘ç»œé…ç½®çš„ä¿¡æ¯ï¼Œå¹¶ç”¨äºæœåŠ¡å…¶ä»–Calicoç»„ä»¶ã€‚
etcdç»„ä»¶ç©¿æ’åœ¨æ•´ä¸ªéƒ¨ç½²ä¸­ã€‚å®ƒå¯ä»¥è¢«åˆ†ä¸ºä¸¤ç»„ä¸»æœºèŠ‚ç‚¹ï¼šæ ¸å¿ƒé›†ç¾¤å’Œä»£ç†ã€‚
å¯¹äºå°å‹éƒ¨ç½²ï¼Œæ ¸å¿ƒé›†ç¾¤å¯ä»¥æ˜¯ä¸€ä¸ªèŠ‚ç‚¹çš„etcdé›†ç¾¤ï¼ˆé€šå¸¸ä¸orchestratoræ’ä»¶ç»„ä»¶ä½äºåŒä¸€èŠ‚ç‚¹ä¸Šï¼‰ã€‚è¿™ç§éƒ¨ç½²æ¨¡å‹å¾ˆç®€å•ä½†æ²¡æœ‰ä¸ºetcdæä¾›å†—ä½™ã€‚åœ¨etcdå¤±è´¥çš„æƒ…å†µä¸‹ï¼Œorchstratoræ’ä»¶å¿…é¡»é‡å»ºæ•°æ®åº“ï¼Œä¾‹å¦‚OpenStackï¼Œå®ƒéœ€è¦æ’ä»¶ä»OpenStackæ•°æ®åº“é‡æ–°åŒæ­¥çŠ¶æ€åˆ°etcdã€‚
åœ¨è¾ƒå¤§çš„éƒ¨ç½²ä¸­ï¼Œæ ¸å¿ƒç¾¤é›†å¯ä»¥æ ¹æ®etcdç®¡ç†æŒ‡å—è¿›è¡Œæ‰©å±•ã€‚
æ­¤å¤–ï¼Œåœ¨è¿è¡ŒFelixæˆ–orchstratoræ’ä»¶çš„æ¯å°è®¡ç®—æœºä¸Šï¼Œä¼šè¿è¡Œä¸€ä¸ªetcdä»£ç†æœåŠ¡ã€‚è¿™å‡å°‘äº†etcdæ ¸å¿ƒé›†ç¾¤ä¸Šçš„è´Ÿè½½ï¼Œå¹¶ä¸ºä¸»æœºèŠ‚ç‚¹å±è”½äº†etcdæœåŠ¡é›†ç¾¤çš„ç»†èŠ‚ã€‚åœ¨etcdé›†ç¾¤ä¸orchstratoræ’ä»¶åœ¨åŒä¸€å°æœºå™¨ä¸Šéƒ½æœ‰æˆå‘˜çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥æ”¾å¼ƒåœ¨è¯¥æœºå™¨ä¸Šä½¿ç”¨etcdä»£ç†ã€‚
etcdè´Ÿè´£æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š</p>

<p>Data Storageï¼Œetcdä»¥åˆ†å¸ƒå¼ã€ä¸€è‡´å’Œå®¹é”™çš„æ–¹å¼å­˜å‚¨Calicoç½‘ç»œçš„æ•°æ®ï¼ˆå¯¹äºè‡³å°‘ä¸‰ä¸ªetcdèŠ‚ç‚¹çš„clusterå¤§å°ï¼‰ã€‚ è¿™ç¡®ä¿Calicoç½‘ç»œå§‹ç»ˆå¤„äºå·²çŸ¥è‰¯å¥½çŠ¶æ€ï¼ŒåŒæ—¶å…è®¸è¿è¡Œetcdçš„ä¸ªåˆ«æœºå™¨èŠ‚ç‚¹å¤±è´¥æˆ–æ— æ³•è®¿é—®ã€‚Calicoç½‘ç»œæ•°æ®çš„è¿™ç§åˆ†å¸ƒå¼å­˜å‚¨æé«˜äº†Calicoç»„ä»¶ä»æ•°æ®åº“è¯»å–çš„èƒ½åŠ›ã€‚
Communicationï¼Œetcdä¹Ÿç”¨ä½œç»„ä»¶ä¹‹é—´çš„é€šä¿¡æœåŠ¡ã€‚ æˆ‘ä»¬é€šè¿‡è®©éetcdç»„ä»¶ç›‘è§†é”®å€¼ç©ºé—´ä¸­çš„æŸäº›ç‚¹æ¥ç¡®ä¿ä»–ä»¬çœ‹åˆ°å·²ç»åšå‡ºçš„ä»»ä½•æ›´æ”¹ï¼Œä»è€Œå…è®¸ä»–ä»¬åŠæ—¶å“åº”è¿™äº›æ›´æ”¹ã€‚ è¯¥åŠŸèƒ½å…è®¸å°†çŠ¶æ€ä¿¡æ¯æäº¤åˆ°æ•°æ®åº“ï¼Œç„¶åè§¦å‘åŸºäºè¯¥çŠ¶æ€æ•°æ®çš„è¿›ä¸€æ­¥ç½‘ç»œé…ç½®ç®¡ç†ã€‚</p>

<p>BGP Client (BIRD)
Calicoåœ¨æ¯ä¸ªè¿è¡ŒFelixæœåŠ¡çš„èŠ‚ç‚¹ä¸Šéƒ½éƒ¨ç½²ä¸€ä¸ªBGPå®¢æˆ·ç«¯ã€‚ BGPå®¢æˆ·ç«¯çš„ä½œç”¨æ˜¯è¯»å–Felixç¨‹åºç¼–å†™åˆ°å†…æ ¸ä¸­å¹¶åœ¨æ•°æ®ä¸­å¿ƒå†…åˆ†å‘çš„è·¯ç”±ä¿¡æ¯ã€‚
BGPå®¢æˆ·ç«¯è´Ÿè´£æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š</p>

<p>è·¯ç”±ä¿¡æ¯åˆ†å‘ï¼Œå½“Felixå°†è·¯ç”±æ’å…¥Linuxå†…æ ¸FIBæ—¶ï¼ŒBGPå®¢æˆ·ç«¯å°†æ¥æ”¶å®ƒä»¬å¹¶å°†å®ƒä»¬åˆ†å‘åˆ°é›†ç¾¤ä¸­çš„å…¶ä»–å·¥ä½œèŠ‚ç‚¹ã€‚</p>

<p>BGP Route Reflector (BIRD)
å¯¹äºè¾ƒå¤§è§„æ¨¡çš„éƒ¨ç½²ï¼Œç®€å•çš„BGPå¯èƒ½æˆä¸ºé™åˆ¶å› ç´ ï¼Œå› ä¸ºå®ƒè¦æ±‚æ¯ä¸ªBGPå®¢æˆ·ç«¯è¿æ¥åˆ°ç½‘çŠ¶æ‹“æ‰‘ä¸­çš„æ¯ä¸€ä¸ªå…¶ä»–BGPå®¢æˆ·ç«¯ã€‚è¿™éœ€è¦è¶Šæ¥è¶Šå¤šçš„è¿æ¥ï¼Œè¿…é€Ÿå˜å¾—éš¾ä»¥ç»´æŠ¤ï¼Œç”šè‡³ä¼šè®©ä¸€äº›è®¾å¤‡çš„è·¯ç”±è¡¨æ’‘æ»¡ã€‚
å› æ­¤ï¼Œåœ¨è¾ƒå¤§è§„æ¨¡çš„éƒ¨ç½²ä¸­ï¼ŒCalicoå»ºè®®éƒ¨ç½²BGP Route Reflectorã€‚é€šå¸¸æ˜¯åœ¨Internetä¸­ä½¿ç”¨è¿™æ ·çš„ç»„ä»¶å……å½“BGPå®¢æˆ·ç«¯è¿æ¥çš„ä¸­å¿ƒç‚¹ï¼Œä»è€Œé˜²æ­¢å®ƒä»¬éœ€è¦ä¸ç¾¤é›†ä¸­çš„æ¯ä¸ªBGPå®¢æˆ·ç«¯è¿›è¡Œé€šä¿¡ã€‚ä¸ºäº†å®ç°å†—ä½™ï¼Œä¹Ÿå¯ä»¥åŒæ—¶éƒ¨ç½²å¤šä¸ªBGP Route ReflectoræœåŠ¡ã€‚Route Reflectorä»…ä»…æ˜¯ååŠ©ç®¡ç†BGPç½‘ç»œï¼Œå¹¶æ²¡æœ‰endpointæ•°æ®ä¼šé€šè¿‡å®ƒä»¬ã€‚
åœ¨Calicoä¸­ï¼Œæ­¤BGPç»„ä»¶ä¹Ÿæ˜¯ä½¿ç”¨çš„æœ€å¸¸è§çš„BIRDï¼Œé…ç½®ä¸ºRoute Reflectorè¿è¡Œï¼Œè€Œä¸æ˜¯æ ‡å‡†BGPå®¢æˆ·ç«¯ã€‚
BGP Route Reflectorè´Ÿè´£ä»¥ä¸‹ä»»åŠ¡ï¼š</p>

<p>é›†ä¸­å¼çš„è·¯ç”±ä¿¡æ¯åˆ†å‘ï¼Œå½“Calico BGPå®¢æˆ·ç«¯å°†è·¯ç”±ä»å…¶FIBé€šå‘Šåˆ°Route Reflectoræ—¶ï¼ŒRoute Reflectorä¼šå°†è¿™äº›è·¯ç”±é€šå‘Šç»™éƒ¨ç½²é›†ç¾¤ä¸­çš„å…¶ä»–èŠ‚ç‚¹ã€‚</p>

<p>BIRDæ˜¯ä»€ä¹ˆ
BIRDæ˜¯å¸ƒæ‹‰æ ¼æŸ¥ç†å¤§å­¦æ•°å­¦ä¸ç‰©ç†å­¦é™¢çš„ä¸€ä¸ªå­¦æ ¡é¡¹ç›®ï¼Œé¡¹ç›®åæ˜¯BIRD Internet Routing Daemonçš„ç¼©å†™ã€‚ ç›®å‰ï¼Œå®ƒç”±CZ.NICå®éªŒå®¤å¼€å‘å’Œæ”¯æŒã€‚
BIRDé¡¹ç›®æ—¨åœ¨å¼€å‘ä¸€ä¸ªåŠŸèƒ½é½å…¨çš„åŠ¨æ€IPè·¯ç”±å®ˆæŠ¤è¿›ç¨‹ï¼Œä¸»è¦é’ˆå¯¹ï¼ˆä½†ä¸é™äºï¼‰Linuxï¼ŒFreeBSDå’Œå…¶ä»–ç±»UNIXç³»ç»Ÿï¼Œå¹¶åœ¨GNUé€šç”¨å…¬å…±è®¸å¯è¯ä¸‹åˆ†å‘ã€‚è¯¦ç»†ä¿¡æ¯å‚ç…§å®˜ç½‘https://bird.network.cz/ã€‚
ä½œä¸ºä¸€ä¸ªå¼€æºçš„ç½‘ç»œè·¯ç”±å®ˆæŠ¤è¿›ç¨‹é¡¹ç›®ï¼ŒBRIDè®¾è®¡å¹¶æ”¯æŒäº†ä»¥ä¸‹åŠŸèƒ½ï¼š</p>

<p>both IPv4 and IPv6 protocols
multiple routing tables
the Border Gateway Protocol (BGPv4)
the Routing Information Protocol (RIPv2, RIPng)
the Open Shortest Path First protocol (OSPFv2, OSPFv3)
the Babel Routing Protocol
the Router Advertisements for IPv6 hosts
a virtual protocol for exchange of routes between different routing tables on a single host
a command-line interface allowing on-line control and inspection of status of the daemon
soft reconfiguration (no need to use complex online commands to change the configuration, just edit the configuration file and notify BIRD to re-read it and it will smoothly switch itself to the new configuration, not disturbing routing protocols unless they are affected by the configuration changes)
a powerful language for route filtering</p>

<p>K8S ä¸­éƒ¨ç½² calico</p>

<p>ä¿®æ”¹kube-api server å¯åŠ¨å‚æ•°
â€“allow-priviledge=true (calico éœ€è¦ç‰¹æƒæ¨¡å¼)
å¤åˆ¶ä»£ç </p>

<p>ä¿®æ”¹kubelet å¯åŠ¨å‚æ•° â€“network-plugin=cni</p>

<p>å‡è®¾K8S ç¯å¢ƒåŒ…å«ä¸¤ä¸ªnodeèŠ‚ç‚¹ node1 (192,168.18.3) , node2 (192.168.18.4)
åˆ›å»ºcalico æœåŠ¡, ä¸»è¦åŒ…æ‹¬calico-node å’Œ calico policy controller, éœ€è¦çš„K8S èµ„æºå¯¹è±¡å¦‚ä¸‹</p>

<p>configmap: calico-config åŒ…å«calicoçš„é…ç½®å‚æ•°
secret: calico-etcd-secrets ç”¨äºTLS è¿æ¥etcd
åœ¨æ¯ä¸ªèŠ‚ç‚¹ä»¥daemonsetçš„å½¢å¼ éƒ¨ç½²calico/node å®¹å™¨
åœ¨æ¯ä¸ªèŠ‚ç‚¹éƒ½å®‰è£…calico cni äºŒè¿›åˆ¶æ–‡ä»¶å’Œç½‘ç»œé…ç½®å‚æ•°(ç”±install-cni å®¹å™¨å®Œæˆ)
éƒ¨ç½²ä¸€ä¸ªåä¸ºcalico/kube-policy-controllerçš„deployment, ä¸ºK8S é›†ç¾¤ä¸­çš„POD è®¾ç½®network policy</p>

<p>å®˜æ–¹ calico k8s å®‰è£… yaml æ–‡ä»¶å¦‚ä¸‹
calico-etcd.yaml
â€”</p>
<h1 id="source-calicotemplatescalico-etcd-secretsyaml">Source: calico/templates/calico-etcd-secrets.yaml</h1>
<h1 id="the-following-contains-k8s-secrets-for-use-with-a-tls-enabled-etcd-cluster">The following contains k8s Secrets for use with a TLS enabled etcd cluster.</h1>
<h1 id="for-information-on-populating-secrets-see-httpkubernetesiodocsuser-guidesecrets">For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/</h1>
<p>apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: calico-etcd-secrets
  namespace: kube-system
data:
  # Populate the following with etcd TLS configuration if desired, but leave blank if
  # not using TLS for etcd.
  # The keys below should be uncommented and the values populated with the base64
  # encoded contents of each file that would be associated with the TLS data.
  # Example command for encoding a file contents: cat <file> | base64 -w 0
  # etcd-key: null
  # etcd-cert: null
  # etcd-ca: null
---</file></p>
<h1 id="source-calicotemplatescalico-configyaml">Source: calico/templates/calico-config.yaml</h1>
<h1 id="this-configmap-is-used-to-configure-a-self-hosted-calico-installation">This ConfigMap is used to configure a self-hosted Calico installation.</h1>
<p>kind: ConfigMap
apiVersion: v1
metadata:
  name: calico-config
  namespace: kube-system
data:
  # Configure this with the location of your etcd cluster.
  #ETCDçš„æœåŠ¡åœ°å€
  etcd_endpoints: â€œhttp://<ETCD_IP>:<ETCD_PORT>"
  # If you're using TLS enabled etcd uncomment the following.
  # You must also populate the Secret below with these files.
  etcd_ca: ""   # "/calico-secrets/etcd-ca"
  etcd_cert: "" # "/calico-secrets/etcd-cert"
  etcd_key: ""  # "/calico-secrets/etcd-key"
  # Typha is disabled.
  typha_service_name: "none"
  # Configure the backend to use.
  calico_backend: "bird"</ETCD_PORT></ETCD_IP></p>

<p># Configure the MTU to use
  veth_mtu: â€œ1440â€</p>

<p># The CNI network configuration to install on each node.  The special
  # values in this config will be automatically populated.
  cni_network_config: |-
    {
      â€œnameâ€: â€œk8s-pod-networkâ€,
      â€œcniVersionâ€: â€œ0.3.1â€,
      â€œpluginsâ€: [
        {
          â€œtypeâ€: â€œcalicoâ€,
          â€œlog_levelâ€: â€œinfoâ€,
          â€œetcd_endpointsâ€: â€œ<strong>ETCD_ENDPOINTS</strong>â€,
          â€œetcd_key_fileâ€: â€œ<strong>ETCD_KEY_FILE</strong>â€,
          â€œetcd_cert_fileâ€: â€œ<strong>ETCD_CERT_FILE</strong>â€,
          â€œetcd_ca_cert_fileâ€: â€œ<strong>ETCD_CA_CERT_FILE</strong>â€,
          â€œmtuâ€: <strong>CNI_MTU</strong>,
          â€œipamâ€: {
              â€œtypeâ€: â€œcalico-ipamâ€
          },
          â€œpolicyâ€: {
              â€œtypeâ€: â€œk8sâ€
          },
          â€œkubernetesâ€: {
              â€œkubeconfigâ€: â€œ<strong>KUBECONFIG_FILEPATH</strong>â€
          }
        },
        {
          â€œtypeâ€: â€œportmapâ€,
          â€œsnatâ€: true,
          â€œcapabilitiesâ€: {â€œportMappingsâ€: true}
        }
      ]
    }</p>

<hr />
<h1 id="source-calicotemplatesrbacyaml">Source: calico/templates/rbac.yaml</h1>

<h1 id="include-a-clusterrole-for-the-kube-controllers-component">Include a clusterrole for the kube-controllers component,</h1>
<h1 id="and-bind-it-to-the-calico-kube-controllers-serviceaccount">and bind it to the calico-kube-controllers serviceaccount.</h1>
<p>kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-kube-controllers
rules:
  # Pods are monitored for changing labels.
  # The node controller monitors Kubernetes nodes.
  # Namespace and serviceaccount labels are used for policy.</p>
<ul>
  <li>apiGroups: [â€â€]
resources:
    <ul>
      <li>pods</li>
      <li>nodes</li>
      <li>namespaces</li>
      <li>serviceaccounts
verbs:</li>
      <li>watch</li>
      <li>list
  # Watch for changes to Kubernetes NetworkPolicies.</li>
    </ul>
  </li>
  <li>apiGroups: [â€œnetworking.k8s.ioâ€]
resources:
    <ul>
      <li>networkpolicies
verbs:</li>
      <li>watch</li>
      <li>
        <h2 id="list">list</h2>
        <p>kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-kube-controllers
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-kube-controllers
subjects:</p>
      </li>
    </ul>
  </li>
  <li>kind: ServiceAccount
name: calico-kube-controllers
namespace: kube-system
â€”
    <h1 id="include-a-clusterrole-for-the-calico-node-daemonset">Include a clusterrole for the calico-node DaemonSet,</h1>
    <h1 id="and-bind-it-to-the-calico-node-serviceaccount">and bind it to the calico-node serviceaccount.</h1>
    <p>kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
name: calico-node
rules:</p>
    <h1 id="the-cni-plugin-needs-to-get-pods-nodes-and-namespaces">The CNI plugin needs to get pods, nodes, and namespaces.</h1>
    <ul>
      <li>apiGroups: [â€â€]
resources:
        <ul>
          <li>pods</li>
          <li>nodes</li>
          <li>namespaces
verbs:</li>
          <li>get</li>
        </ul>
      </li>
      <li>apiGroups: [â€â€]
resources:
        <ul>
          <li>endpoints</li>
          <li>services
verbs:
  # Used to discover service IPs for advertisement.</li>
          <li>watch</li>
          <li>list</li>
        </ul>
      </li>
      <li>apiGroups: [â€â€]
resources:
        <ul>
          <li>nodes/status
verbs:
  # Needed for clearing NodeNetworkUnavailable flag.</li>
          <li>
            <h2 id="patch">patch</h2>
            <p>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
name: calico-node
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: calico-node
subjects:</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>kind: ServiceAccount
name: calico-node
namespace: kube-system</li>
</ul>

<hr />
<h1 id="source-calicotemplatescalico-nodeyaml">Source: calico/templates/calico-node.yaml</h1>
<h1 id="this-manifest-installs-the-calico-node-container-as-well">This manifest installs the calico-node container, as well</h1>
<h1 id="as-the-cni-plugins-and-network-config-on">as the CNI plugins and network config on</h1>
<h1 id="each-master-and-worker-node-in-a-kubernetes-cluster">each master and worker node in a Kubernetes cluster.</h1>
<p>kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: â€˜â€™
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
        # Make sure calico-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: calico-node
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a â€œforce
      # deletionâ€: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      priorityClassName: system-node-critical
      initContainers:
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: calico/cni:v3.8.0
          command: [â€œ/install-cni.shâ€]
          env:
            # Name of the CNI config file to create.
            - name: CNI_CONF_NAME
              value: â€œ10-calico.conflistâ€
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: cni_network_config
            # The location of the etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
            # CNI MTU Config variable
            - name: CNI_MTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Prevents the container from sleeping forever.
            - name: SLEEP
              value: â€œfalseâ€
          volumeMounts:
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
            - mountPath: /calico-secrets
              name: etcd-certs
        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes
        # to communicate with Felix over the Policy Sync API.
        - name: flexvol-driver
          image: calico/pod2daemon-flexvol:v3.8.0
          volumeMounts:
          - name: flexvol-driver-host
            mountPath: /host/driver
      containers:
        # Runs calico-node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: calico/node:v3.8.0
          env:
            # The location of the etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
            # Location of the CA certificate for etcd.
            - name: ETCD_CA_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_ca
            # Location of the client key for etcd.
            - name: ETCD_KEY_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_key
            # Location of the client certificate for etcd.
            - name: ETCD_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_cert
            # Set noderef for node controller.
            - name: CALICO_K8S_NODE_REF
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: â€œk8s,bgpâ€
            # Auto-detect the BGP IP address.
            - name: IP
              value: â€œautodetectâ€
            # Enable IPIP
            - name: CALICO_IPV4POOL_IPIP
              value: â€œAlwaysâ€
            # Set MTU for tunnel device used if ipip is enabled
            - name: FELIX_IPINIPMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # The default IPv4 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            # no effect. This should fall within <code class="language-plaintext highlighter-rouge">--cluster-cidr</code>.
            - name: CALICO_IPV4POOL_CIDR
              value: â€œ192.168.0.0/16â€
            # Disable file logging so <code class="language-plaintext highlighter-rouge">kubectl logs</code> works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: â€œtrueâ€
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: â€œACCEPTâ€
            # Disable IPv6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: â€œfalseâ€
            # Set Felix logging to â€œinfoâ€
            - name: FELIX_LOGSEVERITYSCREEN
              value: â€œinfoâ€
            - name: FELIX_HEALTHENABLED
              value: â€œtrueâ€
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 250m
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -bird-ready
              - -felix-ready
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
            - mountPath: /calico-secrets
              name: etcd-certs
            - name: policysync
              mountPath: /var/run/nodeagent
      volumes:
        # Used by calico-node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Mount in the etcd TLS secrets with mode 400.
        # See https://kubernetes.io/docs/concepts/configuration/secret/
        - name: etcd-certs
          secret:
            secretName: calico-etcd-secrets
            defaultMode: 0400
        # Used to create per-pod Unix Domain Sockets
        - name: policysync
          hostPath:
            type: DirectoryOrCreate
            path: /var/run/nodeagent
        # Used to install Flex Volume Driver
        - name: flexvol-driver-host
          hostPath:
            type: DirectoryOrCreate
            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
â€”</p>

<p>apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-node
  namespace: kube-system</p>

<hr />
<h1 id="source-calicotemplatescalico-kube-controllersyaml">Source: calico/templates/calico-kube-controllers.yaml</h1>

<h1 id="see-httpsgithubcomprojectcalicokube-controllers">See https://github.com/projectcalico/kube-controllers</h1>
<p>apiVersion: apps/v1
kind: Deployment
metadata:
  name: calico-kube-controllers
  namespace: kube-system
  labels:
    k8s-app: calico-kube-controllers
spec:
  # The controllers can only have a single active instance.
  replicas: 1
  selector:
    matchLabels:
      k8s-app: calico-kube-controllers
  strategy:
    type: Recreate
  template:
    metadata:
      name: calico-kube-controllers
      namespace: kube-system
      labels:
        k8s-app: calico-kube-controllers
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: â€˜â€™
    spec:
      nodeSelector:
        beta.kubernetes.io/os: linux
      tolerations:
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      serviceAccountName: calico-kube-controllers
      priorityClassName: system-cluster-critical
      # The controllers must run in the host network namespace so that
      # it isnâ€™t governed by policy that would prevent it from working.
      hostNetwork: true
      containers:
        - name: calico-kube-controllers
          image: calico/kube-controllers:v3.8.0
          env:
            # The location of the etcd cluster.
            - name: ETCD_ENDPOINTS
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_endpoints
            # Location of the CA certificate for etcd.
            - name: ETCD_CA_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_ca
            # Location of the client key for etcd.
            - name: ETCD_KEY_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_key
            # Location of the client certificate for etcd.
            - name: ETCD_CERT_FILE
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: etcd_cert
            # Choose which controllers to run.
            - name: ENABLED_CONTROLLERS
              value: policy,namespace,serviceaccount,workloadendpoint,node
          volumeMounts:
            # Mount in the etcd TLS secrets.
            - mountPath: /calico-secrets
              name: etcd-certs
          readinessProbe:
            exec:
              command:
              - /usr/bin/check-status
              - -r
      volumes:
        # Mount in the etcd TLS secrets with mode 400.
        # See https://kubernetes.io/docs/concepts/configuration/secret/
        - name: etcd-certs
          secret:
            secretName: calico-etcd-secrets
            defaultMode: 0400</p>

<hr />

<p>apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-kube-controllers
  namespace: kube-system
â€”</p>
<h1 id="source-calicotemplatescalico-typhayaml">Source: calico/templates/calico-typha.yaml</h1>

<hr />
<h1 id="source-calicotemplatesconfigure-canalyaml">Source: calico/templates/configure-canal.yaml</h1>

<hr />
<h1 id="source-calicotemplateskdd-crdsyaml">Source: calico/templates/kdd-crds.yaml</h1>

<p>å¤åˆ¶ä»£ç kubectl apply -f calico-etcd.yaml
å¤åˆ¶ä»£ç 
æ³¨æ„ä¿®æ”¹å‚æ•°</p>

<p>æ›´å¤šcalicoè®¾ç½®
coredns
å¯ç”¨ coredns éœ€è¦åœ¨kubelet ä¸Šæ·»åŠ ä¸¤ä¸ªå‚æ•°
â€“cluster-dns=169.169.0.100 IP ä¸ºDNSæœåŠ¡çš„cluster ip
â€“cluster-domain=cluster.local ä¸ºdnsæœåŠ¡è®¾ç½®çš„åŸŸå
éœ€è¦éƒ¨ç½²çš„coredns yamlæ–‡ä»¶
apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
â€”
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:</p>
<ul>
  <li>apiGroups:
    <ul>
      <li>â€â€
resources:</li>
      <li>endpoints</li>
      <li>services</li>
      <li>pods</li>
      <li>namespaces
verbs:</li>
      <li>list</li>
      <li>watch</li>
    </ul>
  </li>
  <li>apiGroups:
    <ul>
      <li>â€â€
resources:</li>
      <li>nodes
verbs:</li>
      <li>
        <h2 id="get">get</h2>
        <p>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
annotations:
rbac.authorization.kubernetes.io/autoupdate: â€œtrueâ€
labels:
kubernetes.io/bootstrapping: rbac-defaults
name: system:coredns
roleRef:
apiGroup: rbac.authorization.k8s.io
kind: ClusterRole
name: system:coredns
subjects:</p>
      </li>
    </ul>
  </li>
  <li>kind: ServiceAccount
name: coredns
namespace: kube-system
â€”
apiVersion: v1
kind: ConfigMap
metadata:
name: coredns
namespace: kube-system
data:
Corefile: |
  .:53 {
      errors
      health
      ready
      kubernetes CLUSTER_DOMAIN REVERSE_CIDRS {
        pods insecure
        fallthrough in-addr.arpa ip6.arpa
      }FEDERATIONS
      prometheus :9153
      forward . UPSTREAMNAMESERVER
      cache 30
      loop
      reload
      loadbalance
  }STUBDOMAINS
â€”
apiVersion: apps/v1
kind: Deployment
metadata:
name: coredns
namespace: kube-system
labels:
  k8s-app: kube-dns
  kubernetes.io/name: â€œCoreDNSâ€
spec:
replicas: 2
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 1
selector:
  matchLabels:
    k8s-app: kube-dns
template:
  metadata:
    labels:
      k8s-app: kube-dns
  spec:
    priorityClassName: system-cluster-critical
    serviceAccountName: coredns
    tolerations:
      - key: â€œCriticalAddonsOnlyâ€
        operator: â€œExistsâ€
    nodeSelector:
      beta.kubernetes.io/os: linux
    containers:
    - name: coredns
      image: coredns/coredns:1.5.0
      imagePullPolicy: IfNotPresent
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      args: [ â€œ-confâ€, â€œ/etc/coredns/Corefileâ€ ]
      volumeMounts:
      - name: config-volume
        mountPath: /etc/coredns
        readOnly: true
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      livenessProbe:
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        timeoutSeconds: 5
        successThreshold: 1
        failureThreshold: 5
      readinessProbe:
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
    dnsPolicy: Default
    volumes:
      - name: config-volume
        configMap:
          name: coredns
          items:
          - key: Corefile
            path: Corefile
â€”
apiVersion: v1
kind: Service
metadata:
name: kube-dns
namespace: kube-system
annotations:
  prometheus.io/port: â€œ9153â€
  prometheus.io/scrape: â€œtrueâ€
labels:
  k8s-app: kube-dns
  kubernetes.io/cluster-service: â€œtrueâ€
  kubernetes.io/name: â€œCoreDNSâ€
spec:
selector:
  k8s-app: kube-dns
  #è¿™é‡Œè¦å’Œkubelet å‚æ•°å¯¹åº”ä¸Š
clusterIP: 169.169.0.100
ports:
    <ul>
      <li>name: dns
port: 53
protocol: UDP</li>
      <li>name: dns-tcp
port: 53
protocol: TCP</li>
      <li>name: metrics
port: 9153
protocol: TCP
å¤åˆ¶ä»£ç å¦‚æœæƒ³çŸ¥é“ç°æœ‰é›†ç¾¤ä¸­ä½¿ç”¨çš„é…ç½®é¡¹å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡ŒæŸ¥çœ‹
kubectl -n kube-system get configmap coredns -o yaml</li>
    </ul>
  </li>
</ul>
:ET