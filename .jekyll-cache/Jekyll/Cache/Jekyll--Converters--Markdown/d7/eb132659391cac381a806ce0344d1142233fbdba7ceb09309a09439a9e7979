I"<p>https://gocn.vip/topics/10382
随着云原生人工智能（Cloud Native AI）的兴起，灵活的计算存储分离架构大行其道。在此背景下，用户在云上训练大规模深度学习模型引发的数据缓存需求日益旺盛。为此，阿里云容器服务团队与 Alluxio 开源社区和南京大学顾荣老师等人通力合作寻找相关解决方案，当前已经提供 K8s 上运行模型训练数据加速的基础方案，包括容器化部署、生命周期管理以及性能优化（持续中），从而降低数据访问高成本和复杂度，进一步助力云上普惠 AI 模型训练。
<!-- more --></p>
<ol>
  <li>背景介绍
近些年，以深度学习为代表的人工智能技术取得了飞速的发展，正落地应用于各行各业。随着深度学习的广泛应用，众多领域产生了大量强烈的高效便捷训练人工智能模型方面的需求。另外，在云计算时代，以 Docker、Kubernetes 以主的容器及其编排技术在应用服务自动化部署的软件开发运维浪潮中取得了长足的发展。Kubernetes 社区对于 GPU 等加速计算设备资源的支持方兴未艾。鉴于云环境在计算成本和规模扩展方面的优势，以及容器化在高效部署和敏捷迭代方面的长处，基于 “容器化弹性基础架构 + 云平台 GPU 实例” 进行分布式深度学习模型训练成为了业界生成 AI 模型的主要趋势。</li>
</ol>
:ET