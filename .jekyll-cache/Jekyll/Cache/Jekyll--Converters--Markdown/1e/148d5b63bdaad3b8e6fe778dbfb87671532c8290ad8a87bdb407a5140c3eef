I";<p>Logistic回归与多重线性回归实际上有很多相同之处，最大的区别就在于它们的因变量不同，其他的基本都差不多。正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalizedlinear model）。</p>

<p>这一家族中的模型形式基本上都差不多，不同的就是因变量不同。</p>

<p>如果是连续的，就是多重线性回归；
如果是二项分布，就是Logistic回归；
如果是Poisson分布，就是Poisson回归；
如果是负二项分布，就是负二项回归。
Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。
Logistic回归的主要用途：</p>

<p>寻找危险因素：寻找某一疾病的危险因素等；
预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；
判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。
Logistic回归主要在流行病学中应用较多，比较常用的情形是探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。
常规步骤</p>

<p>Regression问题的常规步骤为：</p>

<p>寻找h函数（即hypothesis）；
构造J函数（损失函数）；
想办法使得J函数最小并求得回归参数（θ）
http://blog.csdn.net/wjlucc/article/details/69264144
<!-- more --></p>
<ol>
  <li>二项逻辑斯蒂回归模型
二项逻辑斯蒂回归模型是如下的条件概率分布：
$P(Y=1|x)=\frac{\exp{(w \cdot x+b)}}{1+\exp(w\cdot x+b)}$
P(Y=0|x)=11+exp(w⋅x+b)
注意：P(Y=1|x)模型也经常写成hθ(x)=11+exp(−θT⋅x)。 
事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。 
如果事件发生的概率是p，那么该事件的几率是P1−P，该事件的对数几率（log odds）或logit函数是：logit(P)=logp1−p。 
逻辑回归的对数几率是： 
log(P(Y=1|x)1−P(Y=1|x))=w⋅x
意义：在逻辑斯蒂回归模型中，输出Y=1的对数几率是输入x的线性函数。或者说，输出Y=1的对数几率是由属于x的线性函数表示的模型，即逻辑斯蒂回归模型。（这里需要再理解下） 
  感知机只通过决策函数（w⋅x）的符号来判断属于哪一类。逻辑斯蒂回归需要再进一步，它要找到分类概率P(Y=1)与输入向量x的直接关系，再通过比较概率值来判断类别。 
令决策函数（w⋅x）输出值等于概率值比值取对数，即： 
logp1−p=w⋅x⟹p=exp(w⋅x+b)1+exp(w⋅x+b)</li>
</ol>

<p>逻辑斯蒂回归模型的定义式P(Y=1|x)中可以将线性函数w⋅x转换为概率，这时，线性函数的值越接近正无穷，概率值就越接近1；线性函数的值越接近负无穷，概率值就接近0.</p>
<ol>
  <li>模型参数估计
应用极大似然法进行参数估计，从而获得逻辑斯蒂回归模型。极大似然估计的数学原理参考这里。 
设：P(Y=1|x)=π(x),P(Y=0|x)=1−π(x) 
似然函数为：</li>
</ol>

<p>∏i=1N[π(xi)]yi[1−π(xi)]1−yi</p>

<p>上式连乘符号内的两项中，每个样本都只会取到两项中的某一项。若该样本的实际标签yi=1，取样本计算为1的概率值π(xi)；若该样本的实际标签yi=0，取样本计算的为0的概率值1−π(xi)。 
对数似然函数为： 
L(w)====∑i=1N[yilogπ(xi)+(1−yi)log(1−π(xi))]∑i=1N[yilogπ(xi)1−π(xi)+log(1−π(xi))]∑i=1N[yi(w⋅xi)+log11+exp(w⋅xi)]∑i=1N[yi(w⋅xi)−log(1+exp(w⋅xi))]</p>

<p>对上式中的L(w)求极大值，得到w的估计值。 
问题转化成以对数似然函数为目标函数的无约束最优化问题，通常采用梯度下降法以及拟牛顿法求解w。 
假设w的极大估计值是wˆ，那么学到的逻辑斯蒂回归模型为： 
P(Y=1|x)=exp(wˆ⋅x)1+exp(wˆ⋅x)</p>

<p>P(Y=0|x)=11+exp(wˆ⋅x)</p>
<ol>
  <li>多项逻辑斯蒂回归
多项逻辑斯蒂回归用于多分类问题，其模型为：</li>
</ol>

<table>
  <tbody>
    <tr>
      <td>P(Y=k</td>
      <td>x)=exp(wk⋅x)1+∑k=1K−1exp(wk⋅x),k=1,2,⋯,K−1</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>P(Y=K</td>
      <td>x)=11+∑k=1K−1exp(wk⋅x)</td>
    </tr>
  </tbody>
</table>

<p>上面的公式和二分类的类似，式中k的取值只能取到K−1。</p>
<ol>
  <li>交叉熵损失函数的求导
逻辑回归的另一种理解是以交叉熵作为损失函数的目标最优化。交叉熵损失函数可以从上文最大似然推导出来。 
交叉熵损失函数为：</li>
</ol>

<p>y(i)log(hθ(x(i)))+(1−y(i))log(1−hθ(x(i)))</p>

<p>则可以得到目标函数为： 
J(θ)==−1m∑i=1my(i)log(hθ(x(i)))+(1−y(i))log(1−hθ(x(i)))−1m∑i=1m[y(i)θTx(i)−log(1+eθTx(i))]
计算J(θ)对第j个参数分量θj求偏导:</p>

<p>∂∂θjJ(θ)====∂∂θj(1m∑i=1m[log(1+eθTx(i))−y(i)θTx(i)])1m∑i=1m[∂∂θjlog(1+eθTx(i))−∂∂θj(y(i)θTx(i))]1m∑i=1m⎛⎝x(i)jeθTx(i)1+eθTx(i)−y(i)x(i)j⎞⎠1m∑i=1m(hθ(x(i))−y(i))x(i)j</p>
:ET