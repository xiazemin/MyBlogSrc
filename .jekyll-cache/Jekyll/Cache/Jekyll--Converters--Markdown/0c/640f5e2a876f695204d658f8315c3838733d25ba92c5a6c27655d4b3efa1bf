I"<p>NAPI是Linux新的网卡数据处理API，据说是由于找不到更好的名字，所以就叫NAPI(New API)，在2.5之后引入。简单来说，NAPI是综合中断方式与轮询方式的技术。中断的好处是响应及时，如果数据量较小，则不会占用太多的CPU事件；缺点是数据量大时，会产生过多中断，而每个中断都要消耗不少的CPU时间，从而导致效率反而不如轮询高。轮询方式与中断方式相反，它更适合处理大量数据，因为每次轮询不需要消耗过多的CPU时间；缺点是即使只接收很少数据或不接收数据时，也要占用CPU时间。
NAPI是两者的结合，数据量低时采用中断，数据量高时采用轮询。平时是中断方式，当有数据到达时，会触发中断
处理函数执行，中断处理函数关闭中断开始处理。如果此时有数据到达，则没必要再触发中断了，因为中断处理函
数中会轮询处理数据，直到没有新数据时才打开中断。
很明显，数据量很低与很高时，NAPI可以发挥中断与轮询方式的优点，性能较好。如果数据量不稳定，且说高不高
说低不低，则NAPI则会在两种方式切换上消耗不少时间，效率反而较低一些。
来看下NAPI和非NAPI的区别：
(1) 支持NAPI的网卡驱动必须提供轮询方法poll()。
(2) 非NAPI的内核接口为netif_rx()，NAPI的内核接口为napi_schedule()。
(3) 非NAPI使用共享的CPU队列softnet_data-&gt;input_pkt_queue，NAPI使用设备内存(或者
设备驱动程序的接收环)。
(1) NAPI设备结构
/* Structure for NAPI scheduling similar to tasklet but with weighting */</p>

<p>struct napi_struct {<br />
    /* The poll_list must only be managed by the entity which changes the 
     * state of the NAPI_STATE_SCHED bit. This means whoever atomically 
     * sets that bit can add this napi_struct to the per-cpu poll_list, and 
     * whoever clears that bit can remove from the list right before clearing the bit. 
     <em>/<br />
    struct list_head poll_list; /</em> 用于加入处于轮询状态的设备队列 <em>/<br />
    unsigned long state; /</em> 设备的状态 <em>/<br />
    int weight; /</em> 每次处理的最大数量，非NAPI默认为64 <em>/<br />
    int (</em>poll) (struct napi_struct <em>, int); /</em> 此设备的轮询方法，非NAPI为process_backlog() <em>/ <br />
 #ifdef CONFIG_NETPOLL<br />
    …<br />
 #endif<br />
    unsigned int gro_count;<br />
    struct net_device *dev;<br />
    struct list_head dev_list;<br />
    struct sk_buff *gro_list;<br />
    struct sk_buff *skb;<br />
};<br />
(2) 初始化
初始napi_struct实例。
void netif_napi_add(struct net_device *dev, struct napi_struct *napi,<br />
        int (</em>poll) (struct napi_struct <em>, int), int weight)<br />
{<br />
    INIT_LIST_HEAD(&amp;napi-&gt;poll_list);<br />
    napi-&gt;gro_count = 0;<br />
    napi-&gt;gro_list = NULL;<br />
    napi-&gt;skb = NULL;<br />
    napi-&gt;poll = poll; /</em> 设备的poll函数 <em>/<br />
    napi-&gt;weight = weight; /</em> 设备每次poll能处理的数据包个数上限 */</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>list_add(&amp;napi-&gt;dev_list, &amp;dev-&gt;napi_list); /* 加入设备的napi_list */  
napi-&gt;dev = dev; /* 所属设备 */     #ifdef CONFIG_NETPOLL  
spin_lock_init(&amp;napi-&gt;poll_lock);  
napi-&gt;poll_owner = -1;    #endif  
set_bit(NAPI_STATE_SCHED, &amp;napi-&gt;state); /* 设置NAPI标志位 */   }   (3) 调度 在网卡驱动的中断处理函数中调用napi_schedule()来使用NAPI。 /**   * napi_schedule - schedule NAPI poll   * @n: napi context   * Schedule NAPI poll routine to be called if it is not already running.   */    static inline void napi_schedule(struct napi_struct *n)   {  
/* 判断是否可以调度NAPI */  
if (napi_schedule_prep(n))  
    __napi_schedule(n);   }   判断NAPI是否可以调度。如果NAPI没有被禁止，且不存在已被调度的NAPI， 则允许调度NAPI，因为同一时刻只允许有一个NAPI poll instance。 /**   * napi_schedule_prep - check if napi can be scheduled   * @n: napi context   * Test if NAPI routine is already running, and if not mark it as running.   * This is used as a condition variable insure only one NAPI poll instance runs.   * We also make sure there is no pending NAPI disable.   */  
</code></pre></div></div>

<p>static inline int napi_schedule_prep(struct napi_struct *n)<br />
{<br />
    return !napi_disable_pending(n) &amp;&amp; !test_and_set_bit(NAPI_STATE_SCHED, &amp;n-&gt;state);<br />
}</p>

<p>static inline int napi_disable_pending(struct napi_struct *n)<br />
{<br />
    return test_bit(NAPI_STATE_DISABLE, &amp;n-&gt;state);<br />
}</p>

<p>enum {<br />
    NAPI_STATE_SCHED, /* Poll is scheduled <em>/<br />
    NAPI_STATE_DISABLE, /</em> Disable pending <em>/<br />
    NAPI_STATE_NPSVC, /</em> Netpoll - don’t dequeue from poll_list */<br />
};<br />
NAPI的调度函数。把设备的napi_struct实例添加到当前CPU的softnet_data的poll_list中，</p>
:ET