I"­<p>from pyspark.sql import SparkSession, HiveContext</p>

<p>_SPARK_HOST = â€œspark://spark-master:7077â€
_APP_NAME = â€œtestâ€</p>

<p>spark = SparkSession.builder.master(_SPARK_HOST).appName(_APP_NAME).getOrCreate()</p>

<p>data = [
    (1,â€3â€,â€145â€),
    (1,â€4â€,â€146â€),
    (1,â€5â€,â€25â€),
    (1,â€6â€,â€26â€),
    (2,â€32â€,â€32â€),
    (2,â€8â€,â€134â€),
    (2,â€8â€,â€134â€),
    (2,â€9â€,â€137â€)
]
df = spark.createDataFrame(data, [â€˜idâ€™, â€œtest_idâ€, â€˜camera_idâ€™])</p>

<h1 id="method-onedefaultæ˜¯é»˜è®¤æ•°æ®åº“çš„åå­—write_test-æ˜¯è¦å†™åˆ°defaultä¸­æ•°æ®è¡¨çš„åå­—">method oneï¼Œdefaultæ˜¯é»˜è®¤æ•°æ®åº“çš„åå­—ï¼Œwrite_test æ˜¯è¦å†™åˆ°defaultä¸­æ•°æ®è¡¨çš„åå­—</h1>
<p>df.registerTempTable(â€˜test_hiveâ€™)
sqlContext.sql(â€œcreate table default.write_test select * from test_hiveâ€)
<!-- more -->
https://blog.csdn.net/u011412768/article/details/93426353</p>
:ET