I",<!-- more -->
<p>版内核中出现。</p>

<p>在Linux下，信号量和线程互斥锁的实现都是通过futex系统调用。</p>

<p>futex（快速用户区互斥的简称）是一个在Linux上实现锁定和构建高级抽象锁如信号量和POSIX互斥的基本工具。它们第一次出现在内核开发的2.5.7版；其语义在2.5.40固定下来，然后在2.6.x系列稳定版内核中出现。</p>

<p>Futex 是fast userspace mutex的缩写，意思是快速用户空间互斥体。Linux内核把它们作为快速的用户空间的锁和信号量的预制构件提供给开发者。Futex非常基础，借助其自身的优异性能，构建更高级别的锁的抽象，如POSIX互斥体。大多数程序员并不需要直接使用Futex，它一般用来实现像NPTL这样的系统库。</p>

<p>Futex 由一块能够被多个进程共享的内存空间（一个对齐后的整型变量）组成；这个整型变量的值能够通过汇编语言调用CPU提供的原子操作指令来增加或减少，并且一个进程可以等待直到那个值变成正数。Futex 的操作几乎全部在应用程序空间完成；只有当操作结果不一致从而需要仲裁时，才需要进入操作系统内核空间执行。这种机制允许使用 futex 的锁定原语有非常高的执行效率：由于绝大多数的操作并不需要在多个进程之间进行仲裁，所以绝大多数操作都可以在应用程序空间执行，而不需要使用（相对高代价的）内核系统调用。</p>

<p>futex保存在用户空间的共享内存中，并且通过原子操作进行操作。在大部分情况下，资源不存在争用的情况下，进程或者线程可以立刻获得资源成功，实际上就没有必要调用系统调用，陷入内核了。实际上，futex的作用就在于减少系统调用的次数，来提高系统的性能。</p>

<p>线程互斥锁pthread_mutex_t的实现原理：</p>

<p>pthread_mutex_lock:
atomic_dec(pthread_mutex_t.value);
if(pthread_mutex_t.value!=0)
futex(WAIT)
else
success</p>

<p>pthread_mutex_unlock:
atomic_inc(pthread_mutex_t.value);
if(pthread_mutex_t.value!=1)
futex(WAKEUP)
else
success
信号量sem_t的实现原理：</p>

<p>sem_wait(sem_t *sem)
{
for (;;) {</p>

<p>if (atomic_decrement_if_positive(sem-&gt;count))
break;</p>

<p>futex_wait(&amp;sem-&gt;count, 0)
}
}</p>

<p>sem_post(sem_t *sem)
{
n = atomic_increment(sem-&gt;count);
// Pass the new value of sem-&gt;count
futex_wake(&amp;sem-&gt;count, n + 1);
}
对比，pthread_mutex_unlock()和sem_post()的实现，我们发现一个不同点，sem_post()无论如何都会调用 futex_wake()，进行系统调用。但是pthread_mutex_unlock()却符合futex的初衷，只有在需要仲裁的时候才调用 futex_wake()。那么什么是仲裁条件呢？</p>

<p>前面说过信号量和线程互斥锁语义上的区别在于信号量的value&gt;=0，而线程互斥锁的value可以为负数。
对于lock操作，这两个倒是没有多少差别。信号量只要value&gt;0就可以获得资源，线程互斥锁需要value=1。
但是对于unlock操作，这两个就有一些差别了。信号量和线程互斥锁，都会增加对应的value。如果加1后，value为1，对于线程互斥锁来讲，实际上表明资源可用，并且之前没有其他的线程在等待这个资源；否则说明还有其他线程在等待这个资源，需要调用futex系统调用唤醒它们。但是对于信号量，由于value必须&gt;=0。那么加1后，即使value为1，也无法判定现在没有其他的进程或线程正在等待资源，所以必须调用futex系统调用。例如：</p>

<p>#include 
#include 
#include</p>

<p>sem_t sem_a;
void *task1();</p>

<p>int main(void)
{
int ret=0;
pthread_t thrd1;
pthread_t thrd2;
sem_init(&amp;sem_a,0,1);
ret=pthread_create(&amp;thrd1,NULL,task1,NULL); //创建子线程
ret=pthread_create(&amp;thrd2,NULL,task1,NULL); //创建子线程
pthread_join(thrd1,NULL); //等待子线程结束
pthread_join(thrd2,NULL); //等待子线程结束
}</p>

<p>void *task1()
{
int sval = 0;
sem_wait(&amp;sem_a); //持有信号量
sleep(5); //do_nothing
sem_getvalue(&amp;sem_a,&amp;sval);
printf(“sem value = %d/n”,sval);
sem_post(&amp;sem_a); //释放信号量
}
上面sem的value初始化为1，但是有两个线程争用资源。那么第一个线程获得资源成功，当它unlock的时候，sem的value变为1。但是，这个时候，实际上还有一个线程在等待资源。因此，必须要进行futex_wake()系统调用，唤醒等待资源的线程。</p>

<p>原子操作实现原理：</p>

<p>关于x86原子操作指令的说明：
cmpxchg 比较交换指令，其语义为：</p>

<p>int CompareAndExchange(int *ptr, int old, int new)
{
int actual = *ptr;
if (actual == old)
*ptr = new;
return actual;
}
使用此原子操作可以实现自旋锁，之前有一篇文章中描述了实现：</p>

<p>void lock(lock_t *lock) {
while (CompareAndExchange(&amp;lock-&gt;flag, 0, 1) == 1)
; // spin
}
void unlock(lock_t *lock) {
lock-&gt;flag = 0;
}
关于smp下的原子操作的一些说明：
原子操作是不可分割的，在执行完毕不会被任何其它任务或事件中断。在单处理器系统(UniProcessor)中，能够在单条指令中完成的操作都可以认为是” 原子操作”，因为中断只能发生于指令之间。这也是某些CPU指令系统中引入了test_and_set、test_and_clear等指令用于临界资源互斥的原因。在对称多处理器(Symmetric Multi-Processor)结构中就不同了，由于系统中有多个处理器在独立地运行，即使能在单条指令中完成的操作也有可能受到干扰。
在x86 平台上，CPU提供了在指令执行期间对总线加锁的手段。CPU芯片上有一条引线#HLOCK pin，如果汇编语言的程序中在一条指令前面加上前缀”LOCK”，经过汇编以后的机器代码就使CPU在执行这条指令的时候把#HLOCK pin的电位拉低，持续到这条指令结束时放开，从而把总线锁住，这样同一总线上别的CPU就暂时不能通过总线访问内存了，保证了这条指令在多处理器环境中的原子性。
当然，并不是所有的指令前面都可以加lock前缀的，只有ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG,DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, 和 XCHG指令前面可以加lock指令，实现原子操作。</p>

<p>处理器级的原子操作实现</p>

<p>术语定义
术语</p>

<p>英文</p>

<p>解释</p>

<p>缓存行</p>

<p>Cac he line</p>

<p>缓存的最小操作单位</p>

<p>比较并交换</p>

<p>Compare and Swap</p>

<p>CAS操作需要输入两个数值，一个旧值（期望操作前的值）和一个新值，在操作期间先比较下旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。</p>

<p>CPU流水线</p>

<p>CPU pipeline</p>

<p>CPU流水线的工作方式就象工业生产上的装配流水线，在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5~6步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度。</p>

<p>内存顺序冲突</p>

<p>Memory order violation</p>

<p>内存顺序冲突一般是由假共享引起，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线。</p>

<p>32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。处理器如何实现原子操作
处理器自动保证基本内存操作的原子性
首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。</p>

<p>使用总线锁保证原子性
第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2
原因是有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。</p>

<p>处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。</p>

<p>使用缓存锁保证原子性
第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。</p>

<p>频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在例1中，当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。</p>

<p>但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Inter486和奔腾处理器,就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。</p>

<p>以上两个机制我们可以通过Inter处理器提供了很多LOCK前缀的指令来实现。比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，比如ADD（加），OR（或）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。</p>
:ET