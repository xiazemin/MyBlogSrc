I"<p>Apache Parquet是一种能够有效存储嵌套数据的列式存储格式。
Parquet文件由一个文件头（header），一个或多个紧随其后的文件块（block），以及一个用于结尾的文件尾（footer）构成。文件头仅包含
Parquet文件的每个文件块负责存储一个行组，行组由列块组成，且一个列块负责存储一列数据。每个列块中的的数据以页为单位
<!-- more -->
为什么我们选择parquet
前用的hadoop，一直有个疑惑。当时没有细究，昨天突然想到，就又顺着看了下，经过调整，原来在presto中要用1分钟的，现在基本可以秒级别出结果，和presto无关，和文件存储格式有关，hdfs默认存的是文本格式，所以hive,presto，都是在文本格式上做计算，hadoop本身是全表扫，只是分布式而以，所以我们之前用的就是分布式的全表扫而以，没有发挥出数据仓库该有的功能,列式存储，天然擅长分析,千万级别的表，count,sum，group by ，秒出结果!!</p>
:ET