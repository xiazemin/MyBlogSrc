I"ÌÉ<p>https://software.intel.com/en-us/blogs/2014/05/10/debugging-performance-issues-in-go-programs</p>

<p>https://lrita.github.io/2017/05/26/golang-memory-pprof/
<!-- more -->
Debugging performance issues in Go programs
By Dmitry Vyukov, published on May 10, 2014
Letâ€™s assume you have a Go program and want to improve its performance. There are several tools available that can help with this task. These tools can help you to identify various types of hotspots (CPU, IO, memory), hotspots are the places that you need to concentrate on in order to significantly improve performance. However, another outcome is possible â€“ the tools can help you identify obvious performance defects in the program. For example, you prepare an SQL statement before each query while you could prepare it once at program startup. Another example is if an O(N^2) algorithm somehow slipped into where an obvious O(N) exists and is expected. In order to identify such cases you need to sanity check what you see in profiles. For example for the first case significant time spent in SQL statement preparation would be the red flag.</p>

<p>Itâ€™s also important to understand various bounding factors for performance. For example, if the program communicates via 100 Mbps network link and it is already utilizes &gt;90Mbps, there is not much you can do with the program to improve its performance. There are similar bounding factors for disk IO, memory consumption and computational tasks.</p>

<p>With that in mind we can look at the available tools.</p>

<p>Note: The tools can interfere with each other. For example, precise memory profiling skews CPU profiles, goroutine blocking profiling affects scheduler trace, etc. Use tools in isolation to get more precise info.</p>

<p>Note: the formats described here are based on Go1.3 release.</p>

<p>CPU Profiler</p>

<p>Go runtime contains built-in CPU profiler, which shows what functions consume what percent of CPU time. There are 3 ways you can get access to it:</p>

<ol>
  <li>The simplest one is -cpuprofile flag of â€˜go testâ€™ command. For example, the following command:</li>
</ol>

<p>$ go test -run=none -bench=ClientServerParallel4 -cpuprofile=cprof net/http</p>

<p>will profile the given benchmark and write CPU profile into â€˜cprofâ€™ file.</p>

<p>Then:</p>

<p>$ go tool pprof â€“text http.test cprof</p>

<p>will print a list of the hottest functions.</p>

<p>There are several output types available, the most useful ones are: â€“text, â€“web and â€“list. Run â€˜go tool pprofâ€™ to get the complete list.</p>

<p>The obvious drawback of this option is that it works only for tests.</p>

<ol>
  <li>net/http/pprof package. This is the ideal solution for network servers. You merely need to import net/http/pprof, and collect profiles with:</li>
</ol>

<p>$ go tool pprof â€“text mybin http://myserver:6060:/debug/pprof/profile</p>

<ol>
  <li>Manual profile collection. You need to import runtime/pprof and add the following code to main function:</li>
</ol>

<p>1
if <em>flagCpuprofile != â€œâ€ {
2
    f, err := os.Create(</em>flagCpuprofile)
3
    if err != nil {
4
        log.Fatal(err)
5
    }
6
    pprof.StartCPUProfile(f)
7
    defer pprof.StopCPUProfile()
8
}
The profile will be written to the specified file, visualize it the same way as in the first option.</p>

<p>Here is an example of a profile visualized with â€“web option:</p>

<p>cpu profile</p>

<p>You can investigate a single function with â€“list=funcname option. For example, the following profile shows that the time was spent in the append function:</p>

<p>01
.      .   93: func (bp <em>buffer) WriteRune(r rune) error {
02
.      .   94:     if r &lt; utf8.RuneSelf {
03
5      5   95:         *bp = append(</em>bp, byte(r))
04
.      .   96:         return nil
05
.      .   97:     }
06
.      .   98:
07
.      .   99:     b := *bp
08
.      .  100:     n := len(b)
09
.      .  101:     for n+utf8.UTFMax &gt; cap(b) {
10
.      .  102:         b = append(b, 0)
11
.      .  103:     }
12
.      .  104:     w := utf8.EncodeRune(b[n:n+utf8.UTFMax], r)
13
.      .  105:     *bp = b[:n+w]
14
.      .  106:     return nil
15
.      .  107: }
You can find detailed info on pprof tool and description of the numbers in the graph here.</p>

<p>There are also 3 special entries that the profiler uses when it canâ€™t unwind stack: GC, System and ExternalCode. GC means time spent during garbage collection, see Memory Profiler and Garbage Collector Trace sections below for optimization suggestions. System means time spent in goroutine scheduler, stack management code and other auxiliary runtime code. ExternalCode means time spent in native dynamic libraries.</p>

<p>Here are some hints with respect to how to interpret what you see in the profile.</p>

<p>If you see lots of time spent in runtime.mallocgc function, the program potentially makes excessive amount of small memory allocations. The profile will tell you where the allocations are coming from. See the memory profiler section for suggestions on how to optimize this case.</p>

<p>If lots of time is spent in channel operations, sync.Mutex code and other synchronization primitives or System component, the program probably suffers from contention. Consider to restructure program to eliminate frequently accessed shared resources. Common techniques for this include sharding/partitioning, local buffering/batching and copy-on-write technique.</p>

<p>If lots of time is spent in syscall.Read/Write, the program potentially makes excessive amount of small reads and writes. Bufio wrappers around os.File or net.Conn can help in this case.</p>

<p>If lots of time is spent in GC component, the program either allocates too many transient objects or heap size is very small so garbage collections happen too frequently. See Garbage Collector Tracer and Memory Profiler sections for optimization suggestions.</p>

<p>Note: CPU profiler currently does not work on darwin.</p>

<p>Note: On windows you need to install Cygwin, Perl and Graphviz to generate svg/web profiles.</p>

<p>Note: On linux you can also try perf system profiler. It canâ€™t unwind Go stacks, but it can profile and unwind cgo/SWIG code and kernel. So it can be useful to get insights into native/kernel performance bottlenecks.</p>

<p>Memory Profiler</p>

<p>Memory profiler shows what functions allocate heap memory. You can collect it in similar ways as CPU profile: with â€˜go test â€“memprofileâ€™, with net/http/pprof via http://myserver:6060:/debug/pprof/heap or by calling runtime/pprof.WriteHeapProfile.</p>

<p>You can visualize only allocations live at the time of profile collection (â€“inuse_space flag to pprof, default), or all allocations happened since program start (â€“alloc_space flag to pprof). The former is useful for profiles collected with net/http/pprof on live applications, the latter is useful for profiles collected at program end (otherwise you will see almost empty profile).</p>

<p>Note: the memory profiler is sampling, that is, it collects information only about some subset of memory allocations. Probability of sampling an object is proportional to its size. You can change the sampling rate with go test â€“memprofilerate flag, or by setting runtime.MemProfileRate variable at program startup. The rate of 1 will lead to collection of information about all allocations, but it can slow down execution. The default sampling rate is 1 sample per 512KB of allocated memory.</p>

<p>You can also visualize number of bytes allocated or number of objects allocated (â€“inuse/alloc_space and â€“inuse/alloc_objects flags, respectively). The profiler tends to sample larger objects during profiling  more. But itâ€™s important to understand that large objects affect memory consumption and GC time, while large number of tiny allocations affects execution speed (and GC time to some degree as well). So it may be useful to look at both.</p>

<p>Objects can be persistent or transient. If you have several large persistent objects allocated at program start, they will be most likely sampled by the profiler (because they are large). Such objects do affect memory consumption and GC time, but they do not affect normal execution speed (no memory management operations happen on them). On the other hand if you have large number of objects with very short life durations, they can be barely represented in the profile (if you use the default â€“inuse_space mode). But they do significantly affect execution speed, because they are constantly allocated and freed. So, once again, it may be useful to look at both types of objects.</p>

<p>So, generally, if you want to reduce memory consumption, you need to look at â€“inuse_space profile collected during normal program operation. If you want to improve execution speed, look at â€“alloc_objects profile collected after significant running time or at program end.</p>

<p>There are several flags that control reporting granularity. â€“functions makes pprof report on function level (default). â€“lines makes pprof report on source line level, which is useful if hot functions allocate on different lines. And there are also â€“addresses and â€“files for exact instruction address and file level, respectively.</p>

<p>There is a useful option for the memory profile â€“ you can look at it right in the browser (provided that you imported net/http/pprof). If you open  http://myserver:6060/debug/pprof/heap?debug=1 you must see the heap profile along the lines of:</p>

<p>01
heap profile: 4: 266528 [123: 11284472] @ heap/1048576
02
1: 262144 [4: 376832] @ 0x28d9f 0x2a201 0x2a28a 0x2624d 0x26188 0x94ca3 0x94a0b 0x17add6 0x17ae9f 0x1069d3 0xfe911 0xf0a3e 0xf0d22 0x21a70
03</p>
<h1 id="0x2a201----cnew0xc1----runtimemallocgoc718">0x2a201    cnew+0xc1    runtime/malloc.goc:718</h1>
<p>04</p>
<h1 id="0x2a28a----runtimecnewarray0x3a------------runtimemallocgoc731">0x2a28a    runtime.cnewarray+0x3a            runtime/malloc.goc:731</h1>
<p>05</p>
<h1 id="0x2624d----makeslice10x4d----------------runtimeslicec57">0x2624d    makeslice1+0x4d                runtime/slice.c:57</h1>
<p>06</p>
<h1 id="0x26188----runtimemakeslice0x98------------runtimeslicec38">0x26188    runtime.makeslice+0x98            runtime/slice.c:38</h1>
<p>07</p>
<h1 id="0x94ca3----bytesmakeslice0x63------------bytesbuffergo191">0x94ca3    bytes.makeSlice+0x63            bytes/buffer.go:191</h1>
<p>08</p>
<h1 id="0x94a0b----bytesbufferreadfrom0xcb--------bytesbuffergo163">0x94a0b    bytes.(*Buffer).ReadFrom+0xcb        bytes/buffer.go:163</h1>
<p>09</p>
<h1 id="0x17add6----ioioutilreadall0x156------------ioioutilioutilgo32">0x17add6    io/ioutil.readAll+0x156            io/ioutil/ioutil.go:32</h1>
<p>10</p>
<h1 id="0x17ae9f----ioioutilreadall0x3f------------ioioutilioutilgo41">0x17ae9f    io/ioutil.ReadAll+0x3f            io/ioutil/ioutil.go:41</h1>
<p>11</p>
<h1 id="0x1069d3----godocvfsreadfile0x133------------godocvfsvfsgo44">0x1069d3    godoc/vfs.ReadFile+0x133            godoc/vfs/vfs.go:44</h1>
<p>12</p>
<h1 id="0xfe911----godocfunc0230x471------------godocmetago80">0xfe911    godoc.funcÂ·023+0x471            godoc/meta.go:80</h1>
<p>13</p>
<h1 id="0xf0a3e----godoccorpusupdatemetadata0x9e--------godocmetago101">0xf0a3e    godoc.(*Corpus).updateMetadata+0x9e        godoc/meta.go:101</h1>
<p>14</p>
<h1 id="0xf0d22----godoccorpusrefreshmetadataloop0x42----godocmetago141">0xf0d22    godoc.(*Corpus).refreshMetadataLoop+0x42    godoc/meta.go:141</h1>
<p>15</p>

<p>16
2: 4096 [2: 4096] @ 0x28d9f 0x29059 0x1d252 0x1d450 0x106993 0xf1225 0xe1489 0xfbcad 0x21a70
17</p>
<h1 id="0x1d252----newdefer0x112----------------runtimepanicc49">0x1d252    newdefer+0x112                runtime/panic.c:49</h1>
<p>18</p>
<h1 id="0x1d450----runtimedeferproc0x10------------runtimepanicc132">0x1d450    runtime.deferproc+0x10            runtime/panic.c:132</h1>
<p>19</p>
<h1 id="0x106993----godocvfsreadfile0xf3------------godocvfsvfsgo43">0x106993    godoc/vfs.ReadFile+0xf3            godoc/vfs/vfs.go:43</h1>
<p>20</p>
<h1 id="0xf1225----godoccorpusparsefile0x75--------godocparsergo20">0xf1225    godoc.(*Corpus).parseFile+0x75        godoc/parser.go:20</h1>
<p>21</p>
<h1 id="0xe1489----godoctreebuildernewdirtree0x8e9----godocdirtreesgo108">0xe1489    godoc.(*treeBuilder).newDirTree+0x8e9    godoc/dirtrees.go:108</h1>
<p>22</p>
<h1 id="0xfbcad----godocfunc0020x15d------------godocdirtreesgo100">0xfbcad    godoc.funcÂ·002+0x15d            godoc/dirtrees.go:100</h1>
<p>The numbers in the beginning of each entry (â€œ1: 262144 [4: 376832]â€) represent number of currently live objects, amount of memory occupied by live objects, total number of allocations and amount of memory occupied by all allocations, respectively.</p>

<p>Optimizations are usually application-specific, but here are some common suggestions.</p>

<ol>
  <li>
    <p>Combine objects into larger objects. For example, replace *bytes.Buffer struct member with bytes.Buffer (you can preallocate buffer for writing by calling bytes.Buffer.Grow later). This will reduce number of memory allocations (faster) and also reduce pressure on garbage collector (faster garbage collections).</p>
  </li>
  <li>
    <p>Local variables that escape from their declaration scope get promoted into heap allocations. Compiler generally canâ€™t prove that several variables have the same life time, so it allocates each such variable separately. So you can use the above advise for local variables as well. For example, replace:</p>
  </li>
</ol>

<p>1
for k, v := range m {
2
   k, v := k, v   // copy for capturing by the goroutine
3
   go func() {
4
       // use k and v
5
   }()
6
}
with:</p>

<p>1
for k, v := range m {
2
   x := struct{ k, v string }{k, v}   // copy for capturing by the goroutine
3
   go func() {
4
       // use x.k and x.v
5
   }()
6
}
This replaces two memory allocations with a single allocation. However, this optimization usually negatively affects code readability, so use it reasonably.</p>

<ol>
  <li>A special case of allocation combining is slice array preallocation. If you know a typical size of the slice, you can preallocate a backing array for it as follows:</li>
</ol>

<p>01
type X struct {
02
    buf      []byte
03
    bufArray [16]byte // Buf usually does not grow beyond 16 bytes.
04
}
05</p>

<p>06
func MakeX() *X {
07
    x := &amp;X{}
08
    // Preinitialize buf with the backing array.
09
    x.buf = x.bufArray[:0]
10
    return x
11
}</p>
<ol>
  <li>
    <p>If possible use smaller data types. For example, use int8 instead of int.</p>
  </li>
  <li>
    <p>Objects that do not contain any pointers (note that strings, slices, maps and chans contain implicit pointers), are not scanned by garbage collector. For example, a 1GB byte slice virtually does not affect garbage collection time. So if you remove pointers from actively used objects, it can positively impact garbage collection time. Some possibilities are: replace pointers with indices, split object into two parts one of which does not contain pointers.</p>
  </li>
  <li>
    <p>Use freelists to reuse transient objects and reduce number of allocations. Standard library contains sync.Pool type that allows to reuse the same object several times in between garbage collections. However, be aware that, as any manual memory management scheme, incorrect use of sync.Pool can lead to use-after-free bugs.</p>
  </li>
</ol>

<p>You can also use the Garbage Collector Trace (see below) to get some insights into memory issues.</p>

<p>Blocking Profiler</p>

<p>The blocking profiler shows where goroutine block waiting on synchronization primitives (including timer channels). You can collect it in similar ways as CPU profile: with â€˜go test â€“blockprofileâ€™, with net/http/pprof via http://myserver:6060:/debug/pprof/block or by calling runtime/pprof.Lookup(â€œblockâ€).WriteTo.</p>

<p>But there is significant caveat â€“ the blocking profiler is not enabled by default. â€˜go test â€“blockprofileâ€™ will enable it for you automatically. However, if you use net/http/pprof or runtime/pprof, you need to enable it manually (otherwise the profile will be empty). To enable the blocking profiler call runtime.SetBlockProfileRate. SetBlockProfileRate controls the fraction of goroutine blocking events that are reported in the blocking profile. The profiler aims to sample an average of one blocking event per the specified amount of nanoseconds spent blocked. To include every blocking event in the profile, set the rate to 1.</p>

<p>If a function contains several blocking operations and itâ€™s not obvious which one leads to blocking, use â€“lines flag to pprof.</p>

<p>Note that not all blocking is bad. When a goroutine blocks, the underlying worker thread simply switches to another goroutine. So blocking in the cooperative Go environment is very different from blocking on a mutex in a non-cooperative systems (e.g. typical C++ or Java threading libraries, where blocking leads to thread idling and expensive thread context switches). To give you some feeling, letâ€™s consider some examples.</p>

<p>Blocking on a time.Ticker is usually OK. If a goroutine blocks on a Ticker for 10 seconds, you will see 10 seconds of blocking in the profile, which is perfectly fine. Blocking on sync.WaitGroup is frequently OK. For example, is a task takes 10 seconds, the goroutine waiting on a WaitGroup for completion will account for 10 seconds of blocking in the profile. Blocking on sync.Cond may or may not be OK, depending on the situation. Consumer blocking on a channel suggests slow producers or lack of work. Producer blocking on a channel suggests that consumers are slower, but this is frequently OK. Blocking on a channel-based semaphore shows how much goroutines are gated on the semaphore. Blocking on a sync.Mutex or sync.RWMutex is usually bad. You can use â€“ignore flag to pprof to exclude known uninteresting blocking from a profile during visualization.</p>

<p>Blocking of goroutines can lead to two negative consequences:</p>

<ol>
  <li>
    <p>Program does not scale with processors due to lack of work. Scheduler Trace can help to identify this case.</p>
  </li>
  <li>
    <p>Excessive goroutine blocking/unblocking consumes CPU time. CPU Profiler can help to identify this case (look at the System component).</p>
  </li>
</ol>

<p>Here are some common suggestions that can help to reduce goroutine blocking:</p>

<ol>
  <li>
    <p>Use sufficiently buffered channels in producer-consumer scenarios. Unbuffered channels substantially limit available parallelism in the program.</p>
  </li>
  <li>
    <p>Use sync.RWMutex instead of sync.Mutex for read-mostly workloads. Readers never block other readers in sync.RWMutex, even on implementation level.</p>
  </li>
  <li>
    <p>In some cases itâ€™s possible to remove mutexes entirely by using copy-on-write technique. If the protected data structure is modified infrequently and itâ€™s feasible to make copies of it, then it can be updated as follows:</p>
  </li>
</ol>

<p>01
type Config struct {
02
    Routes   map[string]net.Addr
03
    Backends []net.Addr
04
}
05</p>

<p>06
var config unsafe.Pointer  // actual type is *Config
07</p>

<p>08
// Worker goroutines use this function to obtain the current config.
09
func CurrentConfig() <em>Config {
10
    return (</em>Config)(atomic.LoadPointer(&amp;config))
11
}
12</p>

<p>13
// Background goroutine periodically creates a new Config object
14
// as sets it as current using this function.
15
func UpdateConfig(cfg *Config) {
16
    atomic.StorePointer(&amp;config, unsafe.Pointer(cfg))
17
}
This pattern prevents the writer from blocking readers during update.</p>

<ol>
  <li>Partitioning is another general technique for reducing contention/blocking on shared mutable data structures. Below is an example of how to partition a hashmap:</li>
</ol>

<p>01
type Partition struct {
02
    sync.RWMutex
03
    m map[string]string
04
}
05</p>

<p>06
const partCount = 64
07
var m [partCount]Partition
08</p>

<p>09
func Find(k string) string {
10
    idx := hash(k) % partCount
11
    part := &amp;m[idx]
12
    part.RLock()
13
    v := part.m[k]
14
    part.RUnlock()
15
    return v
16
}</p>

<ol>
  <li>Local caching and batching of updates can help to reduce contention on un-partitionable data structures. Below you can see how to batch sends to a channel:</li>
</ol>

<p>01
const CacheSize = 16
02</p>

<p>03
type Cache struct {
04
    buf [CacheSize]int
05
    pos int
06
}
07</p>

<p>08
func Send(c chan [CacheSize]int, cache *Cache, value int) {
09
    cache.buf[cache.pos] = value
10
    cache.pos++
11
    if cache.pos == CacheSize {
12
        c &lt;- cache.buf
13
        cache.pos = 0
14
    }
15
}
This technique is not limited to channels. It can be used to batch updates to a map, batch allocations, etc.</p>

<ol>
  <li>Use sync.Pool for freelists instead of chan-based or mutex-protected freelists. sync.Pool uses smart techniques internally to reduce blocking.</li>
</ol>

<p>Goroutine Profiler</p>

<p>The goroutine profiler simply gives you current stacks of all live goroutines in the process. It can be handy to debug load balancing issues (see Scheduler Trace section below), or to debug deadlocks.</p>

<p>The profile makes sense only for a running app, so go test does not expose it. You can collect the profile with net/http/pprof via http://myserver:6060:/debug/pprof/goroutine, and visualize it to svg/pdf or by calling runtime/pprof.Lookup(â€œgoroutineâ€).WriteTo. But the most useful way is to type  http://myserver:6060:/debug/pprof/goroutine?debug=2 in your browser, which will give you symbolized stacks similar to what you see when a program crashes.</p>

<p>Note that goroutines in â€œsyscallâ€ state consume an OS thread, other goroutines do not (except for goroutines that called runtime.LockOSThread, which is, unfortunately, not visible in the profile). Note that goroutines in â€œIO waitâ€ state also do not consume threads, they are parked on non-blocking network poller (which uses epoll/kqueue/GetQueuedCompletionStatus to unpark goroutines later).</p>

<p>Garbage Collector Trace</p>

<p>Aside from the profiling tools, there is another kind of tools available â€“ tracers. They allow to trace garbage collections, memory allocator and goroutine scheduler state. To enable the garbage collector (GC) trace, run the program with GODEBUG=gctrace=1 environment variable:</p>

<p>$ GODEBUG=gctrace=1 ./myserver</p>

<p>Then the program will print output similar to the following during execution:</p>

<p>1
gc9(2): 12+1+744+8 us, 2 -&gt; 10 MB, 108615 (593983-485368) objects, 4825/3620/0 sweeps, 0(0) handoff, 6(91) steal, 16/1/0 yields
2
gc10(2): 12+6769+767+3 us, 1 -&gt; 1 MB, 4222 (593983-589761) objects, 4825/0/1898 sweeps, 0(0) handoff, 6(93) steal, 16/10/2 yields
3
gc11(2): 799+3+2050+3 us, 1 -&gt; 69 MB, 831819 (1484009-652190) objects, 4825/691/0 sweeps, 0(0) handoff, 5(105) steal, 16/1/0 yields
Letâ€™s consider the meaning of these numbers. One line per GC is printed. The first number (â€œgc9â€) is the number of GC (this is the 9-th GC since program start). The number in parens (â€œ(2)â€) is the number of worker threads participated in the GC. The next 4 numbers (â€œ12+1+744+8 usâ€) mean stop-the-world, sweeping, marking and waiting for worker threads to finish, in microseconds, respectively. The next 2 numbers (â€œ2 -&gt; 10 MBâ€) mean size of live heap after the previous GC and full heap size (including garbage) before the current GC. The next 3 numbers (â€œ108615 (593983-485368) objectsâ€) are total number of objects in heap (including garbage) and total number of memory allocation and free operations. The next 3 numbers (â€œ4825/3620/0 sweepsâ€) characterize sweep phase (of the previous GC): there were total 4825 memory spans, 3620 were swept on demand or in background, 0 were swept during stop-the-world phase (the rest were unused spans). The next 4 numbers (â€œ0(0) handoff, 6(91) stealâ€) characterize load balancing during parallel mark phase: there were 0 object handoff operations (0 objects were handoff), and 6 steal operations (91 objects were stolen). The last 3 numbers (â€œ16/1/0 yieldsâ€) characterize effectiveness of parallel mark phase: there were total of 17 yield operations during waiting for another thread.</p>

<p>The GC is mark-and-sweep type. Total GC can be expressed as:</p>

<p>Tgc = Tseq + Tmark + Tsweep</p>

<p>where Tseq is time to stop user goroutines and some preparation activities (usually small); Tmark is heap marking time, marking happens when all user goroutines are stopped, and thus can significantly affect latency of processing; Tsweep is heap sweeping time, sweeping generally happens concurrently with normal program execution, and so is not so critical for latency.</p>

<p>Marking time can be approximately expressed as:</p>

<p>Tmark = C1<em>Nlive + C2</em>MEMlive_ptr + C3*Nlive_ptr</p>

<p>where Nlive is the number of live objects in the heap during GC, MEMlive_ptr is the amount of memory occupied by live objects with pointers, Nlive_ptr is the number of pointers in live objects.</p>

<p>Sweeping time can be approximately expressed as:</p>

<p>Tsweep = C4<em>MEMtotal + C5</em>MEMgarbage</p>

<p>where MEMtotal is the total amount of heap memory, MEMgarbage is the amount of garbage in the heap.</p>

<p>Next GC happens after the program has allocated an extra amount of memory proportional to the amount already in use. The proportion is controlled by GOGC environment variable (100 by default). If GOGC=100 and the program is using 4M of heap memory, runtime will trigger GC again when the program gets to 8M. This keeps the GC cost in linear proportion to the allocation cost. Adjusting GOGC changes the linear constant and also the amount of extra memory used.</p>

<p>Only sweeping depends on total size of the heap, and sweeping happens concurrently with normal program execution. So it can make sense to set GOGC to a higher value (200, 300, 500, etc) if you can afford extra memory consumption. For example, GOGC=300 can reduce garbage collection overhead by up to 2 times while keeping latencies the same (at the cost of 2 times larger heap).</p>

<p>GC is parallel and generally scales well with hardware parallelism. So it can make sense to set GOMAXPROCS to higher value even for sequential programs just to speed up garbage collections. However, note that number of garbage collector threads is currently bounded by 8.</p>

<p>Memory Allocator Trace</p>

<p>Memory allocator traces simply dumps all memory allocation and free operations onto console. Itâ€™s enabled with GODEBUG=allocfreetrace=1 environment variable. The output looks along the lines of:</p>

<p>01
tracealloc(0xc208062500, 0x100, array of parse.Node)
02
goroutine 16 [running]:
03
runtime.mallocgc(0x100, 0x3eb7c1, 0x0)
04
    runtime/malloc.goc:190 +0x145 fp=0xc2080b39f8
05
runtime.growslice(0x31f840, 0xc208060700, 0x8, 0x8, 0x1, 0x0, 0x0, 0x0)
06
    runtime/slice.goc:76 +0xbb fp=0xc2080b3a90
07
text/template/parse.(*Tree).parse(0xc2080820e0, 0xc208023620, 0x0, 0x0)
08
    text/template/parse/parse.go:289 +0x549 fp=0xc2080b3c50
09
â€¦
10</p>

<p>11
tracefree(0xc208002d80, 0x120)
12
goroutine 16 [running]:
13
runtime.MSpan_Sweep(0x73b080)
14
       runtime/mgc0.c:1880 +0x514 fp=0xc20804b8f0
15
runtime.MCentral_CacheSpan(0x69c858)
16
       runtime/mcentral.c:48 +0x2b5 fp=0xc20804b920
17
runtime.MCache_Refill(0x737000, 0xc200000012)
18
       runtime/mcache.c:78 +0x119 fp=0xc20804b950
19
â€¦
The trace contains address of the memory block, size, type, goroutine id and the stack trace.</p>

<p>Itâ€™s probably more useful for debugging, but can give very fine-grained info for allocation optimizations as well.</p>

<p>Scheduler Trace</p>

<p>Scheduler trace can provide insights into dynamic behavior of the goroutine scheduler and allow to debug load balancing and scalability issues. To enable the scheduler trace trace, run the program with GODEBUG=schedtrace=1000 environment variable (the value means period of output, in ms, in this case itâ€™s once per second):</p>

<p>$ GODEBUG=schedtrace=1000 ./myserver</p>

<p>Then the program will print output similar to the following during execution:</p>

<p>1
SCHED 1004ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=4 runqueue=8 [0 1 0 3]
2
SCHED 2005ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=5 runqueue=6 [1 5 4 0]
3
SCHED 3008ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=4 runqueue=10 [2 2 2 1]
The first number (â€œ1004msâ€) is time since program start. Gomaxprocs is the current value of GOMAXPROCS. Idleprocs is the number of idling processors (the rest are executing Go code). Threads is the total number of worker threads created by the scheduler (threads can be in 3 states: execute Go code (gomaxprocs-idleprocs), execute syscalls/cgocalls or idle). Idlethreads is the number of idling worker threads. Runqueue is the length of global queue with runnable goroutines. The numbers in square brackets (â€œ[0 1 0 3]â€) are lengths of per-processor queues with runnable goroutines. Sum of lengths of global and local queues represents the total number of goroutines available for execution.</p>

<p>Note: You can combine any of the tracers as GODEBUG=gctrace=1,allocfreetrace=1,schedtrace=1000.</p>

<p>Note: There is also detailed scheduler trace, which you can enable with GODEBUG=schedtrace=1000,scheddetail=1. It prints detailed info about every goroutine, worker thread and processor. We wonâ€™t describe its format here as itâ€™s mainly useful for scheduler developers; but you can find details in src/pkg/runtime/proc.c.</p>

<p>The scheduler trace is useful when a program does not scale linearly with GOMAXPROCS and/or does not consume 100% of CPU time. The ideal situation is when all processors are busy executing Go code, number of threads is reasonable, there is plenty of work in all queues and the work is reasonably evenly distributed:</p>

<p>gomaxprocs=8 idleprocs=0 threads=40 idlethreads=5 runqueue=10 [20 20 20 20 20 20 20 20]</p>

<p>A bad situation is when something of the above does not hold. For example the following sample demonstrates shortage of work to keep all processors busy:</p>

<p>gomaxprocs=8 idleprocs=6 threads=40 idlethreads=30 runqueue=0 [0 2 0 0 0 1 0 0]</p>

<p>Note: use OS-provided means to measure actual CPU utilization as the ultimate characteristic. On Unix family of operating system it is top command; on Windows it is Task Manager.</p>

<p>You can use the goroutine profiler to understand where goroutines block in the case of work shortage. Note that load imbalance is not ultimately bad as long as all processors are busy, it will just cause some moderate load balancing overheads.</p>

<p>Memory Statistics</p>

<p>Go runtime exposes coarse-grained memory statistics via runtime.ReadMemStats function. The statistics are also exposed via net/http/pprof at the bottom of  http://myserver:6060/debug/pprof/heap?debug=1. The statistics are described here.</p>

<p>Some of the interesting fields are:</p>

<ol>
  <li>
    <p>HeapAlloc - current heap size.</p>
  </li>
  <li>
    <p>HeapSys - total heap size.</p>
  </li>
  <li>
    <p>HeapObjects - total number of objects in the heap.</p>
  </li>
  <li>
    <p>HeapReleased - amount of memory released to the OS; runtime releases to the OS memory unused for 5 minutes, you can force this process with runtime/debug.FreeOSMemory.</p>
  </li>
  <li>
    <p>Sys - total amount of memory allocated from OS.</p>
  </li>
  <li>
    <p>Sys-HeapReleased - effective memory consumption of the program.</p>
  </li>
  <li>
    <p>StackSys - memory consumed for goroutine stacks (note that some stacks are allocated from heap and are not accounted here, unfortunately there is no way to get total size of stacks (https://code.google.com/p/go/issues/detail?id=7468)).</p>
  </li>
  <li>
    <p>MSpanSys/MCacheSys/BuckHashSys/GCSys/OtherSys - amount of memory allocated by runtime for various auxiliary purposes; they are generally not interesting, unless they are too high.</p>
  </li>
  <li>
    <p>PauseNs - durations of last garbage collections.</p>
  </li>
</ol>

<p>Heap Dumper</p>

<p>The last available tool is heap dumper, it can write state of the whole heap into a file for future exploration. It can be useful for identifying memory leaks and getting insights into program memory consumption.</p>

<p>First, you need to write the dump using runtime/debug.WriteHeapDump function:</p>

<p>1
f, err := os.Create(â€œheapdumpâ€)
2
if err != nil { â€¦ }
3
debug.WriteHeapDump(f.Fd())
Then you can either render it to a dot file with graphical representation of the heap or convert it to hprof format. To render it to a dot file:</p>

<p>$ go get github.com/randall77/hprof/dumptodot</p>

<p>$ dumptodot heapdump mybinary &gt; heap.dot</p>

<p>and open heap.dot with Graphviz.</p>

<p>To convert it to hprof format:</p>

<p>$ go get github.com/randall77/hprof/dumptohprof</p>

<p>$ dumptohprof heapdump heap.hprof</p>

<p>$ jhat heap.hprof</p>

<p>and navigate your browser to http://localhost:7000.</p>

<p>Concluding Remarks</p>

<p>Optimization is an open problem, there are simple recipes that you can use to improve performance. Sometimes optimization requires complete re-architecture of the program. But we hope that the tools will be a valuable addition to your toolbox, that you can use to at least analyze and understand what happens.</p>

<p>Profiling Go Programs is a good tutorial on usage of CPU and memory profilers to optimize a simple program.</p>

<p>å½“ä½ çš„golangç¨‹åºåœ¨è¿è¡Œè¿‡ç¨‹ä¸­æ¶ˆè€—äº†è¶…å‡ºä½ ç†è§£çš„å†…å­˜æ—¶ï¼Œä½ å°±éœ€è¦ææ˜ç™½ï¼Œåˆ°åº•æ˜¯ ç¨‹åºä¸­å“ªäº›ä»£ç å¯¼è‡´äº†è¿™äº›å†…å­˜æ¶ˆè€—ã€‚æ­¤æ—¶golangç¼–è¯‘å¥½çš„ç¨‹åºå¯¹ä½ æ¥è¯´æ˜¯ä¸ªé»‘ç›’ï¼Œè¯¥ å¦‚ä½•ææ¸…å…¶ä¸­çš„å†…å­˜ä½¿ç”¨å‘¢ï¼Ÿå¹¸å¥½golangå·²ç»å†…ç½®äº†ä¸€äº›æœºåˆ¶æ¥å¸®åŠ©æˆ‘ä»¬è¿›è¡Œåˆ†æå’Œè¿½ è¸ªã€‚</p>

<p>æ­¤æ—¶ï¼Œé€šå¸¸æˆ‘ä»¬å¯ä»¥é‡‡ç”¨golangçš„pprofæ¥å¸®åŠ©æˆ‘ä»¬åˆ†ægolangè¿›ç¨‹çš„å†…å­˜ä½¿ç”¨ã€‚</p>

<p>pprof å®ä¾‹
é€šå¸¸æˆ‘ä»¬é‡‡ç”¨http apiæ¥å°†pprofä¿¡æ¯æš´éœ²å‡ºæ¥ä»¥ä¾›åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨net/http/pprof è¿™ä¸ªpackageã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼š</p>

<p>// pprof çš„initå‡½æ•°ä¼šå°†pprofé‡Œçš„ä¸€äº›handleræ³¨å†Œåˆ°http.DefaultServeMuxä¸Š
// å½“ä¸ä½¿ç”¨http.DefaultServeMuxæ¥æä¾›http apiæ—¶ï¼Œå¯ä»¥æŸ¥é˜…å…¶initå‡½æ•°ï¼Œè‡ªå·±æ³¨å†Œhandler
import _ â€œnet/http/pprofâ€</p>

<p>go func() {
    http.ListenAndServe(â€œ0.0.0.0:8080â€, nil)
}()
æ­¤æ—¶æˆ‘ä»¬å¯ä»¥å¯åŠ¨è¿›ç¨‹ï¼Œç„¶åè®¿é—®http://localhost:8080/debug/pprof/å¯ä»¥çœ‹åˆ°ä¸€ä¸ªç®€å•çš„ é¡µé¢ï¼Œé¡µé¢ä¸Šæ˜¾ç¤º: æ³¨æ„: ä»¥ä¸‹çš„å…¨éƒ¨æ•°æ®ï¼ŒåŒ…æ‹¬go tool pprof é‡‡é›†åˆ°çš„æ•°æ®éƒ½ä¾èµ–è¿›ç¨‹ä¸­çš„pprofé‡‡æ ·ç‡ï¼Œé»˜è®¤512kbè¿›è¡Œ ä¸€æ¬¡é‡‡æ ·ï¼Œå½“æˆ‘ä»¬è®¤ä¸ºæ•°æ®ä¸å¤Ÿç»†è‡´æ—¶ï¼Œå¯ä»¥è°ƒèŠ‚é‡‡æ ·ç‡runtime.MemProfileRateï¼Œä½†æ˜¯é‡‡æ ·ç‡è¶Šä½ï¼Œè¿› ç¨‹è¿è¡Œé€Ÿåº¦è¶Šæ…¢ã€‚</p>

<p>/debug/pprof/</p>

<p>profiles:
0         block
136840    goroutine
902       heap
0         mutex
40        threadcreate</p>

<p>full goroutine stack dump
ä¸Šé¢ç®€å•æš´éœ²å‡ºäº†å‡ ä¸ªå†…ç½®çš„Profileç»Ÿè®¡é¡¹ã€‚ä¾‹å¦‚æœ‰136840ä¸ªgoroutineåœ¨è¿è¡Œï¼Œç‚¹å‡»ç›¸å…³é“¾æ¥ å¯ä»¥çœ‹åˆ°è¯¦ç»†ä¿¡æ¯ã€‚</p>

<p>å½“æˆ‘ä»¬åˆ†æå†…å­˜ç›¸å…³çš„é—®é¢˜æ—¶ï¼Œå¯ä»¥ç‚¹å‡»heapé¡¹ï¼Œè¿›å…¥http://127.0.0.1:8080/debug/pprof/heap?debug=1 å¯ä»¥æŸ¥çœ‹å…·ä½“çš„æ˜¾ç¤ºï¼š</p>

<p>heap profile: 3190: 77516056 [54762: 612664248] @ heap/1048576
1: 29081600 [1: 29081600] @ 0x89368e 0x894cd9 0x8a5a9d 0x8a9b7c 0x8af578 0x8b4441 0x8b4c6d 0x8b8504 0x8b2bc3 0x45b1c1</p>
<h1 id="0x89368d----githubcomsyndtrgoleveldbleveldbmemdbdbput0x59d">0x89368d    github.com/syndtr/goleveldb/leveldb/memdb.(*DB).Put+0x59d</h1>
<h1 id="0x894cd8----xxxxxstorageinternalmemtablememtableset0x88">0x894cd8    xxxxx/storage/internal/memtable.(*MemTable).Set+0x88</h1>
<h1 id="0x8a5a9c----xxxxxstoragesnapshotterappendcommitlog0x1cc">0x8a5a9c    xxxxx/storage.(*snapshotter).AppendCommitLog+0x1cc</h1>
<h1 id="0x8a9b7b----xxxxxstoragestoreupdate0x26b">0x8a9b7b    xxxxx/storage.(*store).Update+0x26b</h1>
<h1 id="0x8af577----xxxxxconfigconfigupdate0xa7">0x8af577    xxxxx/config.(*config).Update+0xa7</h1>
<h1 id="0x8b4440----xxxxxnamingnamingupdate0x120">0x8b4440    xxxxx/naming.(*naming).update+0x120</h1>
<h1 id="0x8b4c6c----xxxxxnamingnaminginstancetimeout0x27c">0x8b4c6c    xxxxx/naming.(*naming).instanceTimeout+0x27c</h1>
<h1 id="0x8b8503----xxxxxnamingnamingxxxxxnaminginstancetimeout-fm0x63">0x8b8503    xxxxx/naming.(*naming).(xxxxx/naming.instanceTimeout)-fm+0x63</h1>

<p>â€¦â€¦</p>

<h1 id="runtimememstats">runtime.MemStats</h1>
<h1 id="alloc--2463648064">Alloc = 2463648064</h1>
<h1 id="totalalloc--31707239480">TotalAlloc = 31707239480</h1>
<h1 id="sys--4831318840">Sys = 4831318840</h1>
<h1 id="lookups--2690464">Lookups = 2690464</h1>
<h1 id="mallocs--274619648">Mallocs = 274619648</h1>
<h1 id="frees--262711312">Frees = 262711312</h1>
<h1 id="heapalloc--2463648064">HeapAlloc = 2463648064</h1>
<h1 id="heapsys--3877830656">HeapSys = 3877830656</h1>
<h1 id="heapidle--854990848">HeapIdle = 854990848</h1>
<h1 id="heapinuse--3022839808">HeapInuse = 3022839808</h1>
<h1 id="heapreleased--0">HeapReleased = 0</h1>
<h1 id="heapobjects--11908336">HeapObjects = 11908336</h1>
<h1 id="stack--655949824--655949824">Stack = 655949824 / 655949824</h1>
<h1 id="mspan--63329432--72040448">MSpan = 63329432 / 72040448</h1>
<h1 id="mcache--38400--49152">MCache = 38400 / 49152</h1>
<h1 id="buckhashsys--1706593">BuckHashSys = 1706593</h1>
<h1 id="gcsys--170819584">GCSys = 170819584</h1>
<h1 id="othersys--52922583">OtherSys = 52922583</h1>
<h1 id="nextgc--3570699312">NextGC = 3570699312</h1>
<h1 id="pausens--1052815-217503-208124-233034-1146462-456882-1098525-530706-551702-419372-768322-596273-387826-455807-563621-587849-416204-599143-572823-488681-701731-656358-2476770-12141392-5827253-3508261-1715582-1295487-908563-788435-718700-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0">PauseNs = [1052815 217503 208124 233034 1146462 456882 1098525 530706 551702 419372 768322 596273 387826 455807 563621 587849 416204 599143 572823 488681 701731 656358 2476770 12141392 5827253 3508261 1715582 1295487 908563 788435 718700 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</h1>
<h1 id="numgc--31">NumGC = 31</h1>
<h1 id="debuggc--false">DebugGC = false</h1>
<p>å…¶ä¸­æ˜¾ç¤ºçš„å†…å®¹ä¼šæ¯”è¾ƒå¤šï¼Œä½†æ˜¯ä¸»ä½“åˆ†ä¸º2ä¸ªéƒ¨åˆ†: ç¬¬ä¸€ä¸ªéƒ¨åˆ†æ‰“å°ä¸ºé€šè¿‡runtime.MemProfile()è·å–çš„runtime.MemProfileRecordè®°å½•ã€‚ å…¶å«ä¹‰ä¸ºï¼š</p>

<p>heap profile: 3190(inused objects): 77516056(inused bytes) [54762(alloc objects): 612664248(alloc bytes)] @ heap/1048576(2*MemProfileRate)
1: 29081600 [1: 29081600] (å‰é¢4ä¸ªæ•°è·Ÿç¬¬ä¸€è¡Œçš„ä¸€æ ·ï¼Œæ­¤è¡Œä»¥åæ˜¯æ¯æ¬¡è®°å½•çš„ï¼Œåé¢çš„åœ°å€æ˜¯è®°å½•ä¸­çš„æ ˆæŒ‡é’ˆ)@ 0x89368e 0x894cd9 0x8a5a9d 0x8a9b7c 0x8af578 0x8b4441 0x8b4c6d 0x8b8504 0x8b2bc3 0x45b1c1</p>
<h1 id="0x89368d----githubcomsyndtrgoleveldbleveldbmemdbdbput0x59d-æ ˆä¿¡æ¯">0x89368d    github.com/syndtr/goleveldb/leveldb/memdb.(*DB).Put+0x59d æ ˆä¿¡æ¯</h1>
<p>ç¬¬äºŒéƒ¨åˆ†å°±æ¯”è¾ƒå¥½ç†è§£ï¼Œæ‰“å°çš„æ˜¯é€šè¿‡runtime.ReadMemStats()è¯»å–çš„runtime.MemStatsä¿¡æ¯ã€‚ æˆ‘ä»¬å¯ä»¥é‡ç‚¹å…³æ³¨ä¸€ä¸‹</p>

<p>Sys è¿›ç¨‹ä»ç³»ç»Ÿè·å¾—çš„å†…å­˜ç©ºé—´ï¼Œè™šæ‹Ÿåœ°å€ç©ºé—´ã€‚
HeapAlloc è¿›ç¨‹å †å†…å­˜åˆ†é…ä½¿ç”¨çš„ç©ºé—´ï¼Œé€šå¸¸æ˜¯ç”¨æˆ·newå‡ºæ¥çš„å †å¯¹è±¡ï¼ŒåŒ…å«æœªè¢«gcæ‰çš„ã€‚
HeapSys è¿›ç¨‹ä»ç³»ç»Ÿè·å¾—çš„å †å†…å­˜ï¼Œå› ä¸ºgolangåº•å±‚ä½¿ç”¨TCmallocæœºåˆ¶ï¼Œä¼šç¼“å­˜ä¸€éƒ¨åˆ†å †å†…å­˜ï¼Œè™šæ‹Ÿåœ°å€ç©ºé—´ã€‚
PauseNs è®°å½•æ¯æ¬¡gcæš‚åœçš„æ—¶é—´(çº³ç§’)ï¼Œæœ€å¤šè®°å½•256ä¸ªæœ€æ–°è®°å½•ã€‚
NumGC è®°å½•gcå‘ç”Ÿçš„æ¬¡æ•°ã€‚
ç›¸ä¿¡ï¼Œå¯¹pprofä¸äº†è§£çš„ç”¨æˆ·çœ‹äº†ä»¥ä¸Šå†…å®¹ï¼Œå¾ˆéš¾è·å¾—æ›´å¤šçš„æœ‰ç”¨ä¿¡æ¯ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦å¼•ç”¨æ›´å¤šå·¥å…·æ¥å¸®åŠ© æˆ‘ä»¬æ›´åŠ ç®€å•çš„è§£è¯»pprofå†…å®¹ã€‚</p>

<p>go tool
æˆ‘ä»¬å¯ä»¥é‡‡ç”¨go tool pprof -inuse_space http://127.0.0.1:8080/debug/pprof/heapå‘½ä»¤è¿æ¥åˆ°è¿›ç¨‹ä¸­ æŸ¥çœ‹æ­£åœ¨ä½¿ç”¨çš„ä¸€äº›å†…å­˜ç›¸å…³ä¿¡æ¯ï¼Œæ­¤æ—¶æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå¯ä»¥äº¤äº’çš„å‘½ä»¤è¡Œã€‚</p>

<p>æˆ‘ä»¬å¯ä»¥çœ‹æ•°æ®top10æ¥æŸ¥çœ‹æ­£åœ¨ä½¿ç”¨çš„å¯¹è±¡è¾ƒå¤šçš„10ä¸ªå‡½æ•°å…¥å£ã€‚é€šå¸¸ç”¨æ¥æ£€æµ‹æœ‰æ²¡æœ‰ä¸ç¬¦åˆé¢„æœŸçš„å†…å­˜ å¯¹è±¡å¼•ç”¨ã€‚</p>

<p>(pprof) top10
1355.47MB of 1436.26MB total (94.38%)
Dropped 371 nodes (cum &lt;= 7.18MB)
Showing top 10 nodes out of 61 (cum &gt;= 23.50MB)
      flat  flat%   sum%        cum   cum%
  512.96MB 35.71% 35.71%   512.96MB 35.71%  net/http.newBufioWriterSize
  503.93MB 35.09% 70.80%   503.93MB 35.09%  net/http.newBufioReader
  113.04MB  7.87% 78.67%   113.04MB  7.87%  runtime.rawstringtmp
   55.02MB  3.83% 82.50%    55.02MB  3.83%  runtime.malg
   45.01MB  3.13% 85.64%    45.01MB  3.13%  xxxxx/storage.(<em>Node).clone
   26.50MB  1.85% 87.48%    52.50MB  3.66%  context.WithCancel
   25.50MB  1.78% 89.26%    83.58MB  5.82%  runtime.systemstack
   25.01MB  1.74% 91.00%    58.51MB  4.07%  net/http.readRequest
      25MB  1.74% 92.74%    29.03MB  2.02%  runtime.mapassign
   23.50MB  1.64% 94.38%    23.50MB  1.64%  net/http.(</em>Server).newConn
ç„¶åæˆ‘ä»¬åœ¨ç”¨go tool pprof -alloc_space http://127.0.0.1:8080/debug/pprof/heapå‘½ä»¤é“¾æ¥ç¨‹åºæ¥æŸ¥çœ‹ å†…å­˜å¯¹è±¡åˆ†é…çš„ç›¸å…³æƒ…å†µã€‚ç„¶åè¾“å…¥topæ¥æŸ¥çœ‹ç´¯ç§¯åˆ†é…å†…å­˜è¾ƒå¤šçš„ä¸€äº›å‡½æ•°è°ƒç”¨:</p>

<p>(pprof) top
523.38GB of 650.90GB total (80.41%)
Dropped 342 nodes (cum &lt;= 3.25GB)
Showing top 10 nodes out of 106 (cum &gt;= 28.02GB)
      flat  flat%   sum%        cum   cum%
  147.59GB 22.68% 22.68%   147.59GB 22.68%  runtime.rawstringtmp
  129.23GB 19.85% 42.53%   129.24GB 19.86%  runtime.mapassign
   48.23GB  7.41% 49.94%    48.23GB  7.41%  bytes.makeSlice
   46.25GB  7.11% 57.05%    71.06GB 10.92%  encoding/json.Unmarshal
   31.41GB  4.83% 61.87%   113.86GB 17.49%  net/http.readRequest
   30.55GB  4.69% 66.57%   171.20GB 26.30%  net/http.(*conn).readRequest
   22.95GB  3.53% 70.09%    22.95GB  3.53%  net/url.parse
   22.70GB  3.49% 73.58%    22.70GB  3.49%  runtime.stringtoslicebyte
   22.70GB  3.49% 77.07%    22.70GB  3.49%  runtime.makemap
   21.75GB  3.34% 80.41%    28.02GB  4.31%  context.WithCancel
å¯ä»¥çœ‹å‡ºstring-[]byteç›¸äº’è½¬æ¢ã€åˆ†é…mapã€bytes.makeSliceã€encoding/json.Unmarshalç­‰è°ƒç”¨ç´¯ç§¯åˆ†é…çš„å†…å­˜è¾ƒå¤šã€‚ æ­¤æ—¶æˆ‘ä»¬å°±å¯ä»¥reviewä»£ç ï¼Œå¦‚ä½•å‡å°‘è¿™äº›ç›¸å…³çš„è°ƒç”¨ï¼Œæˆ–è€…ä¼˜åŒ–ç›¸å…³ä»£ç é€»è¾‘ã€‚</p>

<p>å½“æˆ‘ä»¬ä¸æ˜ç¡®è¿™äº›è°ƒç”¨æ—¶æ˜¯è¢«å“ªäº›å‡½æ•°å¼•èµ·çš„æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥è¾“å…¥top -cumæ¥æŸ¥æ‰¾ï¼Œ-cumçš„æ„æ€å°±æ˜¯ï¼Œå°†å‡½æ•°è°ƒç”¨å…³ç³» ä¸­çš„æ•°æ®è¿›è¡Œç´¯ç§¯ï¼Œæ¯”å¦‚Aå‡½æ•°è°ƒç”¨çš„Bå‡½æ•°ï¼Œåˆ™Bå‡½æ•°ä¸­çš„å†…å­˜åˆ†é…é‡ä¹Ÿä¼šç´¯ç§¯åˆ°Aä¸Šé¢ï¼Œè¿™æ ·å°±å¯ä»¥å¾ˆå®¹æ˜“çš„æ‰¾å‡ºè°ƒç”¨é“¾ã€‚</p>

<p>(pprof) top20 -cum
322890.40MB of 666518.53MB total (48.44%)
Dropped 342 nodes (cum &lt;= 3332.59MB)
Showing top 20 nodes out of 106 (cum &gt;= 122316.23MB)
      flat  flat%   sum%        cum   cum%
         0     0%     0% 643525.16MB 96.55%  runtime.goexit
 2184.63MB  0.33%  0.33% 620745.26MB 93.13%  net/http.(<em>conn).serve
         0     0%  0.33% 435300.50MB 65.31%  xxxxx/api/server.(</em>HTTPServer).ServeHTTP
 5865.22MB  0.88%  1.21% 435300.50MB 65.31%  xxxxx/api/server/router.(<em>httpRouter).ServeHTTP
         0     0%  1.21% 433121.39MB 64.98%  net/http.serverHandler.ServeHTTP
         0     0%  1.21% 430456.29MB 64.58%  xxxxx/api/server/filter.(</em>chain).Next
   43.50MB 0.0065%  1.21% 429469.71MB 64.43%  xxxxx/api/server/filter.TransURLTov1
         0     0%  1.21% 346440.39MB 51.98%  xxxxx/api/server/filter.Role30x
31283.56MB  4.69%  5.91% 175309.48MB 26.30%  net/http.(<em>conn).readRequest
         0     0%  5.91% 153589.85MB 23.04%  github.com/julienschmidt/httprouter.(</em>Router).ServeHTTP
         0     0%  5.91% 153589.85MB 23.04%  github.com/julienschmidt/httprouter.(<em>Router).ServeHTTP-fm
         0     0%  5.91% 153540.85MB 23.04%  xxxxx/api/server/router.(</em>httpRouter).Register.func1
       2MB 0.0003%  5.91% 153117.78MB 22.97%  xxxxx/api/server/filter.Validate
151134.52MB 22.68% 28.58% 151135.02MB 22.68%  runtime.rawstringtmp
         0     0% 28.58% 150714.90MB 22.61%  xxxxx/api/server/router/naming/v1.(<em>serviceRouter).(git.intra.weibo.com/platform/vintage/api/server/router/naming/v1.service)-fm
         0     0% 28.58% 150714.90MB 22.61%  xxxxx/api/server/router/naming/v1.(</em>serviceRouter).service
         0     0% 28.58% 141200.76MB 21.18%  net/http.Redirect
132334.96MB 19.85% 48.44% 132342.95MB 19.86%  runtime.mapassign
      42MB 0.0063% 48.44% 125834.16MB 18.88%  xxxxx/api/server/router/naming/v1.heartbeat
         0     0% 48.44% 122316.23MB 18.35%  xxxxxx/config.(*config).Lookup
å¦‚ä¸Šæ‰€ç¤ºï¼Œæˆ‘ä»¬å°±å¾ˆå®¹æ˜“çš„æŸ¥æ‰¾åˆ°è¿™äº›å‡½æ•°æ˜¯è¢«å“ªäº›å‡½æ•°è°ƒç”¨çš„ã€‚</p>

<p>æ ¹æ®ä»£ç çš„è°ƒç”¨å…³ç³»ï¼Œfilter.TransURLTov1ä¼šè°ƒç”¨filter.Role30xï¼Œä½†æ˜¯ä»–ä»¬ä¹‹é—´çš„cum%å·®å€¼æœ‰12.45%ï¼Œå› æ­¤ æˆ‘ä»¬å¯ä»¥å¾—çŸ¥filter.TransURLTov1å†…éƒ¨è‡ªå·±ç›´æ¥åˆ†é…çš„å†…å­˜é‡è¾¾åˆ°äº†æ•´ä¸ªè¿›ç¨‹åˆ†é…å†…å­˜æ€»é‡çš„12.45%ï¼Œè¿™å¯æ˜¯ä¸€ä¸ª å€¼å¾—å¤§å¤§ä¼˜åŒ–çš„åœ°æ–¹ã€‚</p>

<p>ç„¶åæˆ‘ä»¬å¯ä»¥è¾“å…¥å‘½ä»¤webï¼Œå…¶ä¼šç»™æˆ‘ä»¬çš„æµè§ˆå™¨å¼¹å‡ºä¸€ä¸ª.svgå›¾ç‰‡ï¼Œå…¶ä¼šæŠŠè¿™äº›ç´¯ç§¯å…³ç³»ç”»æˆä¸€ä¸ªæ‹“æ‰‘å›¾ï¼Œæä¾›ç»™ æˆ‘ä»¬ã€‚æˆ–è€…ç›´æ¥æ‰§è¡Œgo tool pprof -alloc_space -cum -svg http://127.0.0.1:8080/debug/pprof/heap &gt; heap.svgæ¥ç”Ÿ æˆheap.svgå›¾ç‰‡ã€‚</p>

<p>ä¸‹é¢æˆ‘ä»¬å–ä¸€ä¸ªå›¾ç‰‡ä¸­çš„ä¸€ä¸ªç‰‡æ®µè¿›è¡Œåˆ†æ:</p>

<p>golang-memory-pprof.png</p>

<p>æ¯ä¸€ä¸ªæ–¹å—ä¸ºpprofè®°å½•çš„ä¸€ä¸ªå‡½æ•°è°ƒç”¨æ ˆï¼ŒæŒ‡å‘æ–¹å—çš„ç®­å¤´ä¸Šçš„æ•°å­—æ˜¯è®°å½•çš„è¯¥æ ˆç´¯ç§¯åˆ†é…çš„å†…å­˜å‘ï¼Œä»æ–¹å—æŒ‡å‡ºçš„ ç®­å¤´ä¸Šçš„æ•°å­—ä¸ºè¯¥å‡½æ•°è°ƒç”¨çš„å…¶ä»–å‡½æ•°ç´¯ç§¯åˆ†é…çš„å†…å­˜ã€‚ä»–ä»¬ä¹‹é—´çš„å·®å€¼å¯ä»¥ç®€å•ç†è§£ä¸ºæœ¬å‡½æ•°é™¤è°ƒç”¨å…¶ä»–å‡½æ•°å¤–ï¼Œè‡ª èº«åˆ†é…çš„ã€‚æ–¹å—å†…éƒ¨çš„æ•°å­—ä¹Ÿä½“ç°äº†è¿™ä¸€ç‚¹ï¼Œå…¶æ•°å­—ä¸º:(è‡ªèº«åˆ†é…çš„å†…å­˜ of è¯¥å‡½æ•°ç´¯ç§¯åˆ†é…çš„å†…å­˜)ã€‚</p>

<p>â€“inuse/alloc_space â€“inuse/alloc_objectsåŒºåˆ«
é€šå¸¸æƒ…å†µä¸‹ï¼š</p>

<p>ç”¨â€“inuse_spaceæ¥åˆ†æç¨‹åºå¸¸é©»å†…å­˜çš„å ç”¨æƒ…å†µ;
ç”¨â€“alloc_objectsæ¥åˆ†æå†…å­˜çš„ä¸´æ—¶åˆ†é…æƒ…å†µï¼Œå¯ä»¥æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ã€‚
go-torch
é™¤äº†ç›´æ¥ä½¿ç”¨go tool pprofå¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ›´åŠ ç›´è§‚äº†ç«ç„°å›¾ ã€‚å› æ­¤æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨go-torchæ¥ç”Ÿæˆgolangç¨‹åºçš„ç«ç„°å›¾ï¼Œè¯¥å·¥å…·ä¹Ÿç›´æ¥ ä¾èµ–pprof/go tool pprofç­‰ã€‚è¯¥å·¥å…·çš„ç›¸å…³å®‰è£…è¯·çœ‹è¯¥é¡¹ç›®çš„ä»‹ç»ã€‚è¯¥è½¯ä»¶çš„a4daa2b ä»¥åç‰ˆæœ¬æ‰æ”¯æŒå†…å­˜çš„profilingã€‚</p>

<p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨</p>

<p>go-torch -alloc_space http://127.0.0.1:8080/debug/pprof/heap â€“colors=mem
go-torch -inuse_space http://127.0.0.1:8080/debug/pprof/heap â€“colors=mem
æ³¨æ„:-alloc_space/-inuse_spaceå‚æ•°ä¸-u/-bç­‰å‚æ•°æœ‰å†²çªï¼Œä½¿ç”¨äº†-alloc_space/-inuse_spaceåè¯·å°†pprofçš„ èµ„æºç›´æ¥è¿½åŠ åœ¨å‚æ•°åé¢ï¼Œè€Œä¸è¦ä½¿ç”¨-u/-bå‚æ•°å»æŒ‡å®šï¼Œè¿™ä¸go-torchçš„å‚æ•°è§£æé—®é¢˜æœ‰å…³ï¼Œçœ‹è¿‡å…¶æºç åæ—¢èƒ½æ˜ç™½ã€‚ åŒæ—¶è¿˜è¦æ³¨æ„ï¼Œåˆ†æå†…å­˜çš„URLä¸€å®šæ˜¯heapç»“å°¾çš„ï¼Œå› ä¸ºé»˜è®¤è·¯å¾„æ˜¯profileçš„ï¼Œå…¶ç”¨æ¥åˆ†æcpuç›¸å…³é—®é¢˜ã€‚</p>

<p>é€šè¿‡ä¸Šé¢2ä¸ªå‘½ä»¤ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°alloc_space/inuse_spaceå«ä¹‰çš„2ä¸ªç«ç„°å›¾ï¼Œä¾‹å¦‚ alloc_space.svg/inuse_space.svgã€‚ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æµè§ˆå™¨è§‚å¯Ÿè¿™2å¼ å›¾ï¼Œè¿™å¼ å›¾ï¼Œå°±åƒä¸€ä¸ªå±±è„‰çš„æˆªé¢å›¾ï¼Œä»ä¸‹è€Œä¸Šæ˜¯æ¯ä¸ªå‡½æ•°çš„è°ƒç”¨æ ˆï¼Œå› æ­¤å±±çš„é«˜åº¦è·Ÿå‡½æ•° è°ƒç”¨çš„æ·±åº¦æ­£ç›¸å…³ï¼Œè€Œå±±çš„å®½åº¦è·Ÿä½¿ç”¨/åˆ†é…å†…å­˜çš„æ•°é‡æˆæ­£æ¯”ã€‚æˆ‘ä»¬åªéœ€è¦ç•™æ„é‚£äº›å®½è€Œå¹³çš„å±±é¡¶ï¼Œè¿™äº›éƒ¨åˆ†é€šå¸¸æ˜¯æˆ‘ä»¬ éœ€è¦ä¼˜åŒ–çš„åœ°æ–¹ã€‚</p>

<p>testing
å½“æˆ‘ä»¬éœ€è¦å¯¹go testä¸­æŸäº›test/benchmarkè¿›è¡Œprofilingæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç±»ä¼¼çš„æ–¹æ³•ã€‚ä¾‹å¦‚æˆ‘ä»¬å¯ä»¥å…ˆä½¿ç”¨go test å†…ç½®çš„å‚æ•°ç”Ÿæˆpprofæ•°æ®ï¼Œç„¶åå€ŸåŠ©go tool pprof/go-torchæ¥åˆ†æã€‚</p>

<p>ç”Ÿæˆcpuã€memçš„pprofæ–‡ä»¶
go test -bench=BenchmarkStorageXXX -cpuprofile cpu.out -memprofile mem.out
æ­¤æ—¶ä¼šç”Ÿæˆä¸€ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶å’Œ2ä¸ªpprofæ•°æ®æ–‡ä»¶ï¼Œä¾‹å¦‚
storage.test cpu.out mem.out
ç„¶åä½¿ç”¨go-torchæ¥åˆ†æï¼ŒäºŒè¿›åˆ¶æ–‡ä»¶æ”¾å‰é¢
#åˆ†æcpu
go-torch storage.test cpu.out
#åˆ†æå†…å­˜
go-torch â€“colors=mem -alloc_space storage.test mem.out
go-torch â€“colors=mem -inuse_space storage.test mem.out
ä¼˜åŒ–å»ºè®®
Debugging performance issues in Go programs æä¾›äº†ä¸€äº›å¸¸ç”¨çš„ä¼˜åŒ–å»ºè®®:</p>

<p>1 å°†å¤šä¸ªå°å¯¹è±¡åˆå¹¶æˆä¸€ä¸ªå¤§çš„å¯¹è±¡
2 å‡å°‘ä¸å¿…è¦çš„æŒ‡é’ˆé—´æ¥å¼•ç”¨ï¼Œå¤šä½¿ç”¨copyå¼•ç”¨
ä¾‹å¦‚ä½¿ç”¨bytes.Bufferä»£æ›¿*bytes.Bufferï¼Œå› ä¸ºä½¿ç”¨æŒ‡é’ˆæ—¶ï¼Œä¼šåˆ†é…2ä¸ªå¯¹è±¡æ¥å®Œæˆå¼•ç”¨ã€‚</p>

<p>3 å±€éƒ¨å˜é‡é€ƒé€¸æ—¶ï¼Œå°†å…¶èšåˆèµ·æ¥
è¿™ä¸€ç‚¹ç†è®ºè·Ÿ1ç›¸åŒï¼Œæ ¸å¿ƒåœ¨äºå‡å°‘objectçš„åˆ†é…ï¼Œå‡å°‘gcçš„å‹åŠ›ã€‚ ä¾‹å¦‚ï¼Œä»¥ä¸‹ä»£ç </p>

<p>for k, v := range m {
	k, v := k, v   // copy for capturing by the goroutine
	go func() {
		// use k and v
	}()
}
å¯ä»¥ä¿®æ”¹ä¸º:</p>

<p>for k, v := range m {
	x := struct{ k, v string }{k, v}   // copy for capturing by the goroutine
	go func() {
		// use x.k and x.v
	}()
}
ä¿®æ”¹åï¼Œé€ƒé€¸çš„å¯¹è±¡å˜ä¸ºäº†xï¼Œå°†kï¼Œv2ä¸ªå¯¹è±¡å‡å°‘ä¸º1ä¸ªå¯¹è±¡ã€‚</p>

<p>4 []byteçš„é¢„åˆ†é…
å½“æˆ‘ä»¬æ¯”è¾ƒæ¸…æ¥šçš„çŸ¥é“[]byteä¼šåˆ°åº•ä½¿ç”¨å¤šå°‘å­—èŠ‚ï¼Œæˆ‘ä»¬å°±å¯ä»¥é‡‡ç”¨ä¸€ä¸ªæ•°ç»„æ¥é¢„åˆ†é…è¿™æ®µå†…å­˜ã€‚ ä¾‹å¦‚:</p>

<p>type X struct {
    buf      []byte
    bufArray [16]byte // Buf usually does not grow beyond 16 bytes.
}</p>

<p>func MakeX() *X {
    x := &amp;X{}
    // Preinitialize buf with the backing array.
    x.buf = x.bufArray[:0]
    return x
}
5 å°½å¯èƒ½ä½¿ç”¨å­—èŠ‚æ•°å°‘çš„ç±»å‹
å½“æˆ‘ä»¬çš„ä¸€äº›constæˆ–è€…è®¡æ•°å­—æ®µä¸éœ€è¦å¤ªå¤§çš„å­—èŠ‚æ•°æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å¯ä»¥å°†å…¶å£°æ˜ä¸ºint8ç±»å‹ã€‚</p>

<p>6 å‡å°‘ä¸å¿…è¦çš„æŒ‡é’ˆå¼•ç”¨
å½“ä¸€ä¸ªå¯¹è±¡ä¸åŒ…å«ä»»ä½•æŒ‡é’ˆï¼ˆæ³¨æ„ï¼šstringsï¼Œslicesï¼Œmaps å’ŒchansåŒ…å«éšå«çš„æŒ‡é’ˆï¼‰ï¼Œæ—¶ï¼Œå¯¹gcçš„æ‰«æå½±å“å¾ˆå°ã€‚ æ¯”å¦‚ï¼Œ1GB byte çš„sliceäº‹å®ä¸ŠåªåŒ…å«æœ‰é™çš„å‡ ä¸ªobjectï¼Œä¸ä¼šå½±å“åƒåœ¾æ”¶é›†æ—¶é—´ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°½å¯èƒ½çš„å‡å°‘æŒ‡é’ˆçš„å¼•ç”¨ã€‚</p>

<p>7 ä½¿ç”¨sync.Poolæ¥ç¼“å­˜å¸¸ç”¨çš„å¯¹è±¡
æ³¨æ„
go1.9ã€go1.9.2ä¹‹é—´çš„ç‰ˆæœ¬go tool pprofå¼•å…¥äº†ä¸€ä¸ªBUGï¼Œä¼šå¯¼è‡´ä¸Šé¢çš„å†…å­˜åˆ†æå‘½ä»¤å¤±è´¥ã€‚ ä¸‹é¢ç»™å‡ºä¸€ç§ä¿®å¤åŠæ³•ï¼š</p>

<p>cd $GOROOT/src/cmd/vendor/github.com/google
rm pprof
git clone https://github.com/google/pprof.git #ç¡®ä¿åœ¨ç‰ˆæœ¬<code class="language-plaintext highlighter-rouge">e82ee9addc1b6c8e1d667ed6de0194241e1e03b5</code>ä¹‹å
rm $GOROOT/pkg/darwin_amd64/cmd/vendor/github.com/google/pprof
cd $GOROOT/src/cmd/pprof
go build
mv pprof $GOROOT/pkg/tool/darwin_amd64/pprof
å‚è€ƒ
profiling-go-programs
Optimising Go allocations using pprof
Debugging performance issues in Go programs
Debugging performance issues in Go programs ç¿»è¯‘(è²Œä¼¼æ˜¯æœºå™¨ç¿»è¯‘çš„ï¼Œè¯­ä¹‰ä¸æ˜¯å¾ˆé€šé¡º)
Golang Slices And The Case Of The Missing Memory</p>
:ET