I"z„<p>https://juejin.im/post/5ec72e0951882542f346e672
æœ‰å…³goroutineçš„é—®é¢˜ï¼Œå¤§å¤šæ•°é›†ä¸­åœ¨</p>

<p>å®ƒè·Ÿçº¿ç¨‹æœ‰å•¥åŒºåˆ«ï¼ŸåŸç†æ˜¯å•¥ï¼Ÿ
éƒ½è¯´ä»–å¥½ï¼Œä»–å¥½åœ¨å“ªé‡Œï¼Ÿ
ä½¿ç”¨ä¸Šé¢æœ‰å•¥æ³¨æ„çš„ï¼Ÿ</p>

<p>ç­‰ç­‰,æˆ–è®¸æˆ‘ä»¬è¿˜æœ‰æ›´å¤šç–‘é—®ï¼Œä½†æ˜¯å…ˆä»æœ€åŸºç¡€çš„å¼€å§‹å§
package main</p>

<p>import (
	â€œfmtâ€
)</p>

<p>func worker(stop chan bool) {</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for i:=0;i&lt;10;i++ {
	fmt.Println("å¹²æ´»....")
}
stop &lt;- true }
</code></pre></div></div>

<p>func main() {
	stop := make(chan bool)
	go worker(stop)
	&lt;- stop
}
å¤åˆ¶ä»£ç æˆ‘ä»¬åœ¨mainä¸­æ–°èµ·äº†ä¸€ä¸ªgoroutineæ¥å¹²æ´»ã€‚åå°å®ç°æ˜¯runtime.newprocè°ƒç”¨,å‡½æ•°ä½“å¦‚ä¸‹
// ä½¿ç”¨sizå­—èŠ‚å‚æ•°åˆ›å»ºä¸€ä¸ªè¿è¡Œfnçš„æ–°gã€‚ 
// å°†å…¶æ”¾åœ¨gç­‰å¾…è¿è¡Œçš„é˜Ÿåˆ—ä¸­ã€‚ ç¼–è¯‘å™¨å°†goè¯­å¥è½¬æ¢ä¸ºå¯¹æ­¤çš„è°ƒç”¨ã€‚ 
// æ— æ³•æ‹†åˆ†å †æ ˆï¼Œå› ä¸ºå®ƒå‡å®šå‚æ•°åœ¨ï¼†fn;ä¹‹åé¡ºåºå¯ç”¨ã€‚ 
// å¦‚æœå‘ç”Ÿå †æ ˆæ‹†åˆ†ï¼Œåˆ™ä¸ä¼šå¤åˆ¶å®ƒä»¬ã€‚
//go:nosplit
func newproc(siz int32, fn <em>funcval) {
    // ä» fn çš„åœ°å€å¢åŠ ä¸€ä¸ªæŒ‡é’ˆçš„é•¿åº¦ï¼Œä»è€Œè·å–ç¬¬ä¸€å‚æ•°åœ°å€
	argp := add(unsafe.Pointer(&amp;fn), sys.PtrSize)
	// è·å–å½“å‰çš„è¿è¡Œçš„g
	gp := getg()
	// getcallerpcè¿”å›å…¶è°ƒç”¨æ–¹çš„ç¨‹åºè®¡æ•°å™¨ï¼ˆPCï¼‰ã€‚ç”¨äºå­˜æ”¾ä¸‹ä¸€æ¡æŒ‡ä»¤æ‰€åœ¨å•å…ƒçš„åœ°å€çš„åœ°æ–¹ã€‚
	pc := getcallerpc()
	// systemstackåœ¨ç³»ç»Ÿå †æ ˆä¸Šè¿è¡Œ
	// å¦‚æœä»æ¯ä¸ªOSçº¿ç¨‹ï¼ˆg0ï¼‰å †æ ˆè°ƒç”¨systemstack
	// ï¼Œæˆ–è€…ä»ä¿¡å·å¤„ç†ï¼ˆgsignalï¼‰å †æ ˆè°ƒç”¨systemstack ï¼Œ
	// systemstackç›´æ¥è°ƒç”¨fnå¹¶è¿”å›ã€‚
	// å¦åˆ™ï¼Œä»æ™®é€šgoroutineçš„æœ‰é™å †æ ˆä¸­è°ƒç”¨systemstackã€‚
	// åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç³»ç»Ÿå †æ ˆåˆ‡æ¢åˆ°æ¯ä¸ªOSçº¿ç¨‹å †æ ˆï¼Œè°ƒç”¨fnï¼Œç„¶ååˆ‡å›ã€‚
	// é€šå¸¸ä½¿ç”¨funcå­—é¢é‡ä½œä¸ºå‚æ•°ï¼Œä»¥ä¾¿ä¸è°ƒç”¨ç³»ç»Ÿå †æ ˆå‘¨å›´çš„ä»£ç å…±äº«è¾“å…¥å’Œè¾“å‡º
	systemstack(func() {
	    // åŸå‹ï¼šfunc newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) 
	    // åˆ›å»ºä¸€ä¸ªæ–°çš„gï¼Œè¿è¡Œfnï¼Œå…¶ä¸­nargä¸ªå­—èŠ‚çš„å‚æ•°ä»argpå¼€å§‹ã€‚
	    // callerpcæ˜¯åˆ›å»ºå®ƒçš„goè¯­å¥çš„åœ°å€ã€‚æ–°gæ”¾å…¥gç­‰å¾…è¿è¡Œçš„é˜Ÿåˆ—ä¸­ã€‚
		newproc1(fn, (</em>uint8)(argp), siz, gp, pc)
	})
}
<!-- more -->
newproc1æ˜¯é‡å¤´æˆï¼Œä¹Ÿæ¯”è¾ƒå¤æ‚ï¼Œå¯èƒ½ç›®å‰è¿˜ä¸èƒ½çœ‹çš„å¾ˆæ˜ç™½ï¼Œä½†æ˜¯ï¼Œå¤§è‡´å…ˆäº†è§£ä¸€ä¸‹ï¼š
func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) {
	<em>g</em> := getg()</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if fn == nil {
	_g_.m.throwing = -1 // do not dump full stacks
	throw("go of nil func value")
}
_g_.m.locks++ // disable preemption because it can be holding p in a local var
siz := narg
siz = (siz + 7) &amp;^ 7

// We could allocate a larger initial stack if necessary.
// Not worth it: this is almost always an error.
// 4*sizeof(uintreg): extra space added below
// sizeof(uintreg): caller's LR (arm) or return address (x86, in gostartcall).
if siz &gt;= _StackMin-4*sys.RegSize-sys.RegSize {
	throw("newproc: function arguments too large for new goroutine")
}

_p_ := _g_.m.p.ptr() 
newg := gfget(_p_) // æ ¹æ® p è·å¾—ä¸€ä¸ªæ–°çš„ g
// åˆå§‹åŒ–é˜¶æ®µï¼Œgfget æ˜¯ä¸å¯èƒ½æ‰¾åˆ° g çš„
// ä¹Ÿå¯èƒ½è¿è¡Œä¸­æœ¬æ¥å°±å·²ç»è€—å°½äº†
if newg == nil {
	newg = malg(_StackMin) // åˆ›å»ºä¸€ä¸ªæ‹¥æœ‰ _StackMin å¤§å°çš„æ ˆçš„ g
	casgstatus(newg, _Gidle, _Gdead) // å°†æ–°åˆ›å»ºçš„ g ä» _Gidle æ›´æ–°ä¸º _Gdead çŠ¶æ€
	allgadd(newg) // å°† Gdead çŠ¶æ€çš„ g æ·»åŠ åˆ° allgï¼Œè¿™æ · GC ä¸ä¼šæ‰«ææœªåˆå§‹åŒ–çš„æ ˆ
}
if newg.stack.hi == 0 {
	throw("newproc1: newg missing stack")
}

if readgstatus(newg) != _Gdead {
	throw("newproc1: new g is not Gdead")
}

totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame
totalSize += -totalSize &amp; (sys.SpAlign - 1)                  // align to spAlign
sp := newg.stack.hi - totalSize
spArg := sp
if usesLR {
	// caller's LR
	*(*uintptr)(unsafe.Pointer(sp)) = 0
	prepGoExitFrame(sp)
	spArg += sys.MinFrameSize
}
if narg &gt; 0 {
	memmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg))
	// This is a stack-to-stack copy. If write barriers
	// are enabled and the source stack is grey (the
	// destination is always black), then perform a
	// barrier copy. We do this *after* the memmove
	// because the destination stack may have garbage on
	// it.
	if writeBarrier.needed &amp;&amp; !_g_.m.curg.gcscandone {
		f := findfunc(fn.fn)
		stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps))
		if stkmap.nbit &gt; 0 {
			// We're in the prologue, so it's always stack map index 0.
			bv := stackmapdata(stkmap, 0)
			bulkBarrierBitmap(spArg, spArg, uintptr(bv.n)*sys.PtrSize, 0, bv.bytedata)
		}
	}
}

memclrNoHeapPointers(unsafe.Pointer(&amp;newg.sched), unsafe.Sizeof(newg.sched))
newg.sched.sp = sp
newg.stktopsp = sp
newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
newg.sched.g = guintptr(unsafe.Pointer(newg))
gostartcallfn(&amp;newg.sched, fn)
newg.gopc = callerpc
newg.ancestors = saveAncestors(callergp)
newg.startpc = fn.fn
if _g_.m.curg != nil {
	newg.labels = _g_.m.curg.labels
}
if isSystemGoroutine(newg, false) {
	atomic.Xadd(&amp;sched.ngsys, +1)
}
newg.gcscanvalid = false
casgstatus(newg, _Gdead, _Grunnable)

if _p_.goidcache == _p_.goidcacheend {
	// Sched.goidgen is the last allocated id,
	// this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch].
	// At startup sched.goidgen=0, so main goroutine receives goid=1.
	_p_.goidcache = atomic.Xadd64(&amp;sched.goidgen, _GoidCacheBatch)
	_p_.goidcache -= _GoidCacheBatch - 1
	_p_.goidcacheend = _p_.goidcache + _GoidCacheBatch
}
newg.goid = int64(_p_.goidcache)
_p_.goidcache++
if raceenabled {
	newg.racectx = racegostart(callerpc)
}
if trace.enabled {
	traceGoCreate(newg, newg.startpc)
}
runqput(_p_, newg, true)

if atomic.Load(&amp;sched.npidle) != 0 &amp;&amp; atomic.Load(&amp;sched.nmspinning) == 0 &amp;&amp; mainStarted {
	wakep()
}
_g_.m.locks--
if _g_.m.locks == 0 &amp;&amp; _g_.preempt { // restore the preemption request in case we've cleared it in newstack
	_g_.stackguard0 = stackPreempt
} } å¤åˆ¶ä»£ç ä¹Ÿå°±æ˜¯è¯´ï¼Œåˆšå¼€å§‹çš„æ—¶å€™ï¼Œpä¸Šå¹¶æ²¡æœ‰å¯ä»¥ä½¿ç”¨çš„g,æ‰€ä»¥åˆ›å»ºäº†ä¸€ä¸ªå…·æœ‰å¾ˆå°‘æ ˆå®¹é‡çš„g. // åˆ†é…ä¸€ä¸ªæ–°çš„gï¼Œå…¶å †æ ˆè¶³ä»¥å®¹çº³stacksizeå­—èŠ‚ã€‚ func malg(stacksize int32) *g {
newg := new(g)
if stacksize &gt;= 0 {
	stacksize = round2(_StackSystem + stacksize)
	systemstack(func() {
		newg.stack = stackalloc(uint32(stacksize))
	})
	newg.stackguard0 = newg.stack.lo + _StackGuard
	newg.stackguard1 = ^uintptr(0)
}
return newg } å¤åˆ¶ä»£ç åˆ†é…çš„gæ˜¯ä¸€ä¸ªç»“æ„ä½“æŒ‡é’ˆ,å¦‚æœstacksizeå¤§äºé›¶ï¼Œè¿˜å°†åˆ†é…stackå †æ ˆï¼Œè¯¥ç»“æ„ä½“å…·ä½“å†…å®¹å¦‚ä¸‹ï¼š type g struct {
// Stack parameters.
// stack describes the actual stack memory: [stack.lo, stack.hi).
// stackguard0 is the stack pointer compared in the Go stack growth prologue.
// It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption.
// stackguard1 is the stack pointer compared in the C stack growth prologue.
// It is stack.lo+StackGuard on g0 and gsignal stacks.
// It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash).
stack       stack   // offset known to runtime/cgo
stackguard0 uintptr // offset known to liblink
stackguard1 uintptr // offset known to liblink

_panic         *_panic // innermost panic - offset known to liblink
_defer         *_defer // innermost defer
m              *m      // current m; offset known to arm liblink
sched          gobuf
syscallsp      uintptr        // if status==Gsyscall, syscallsp = sched.sp to use during gc
syscallpc      uintptr        // if status==Gsyscall, syscallpc = sched.pc to use during gc
stktopsp       uintptr        // expected sp at top of stack, to check in traceback
param          unsafe.Pointer // passed parameter on wakeup
atomicstatus   uint32
stackLock      uint32 // sigprof/scang lock; TODO: fold in to atomicstatus
goid           int64
schedlink      guintptr
waitsince      int64      // approx time when the g become blocked
waitreason     waitReason // if status==Gwaiting
preempt        bool       // preemption signal, duplicates stackguard0 = stackpreempt
paniconfault   bool       // panic (instead of crash) on unexpected fault address
preemptscan    bool       // preempted g does scan for gc
gcscandone     bool       // g has scanned stack; protected by _Gscan bit in status
gcscanvalid    bool       // false at start of gc cycle, true if G has not run since last scan; TODO: remove?
throwsplit     bool       // must not split stack
raceignore     int8       // ignore race detection events
sysblocktraced bool       // StartTrace has emitted EvGoInSyscall about this goroutine
sysexitticks   int64      // cputicks when syscall has returned (for tracing)
traceseq       uint64     // trace event sequencer
tracelastp     puintptr   // last P emitted an event for this goroutine
lockedm        muintptr
sig            uint32
writebuf       []byte
sigcode0       uintptr
sigcode1       uintptr
sigpc          uintptr
gopc           uintptr         // pc of go statement that created this goroutine
ancestors      *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors)
startpc        uintptr         // pc of goroutine function
racectx        uintptr
waiting        *sudog         // sudog structures this g is waiting on (that have a valid elem ptr); in lock order
cgoCtxt        []uintptr      // cgo traceback context
labels         unsafe.Pointer // profiler labels
timer          *timer         // cached timer for time.Sleep
selectDone     uint32         // are we participating in a select and did someone win the race?

// Per-G GC state

// gcAssistBytes is this G's GC assist credit in terms of
// bytes allocated. If this is positive, then the G has credit
// to allocate gcAssistBytes bytes without assisting. If this
// is negative, then the G must correct this by performing
// scan work. We track this in bytes to make it fast to update
// and check for debt in the malloc hot path. The assist ratio
// determines how this corresponds to scan work debt.
gcAssistBytes int64 } å¤åˆ¶ä»£ç ä¸œè¥¿å¤ªå¤šï¼Œç›®å‰èƒ½çœ‹æ‡‚çš„å°±æ˜¯newè¿‡gåï¼Œåˆ†é…äº†ä¸€ä¸ªround2(_StackSystem + stacksize)ä¸ªå­—èŠ‚çš„stack. newg.stackguard0 = newg.stack.lo + _StackGuard newg.stackguard1 = ^uintptr(0) å¤åˆ¶ä»£ç ç„¶åå°†æ–°ç”Ÿæˆçš„gçš„çŠ¶æ€ç”±_Gidleå˜æˆ_Gdeadã€‚å°† Gdead çŠ¶æ€çš„ g æ·»åŠ åˆ° allgåˆ‡ç‰‡ä¸­ã€‚ var (
allgs    []*g
allglock mutex )
</code></pre></div></div>

<p>func allgadd(gp *g) {
	if readgstatus(gp) == _Gidle {
		throw(â€œallgadd: bad status Gidleâ€)
	}</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lock(&amp;allglock)
allgs = append(allgs, gp)
allglen = uintptr(len(allgs))
unlock(&amp;allglock) } å¤åˆ¶ä»£ç ä¹‹åå¯¹gç›¸å…³çš„schedå­—æ®µè¿›è¡Œåˆå§‹åŒ–èµ‹å€¼,è¯¥å­—æ®µç±»å‹æ˜¯ä¸ªç»“æ„ä½“ï¼Œ type gobuf struct {
// The offsets of sp, pc, and g are known to (hard-coded in) libmach.
//
// ctxt is unusual with respect to GC: it may be a
// heap-allocated funcval, so GC needs to track it, but it
// needs to be set and cleared from assembly, where it's
// difficult to have write barriers. However, ctxt is really a
// saved, live register, and we only ever exchange it between
// the real register and the gobuf. Hence, we treat it as a
// root during stack scanning, which means assembly that saves
// and restores it doesn't need write barriers. It's still
// typed as a pointer so that any other writes from Go get
// write barriers.
sp   uintptr
pc   uintptr
g    guintptr
ctxt unsafe.Pointer
ret  sys.Uintreg
lr   uintptr
bp   uintptr // for GOEXPERIMENT=framepointer } å¤åˆ¶ä»£ç è¯¥å­—æ®µçš„åŠŸèƒ½ï¼Œç›®å‰æˆ‘ä»¬ä¸å¾—è€ŒçŸ¥ï¼Œå…ˆçœ‹
memclrNoHeapPointers(unsafe.Pointer(&amp;newg.sched), unsafe.Sizeof(newg.sched))
newg.sched.sp = sp
newg.stktopsp = sp
newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
newg.sched.g = guintptr(unsafe.Pointer(newg))
gostartcallfn(&amp;newg.sched, fn) å¤åˆ¶ä»£ç è°ƒæ•´Gobufå°±åƒæ‰§è¡Œå¯¹fnçš„è°ƒç”¨ä¸€æ ·ï¼Œç„¶åç«‹å³æ‰§è¡Œgosave. func gostartcallfn(gobuf *gobuf, fv *funcval) {
var fn unsafe.Pointer
if fv != nil {
	fn = unsafe.Pointer(fv.fn)
} else {
	fn = unsafe.Pointer(funcPC(nilfunc))
}
gostartcall(gobuf, fn, unsafe.Pointer(fv)) } å¤åˆ¶ä»£ç ä¹‹åæœ‰ä¸€ä¸ªå°†å½“å‰gçš„çŠ¶æ€è°ƒæ•´çš„åŠ¨ä½œ casgstatus(newg, _Gdead, _Grunnable) å¤åˆ¶ä»£ç å¯è¿è¡ŒçŠ¶æ€çš„gä¼šè¢«æ”¾å…¥åˆ°æœ¬åœ°çš„å¯è¿è¡Œé˜Ÿåˆ—ä¸­ï¼Œ runqput(_p_, newg, true) å¤åˆ¶ä»£ç è¯¥å‡½æ•°ä½“å¦‚ä¸‹ï¼š // runqputå°è¯•å°†gæ”¾ç½®åœ¨æœ¬åœ°å¯è¿è¡Œé˜Ÿåˆ—ä¸­ã€‚  // å¦‚æœnextä¸ºfalseï¼Œåˆ™runqputå°†gæ·»åŠ åˆ°å¯è¿è¡Œé˜Ÿåˆ—çš„å°¾éƒ¨ã€‚ // å¦‚æœnextä¸ºtrueï¼Œåˆ™runqputå°†gæ”¾åœ¨_p_.runnextæ’æ§½ä¸­ã€‚  // å¦‚æœè¿è¡Œé˜Ÿåˆ—å·²æ»¡ï¼Œåˆ™runnextå°†gæ”¾å…¥å…¨å±€é˜Ÿåˆ—ã€‚  // ä»…ç”±æ‰€æœ‰è€…Pæ‰§è¡Œã€‚ func runqput(_p_ *p, gp *g, next bool) {
if randomizeScheduler &amp;&amp; next &amp;&amp; fastrand()%2 == 0 {
	next = false
}

if next {
retryNext:
	oldnext := _p_.runnext
	if !_p_.runnext.cas(oldnext, guintptr(unsafe.Pointer(gp))) {
		goto retryNext
	}
	if oldnext == 0 {
		return
	}
	// Kick the old runnext out to the regular run queue.
	gp = oldnext.ptr()
}
</code></pre></div></div>

<p>retry:
	h := atomic.LoadAcq(&amp;<em>p</em>.runqhead) // load-acquire, synchronize with consumers
	t := <em>p</em>.runqtail
	if t-h &lt; uint32(len(<em>p</em>.runq)) {
		<em>p</em>.runq[t%uint32(len(<em>p</em>.runq))].set(gp)
		atomic.StoreRel(&amp;<em>p</em>.runqtail, t+1) // store-release, makes the item available for consumption
		return
	}
	if runqputslow(<em>p</em>, gp, h, t) {
		return
	}
	// the queue is not full, now the put above must succeed
	goto retry
}
å¤åˆ¶ä»£ç ä»¥ä¸Šï¼Œå…³äºgçš„å†…å®¹ï¼Œæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¤§è‡´çš„äº†è§£ï¼Œå½“æˆ‘ä»¬å°†åˆ›å»ºçš„gæ”¾åˆ°æœ¬åœ°é˜Ÿåˆ—æ—¶ï¼Œæåˆ°äº†ä¸€ä¸ªç»“æ„ä½“p,è¿™ä¸ªä¸œè¥¿æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿä¸‹é¢æ˜¯ä»–çš„ç»“æ„ä½“
type p struct {
	lock mutex</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>id          int32
status      uint32 // one of pidle/prunning/...
link        puintptr
schedtick   uint32     // incremented on every scheduler call
syscalltick uint32     // incremented on every system call
sysmontick  sysmontick // last tick observed by sysmon
m           muintptr   // back-link to associated m (nil if idle)
mcache      *mcache
racectx     uintptr

deferpool    [5][]*_defer // pool of available defer structs of different sizes (see panic.go)
deferpoolbuf [5][32]*_defer

// Cache of goroutine ids, amortizes accesses to runtimeÂ·sched.goidgen.
goidcache    uint64
goidcacheend uint64

// Queue of runnable goroutines. Accessed without lock.
// å¯è¿è¡Œgoroutinesçš„é˜Ÿåˆ—ï¼Œè®¿é—®æ— éœ€é”ï¼Œè¿™ä¸ªå°±æ˜¯æˆ‘ä»¬ä¸Šè¿°åˆ›å»ºçš„gå­˜æ”¾çš„ä½ç½®
runqhead uint32
runqtail uint32
runq     [256]guintptr
// runnextï¼ˆå¦‚æœä¸æ˜¯nilï¼‰æ˜¯å½“å‰Gå‡†å¤‡å¥½çš„å¯è¿è¡ŒGï¼Œ
// å¦‚æœæ­£åœ¨è¿è¡Œçš„Gçš„æ—¶é—´ç‰‡ä¸­è¿˜æœ‰å‰©ä½™æ—¶é—´ï¼Œåˆ™åº”ä¸‹ä¸€ä¸ªè¿è¡Œï¼Œè€Œä¸æ˜¯ä»runqä¸­è·å–Gã€‚
// å®ƒå°†ç»§æ‰¿å½“å‰æ—¶é—´ç‰‡ä¸­å‰©ä½™çš„æ—¶é—´ã€‚
// å¦‚æœå°†ä¸€ç»„goroutineé”å®šä¸ºé€šä¿¡ç­‰å¾…æ¨¡å¼ï¼Œ
// åˆ™æ­¤è°ƒåº¦ä¼šå°†å…¶è®¾ç½®ä¸ºä¸€ä¸ªå•å…ƒï¼Œ
// å¹¶æ¶ˆé™¤ï¼ˆå¯èƒ½å¾ˆå¤§çš„ï¼‰è°ƒåº¦å»¶è¿Ÿï¼Œ
// å¦åˆ™è¯¥å»¶è¿Ÿå¯èƒ½æ˜¯ç”±äºå°†å°±ç»ªçš„goroutineæ·»åŠ åˆ°è¿è¡Œé˜Ÿåˆ—çš„æœ«å°¾è€Œå¼•èµ·çš„ã€‚
runnext guintptr

// Available G's (status == Gdead)
gFree struct {
	gList
	n int32
}

sudogcache []*sudog
sudogbuf   [128]*sudog

tracebuf traceBufPtr

// traceSweep indicates the sweep events should be traced.
// This is used to defer the sweep start event until a span
// has actually been swept.
traceSweep bool
// traceSwept and traceReclaimed track the number of bytes
// swept and reclaimed by sweeping in the current sweep loop.
traceSwept, traceReclaimed uintptr

palloc persistentAlloc // per-P to avoid mutex

// Per-P GC state
gcAssistTime         int64 // Nanoseconds in assistAlloc
gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker
gcBgMarkWorker       guintptr
gcMarkWorkerMode     gcMarkWorkerMode

// gcMarkWorkerStartTime is the nanotime() at which this mark
// worker started.
gcMarkWorkerStartTime int64

// gcw is this P's GC work buffer cache. The work buffer is
// filled by write barriers, drained by mutator assists, and
// disposed on certain GC state transitions.
gcw gcWork

// wbBuf is this P's GC write barrier buffer.
//
// TODO: Consider caching this in the running G.
wbBuf wbBuf

runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point

pad cpu.CacheLinePad } å¤åˆ¶ä»£ç åœ¨newprocå‡½æ•°ä¸­ï¼Œä»å½“å‰gè·å–pç»“æ„æ—¶ï¼Œé€šè¿‡çš„æ˜¯gçš„må­—æ®µï¼Œè¯¥å­—æ®µæ˜¯ä¸ªä»€ä¹ˆå‘¢ï¼Ÿæ˜¯ä¸ªmç»“æ„ä½“æŒ‡é’ˆï¼Œmçš„ç»“æ„ä½“åŸå‹ä¸ºï¼š type m struct {
g0      *g     // ç”¨äºæ‰§è¡Œè°ƒåº¦æŒ‡ä»¤çš„ goroutine
morebuf gobuf  // gobuf arg to morestack
divmod  uint32 // div/mod denominator for arm - known to liblink

// Fields not known to debuggers.
procid        uint64       // for debuggers, but offset not hard-coded
gsignal       *g           // å¤„ç† signal çš„ g
goSigStack    gsignalStack // Go-allocated signal handling stack
sigmask       sigset       // storage for saved signal mask
tls           [6]uintptr   // çº¿ç¨‹æœ¬åœ°å­˜å‚¨
mstartfn      func()
curg          *g       // å½“å‰è¿è¡Œçš„G
caughtsig     guintptr // goroutine running during fatal signal
p             puintptr // æ‰§è¡Œ go ä»£ç æ—¶æŒæœ‰çš„ p (å¦‚æœæ²¡æœ‰æ‰§è¡Œåˆ™ä¸º nil)
nextp         puintptr
oldp          puintptr // the p that was attached before executing a syscall
id            int64
mallocing     int32
throwing      int32
preemptoff    string // if != "", keep curg running on this m
locks         int32
dying         int32
profilehz     int32
spinning      bool // m å½“å‰æ²¡æœ‰è¿è¡Œ work ä¸”æ­£å¤„äºå¯»æ‰¾ work çš„æ´»è·ƒçŠ¶æ€
blocked       bool // m is blocked on a note
inwb          bool // m is executing a write barrier
newSigstack   bool // minit on C thread called sigaltstack
printlock     int8
incgo         bool   // m is executing a cgo call
freeWait      uint32 // if == 0, safe to free g0 and delete m (atomic)
fastrand      [2]uint32
needextram    bool
traceback     uint8
ncgocall      uint64      // number of cgo calls in total
ncgo          int32       // number of cgo calls currently in progress
cgoCallersUse uint32      // if non-zero, cgoCallers in use temporarily
cgoCallers    *cgoCallers // cgo traceback if crashing in cgo call
park          note
alllink       *m // on allm
schedlink     muintptr
mcache        *mcache
lockedg       guintptr
createstack   [32]uintptr    // stack that created this thread.
lockedExt     uint32         // tracking for external LockOSThread
lockedInt     uint32         // tracking for internal lockOSThread
nextwaitm     muintptr       // next m waiting for lock
waitunlockf   unsafe.Pointer // todo go func(*g, unsafe.pointer) bool
waitlock      unsafe.Pointer
waittraceev   byte
waittraceskip int
startingtrace bool
syscalltick   uint32
thread        uintptr // thread handle
freelink      *m      // on sched.freem

// these are here because they are too large to be on the stack
// of low-level NOSPLIT functions.
libcall   libcall
libcallpc uintptr // for cpu profiler
libcallsp uintptr
libcallg  guintptr
syscall   libcall // stores syscall parameters on windows

vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call)
vdsoPC uintptr // PC for traceback while in VDSO call

mOS } å¤åˆ¶ä»£ç çœ‹äº†ä¸Šé¢çš„ç»“æ„ä½“æ„Ÿè§‰å¾ˆç©ºæ´ï¼Œéƒ½æ˜¯äº›ä»€ä¹ˆå‘¢ï¼Ÿå°±çŸ¥é“newprocæ—¶ï¼Œåˆ›å»ºçš„G,æ”¾åˆ°äº†å…³è”çš„Pçš„æœ¬åœ°å¯è¿è¡Œé˜Ÿåˆ—ä¸­ï¼Œè¦æ˜ç™½è¿™äº›ä¸œè¥¿æ˜¯ä»€ä¹ˆï¼Œå°±è¦ä»ä»–ä»¬æ˜¯å¦‚ä½•äº§ç”Ÿçš„è¯´èµ·ï¼Ÿ âœ  goroutinetest gdb main GNU gdb (GDB) 8.3 Copyright (C) 2019 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type "show copying" and "show warranty" for details. This GDB was configured as "x86_64-apple-darwin16.7.0". Type "show configuration" for configuration details. For bug reporting instructions, please see:
</code></pre></div></div>
<p><a href="http://www.gnu.org/software/gdb/bugs/">http://www.gnu.org/software/gdb/bugs/</a>.
Find the GDB manual and other documentation resources online at:
    <a href="http://www.gnu.org/software/gdb/documentation/">http://www.gnu.org/software/gdb/documentation/</a>.</p>

<p>For help, type â€œhelpâ€.
Type â€œapropos wordâ€ to search for commands related to â€œwordâ€â€¦
Reading symbols from mainâ€¦
(No debugging symbols found in main)
Loading Go Runtime support.
(gdb) info files
Symbols from â€œ/Users/zhaojunwei/workspace/src/just.for.test/goroutinetest/mainâ€.
Local exec file:
	`/Users/zhaojunwei/workspace/src/just.for.test/goroutinetest/mainâ€™, file type mach-o-x86-64.
	Entry point: 0x1052770
	0x0000000001001000 - 0x0000000001093194 is .text
	0x00000000010931a0 - 0x00000000010e1ace is __TEXT.__rodata
	0x00000000010e1ae0 - 0x00000000010e1be2 is __TEXT.__symbol_stub1
	0x00000000010e1c00 - 0x00000000010e2864 is __TEXT.__typelink
	0x00000000010e2868 - 0x00000000010e28d0 is __TEXT.__itablink
	0x00000000010e28d0 - 0x00000000010e28d0 is __TEXT.__gosymtab
	0x00000000010e28e0 - 0x000000000115c108 is __TEXT.__gopclntab
	0x000000000115d000 - 0x000000000115d158 is __DATA.__nl_symbol_ptr
	0x000000000115d160 - 0x0000000001169c9c is __DATA.__noptrdata
	0x0000000001169ca0 - 0x0000000001170610 is .data
	0x0000000001170620 - 0x000000000118be50 is .bss
	0x000000000118be60 - 0x000000000118e418 is __DATA.__noptrbss
(gdb)
(gdb) b *0x1052770
Breakpoint 1 at 0x1052770
(gdb) info br
Num     Type           Disp Enb Address            What
1       breakpoint     keep y   0x0000000001052770 <_rt0_amd64_darwin>
(gdb)
å¤åˆ¶ä»£ç æŸ¥çœ‹ä¸€ä¸‹_rt0_amd64_darwinæ˜¯ä»€ä¹ˆï¼Ÿ
#include "textflag.h"</_rt0_amd64_darwin></p>

<p>TEXT _rt0_amd64_darwin(SB),NOSPLIT,$-8
	JMP	_rt0_amd64(SB)</p>

<p>// When linking with -shared, this symbol is called when the shared library
// is loaded.
TEXT _rt0_amd64_darwin_lib(SB),NOSPLIT,$0
	JMP	_rt0_amd64_lib(SB)</p>

<p>å¤åˆ¶ä»£ç _rt0_amd64æ˜¯ä½¿ç”¨å†…éƒ¨é“¾æ¥æ—¶å¤§å¤šæ•°amd64ç³»ç»Ÿçš„é€šç”¨å¯åŠ¨ä»£ç ã€‚ è¿™æ˜¯å†…æ ¸ä¸­æ™®é€š-buildmode = exeç¨‹åºçš„ç¨‹åºå…¥å£ç‚¹ã€‚ å †æ ˆä¿å­˜å‚æ•°æ•°é‡å’ŒCé£æ ¼çš„argvã€‚
TEXT _rt0_amd64(SB),NOSPLIT,$-8
	MOVQ	0(SP), DI	// argc
	LEAQ	8(SP), SI	// argv
	JMP	runtimeÂ·rt0_go(SB)
å¤åˆ¶ä»£ç æœ€ç»ˆè°ƒç”¨çš„æ˜¯runtime.rt0_goæ–¹æ³•
TEXT runtimeÂ·rt0_go(SB),NOSPLIT,$0
	// SP = stack; R0 = argc; R1 = argv</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SUB	$32, RSP
MOVW	R0, 8(RSP) // argc
MOVD	R1, 16(RSP) // argv

// create istack out of the given (operating system) stack.
// _cgo_init may update stackguard.
MOVD	$runtimeÂ·g0(SB), g
MOVD	RSP, R7
MOVD	$(-64*1024)(R7), R0
MOVD	R0, g_stackguard0(g)
MOVD	R0, g_stackguard1(g)
MOVD	R0, (g_stack+stack_lo)(g)
MOVD	R7, (g_stack+stack_hi)(g)

// if there is a _cgo_init, call it using the gcc ABI.
MOVD	_cgo_init(SB), R12
CMP	$0, R12
BEQ	nocgo

MRS_TPIDR_R0			// load TLS base pointer
MOVD	R0, R3			// arg 3: TLS base pointer #ifdef TLSG_IS_VARIABLE
MOVD	$runtimeÂ·tls_g(SB), R2 	// arg 2: &amp;tls_g #else
MOVD	$0, R2		        // arg 2: not used when using platform's TLS #endif
MOVD	$setg_gcc&lt;&gt;(SB), R1	// arg 1: setg
MOVD	g, R0			// arg 0: G
SUB	$16, RSP		// reserve 16 bytes for sp-8 where fp may be saved.
BL	(R12)
ADD	$16, RSP
</code></pre></div></div>

<p>nocgo:
	BL	runtimeÂ·save_g(SB)
	// update stackguard after _cgo_init
	MOVD	(g_stack+stack_lo)(g), R0
	ADD	$const__StackGuard, R0
	MOVD	R0, g_stackguard0(g)
	MOVD	R0, g_stackguard1(g)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// set the per-goroutine and per-mach "registers"
MOVD	$runtimeÂ·m0(SB), R0

// save m-&gt;g0 = g0
MOVD	g, m_g0(R0)
// save m0 to g0-&gt;m
MOVD	R0, g_m(g)

BL	runtimeÂ·check(SB)

MOVW	8(RSP), R0	// copy argc
MOVW	R0, -8(RSP)
MOVD	16(RSP), R0		// copy argv
MOVD	R0, 0(RSP)
BL	runtimeÂ·args(SB)
BL	runtimeÂ·osinit(SB)
BL	runtimeÂ·schedinit(SB)

// create a new goroutine to start program
MOVD	$runtimeÂ·mainPC(SB), R0		// entry
MOVD	RSP, R7
MOVD.W	$0, -8(R7)
MOVD.W	R0, -8(R7)
MOVD.W	$0, -8(R7)
MOVD.W	$0, -8(R7)
MOVD	R7, RSP
BL	runtimeÂ·newproc(SB)
ADD	$32, RSP

// start this M
BL	runtimeÂ·mstart(SB)

MOVD	$0, R0
MOVD	R0, (R0)	// boom
UNDEF å¤åˆ¶ä»£ç é¦–å…ˆè¿›è¡Œg0å’Œm0çš„åˆå§‹åŒ–ï¼Œä¹‹åè¿›è¡Œæœ¬åœ°çº¿ç¨‹å­˜å‚¨çš„æ£€æµ‹è®¾ç½®ã€‚ä¹‹åå°½å¿ƒè°ƒåº¦å™¨çš„åˆå§‹åŒ–ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„goroutineè¿è¡Œç¨‹åºï¼Œæœ€åå¼€å¯æˆ‘ä»¬çš„M. // The bootstrap sequence is: // //	call osinit //	call schedinit //	make &amp; queue new G //	call runtimeÂ·mstart // // The new G calls runtimeÂ·main. func schedinit() {
// raceinit must be the first call to race detector.
// In particular, it must be done before mallocinit below calls racemapshadow.
_g_ := getg()
if raceenabled {
	_g_.racectx, raceprocctx0 = raceinit()
}
// è®¾ç½®æœ€å¤šå¯åŠ¨10000ä¸ªæ“ä½œç³»ç»Ÿçº¿ç¨‹ï¼Œä¹Ÿæ˜¯æœ€å¤š10000ä¸ªM
sched.maxmcount = 10000

tracebackinit()
moduledataverify()
stackinit()
mallocinit()
mcommoninit(_g_.m) // åˆå§‹åŒ–m0ï¼Œå› ä¸ºä»å‰é¢çš„ä»£ç æˆ‘ä»¬çŸ¥é“g0-&gt;m = &amp;m0
cpuinit()       // must run before alginit
alginit()       // maps must not be used before this call
modulesinit()   // provides activeModules
typelinksinit() // uses maps, activeModules
itabsinit()     // uses activeModules

msigsave(_g_.m)
initSigmask = _g_.m.sigmask

goargs()
goenvs()
parsedebugvars()
gcinit()

sched.lastpoll = uint64(nanotime())
// ç³»ç»Ÿä¸­æœ‰å¤šå°‘æ ¸ï¼Œå°±åˆ›å»ºå’Œåˆå§‹åŒ–å¤šå°‘ä¸ªpç»“æ„ä½“å¯¹è±¡
procs := ncpu
if n, ok := atoi32(gogetenv("GOMAXPROCS")); ok &amp;&amp; n &gt; 0 {
    // å¦‚æœç¯å¢ƒå˜é‡æŒ‡å®šäº†GOMAXPROCSï¼Œåˆ™åˆ›å»ºæŒ‡å®šæ•°é‡çš„p
	procs = n
}
// åˆ›å»ºå’Œåˆå§‹åŒ–å…¨å±€å˜é‡allp
if procresize(procs) != nil {
	throw("unknown runnable goroutine during bootstrap")
}

// For cgocheck &gt; 1, we turn on the write barrier at all times
// and check all pointer writes. We can't do this until after
// procresize because the write barrier needs a P.
if debug.cgocheck &gt; 1 {
	writeBarrier.cgo = true
	writeBarrier.enabled = true
	for _, p := range allp {
		p.wbBuf.reset()
	}
}

if buildVersion == "" {
	// Condition should never trigger. This code just serves
	// to ensure runtimeÂ·buildVersion is kept in the resulting binary.
	buildVersion = "unknown"
} } å¤åˆ¶ä»£ç æˆ‘ä»¬æ¥å…³æ³¨ä¸€ä¸‹m0æ˜¯å¦‚ä½•åˆå§‹åŒ–çš„ func mcommoninit(mp *m) {
_g_ := getg()

// g0 stack won't make sense for user (and is not necessary unwindable).
if _g_ != _g_.m.g0 {
	callers(1, mp.createstack[:])
}

lock(&amp;sched.lock)
if sched.mnext+1 &lt; sched.mnext {
	throw("runtime: thread ID overflow")
}
// m0åˆ†é…çš„id,schedtç»“æ„ä½“çš„mnextå­—æ®µæ ‡è¯†ä¸‹ä¸€ä¸ªå¯ç”¨çš„thread id.
mp.id = sched.mnext
sched.mnext++

checkmcount()

mp.fastrand[0] = 1597334677 * uint32(mp.id)
mp.fastrand[1] = uint32(cputicks())
if mp.fastrand[0]|mp.fastrand[1] == 0 {
	mp.fastrand[1] = 1
}

mpreinit(mp)
if mp.gsignal != nil {
	mp.gsignal.stackguard1 = mp.gsignal.stack.lo + _StackGuard
}

// Add to allm so garbage collector doesn't free g-&gt;m
// when it is just in a register or thread-local storage.
// allmæŒ‚åˆ°è¿™é‡Œï¼Œé˜²æ­¢è¢«åƒåœ¾å›æ”¶
mp.alllink = allm

// NumCgoCall() iterates over allm w/o schedlock,
// so we need to publish it safely.
atomicstorep(unsafe.Pointer(&amp;allm), unsafe.Pointer(mp))
unlock(&amp;sched.lock)

// Allocate memory to hold a cgo traceback if the cgo call crashes.
if iscgo || GOOS == "solaris" || GOOS == "windows" {
	mp.cgoCallers = new(cgoCallers)
} } å¤åˆ¶ä»£ç è°ƒåº¦å™¨åˆå§‹åŒ–æœ€åä¸€éƒ¨åˆ†å·¥ä½œå°±æ˜¯pçš„åˆå§‹åŒ–
</code></pre></div></div>

<p>åˆå§‹åŒ–è°ƒåº¦åï¼Œå¼€å¯æ–°çš„goroutineè¿è¡Œæˆ‘ä»¬çš„ä¸»ç¨‹åºï¼Œç„¶åè°ƒç”¨runtime.mstartå¼€å¯M.
func mstart() {
	<em>g</em> := getg()</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// é€šè¿‡æ£€æŸ¥ g æ‰§è¡Œå çš„è¾¹ç•Œæ¥ç¡®å®šæ˜¯å¦ä¸ºç³»ç»Ÿæ ˆ
osStack := _g_.stack.lo == 0
if osStack {
	// Initialize stack bounds from system stack.
	// Cgo may have left stack size in stack.hi.
	// minit may update the stack bounds.
	size := _g_.stack.hi
	if size == 0 {
		size = 8192 * sys.StackGuardMultiplier
	}
	_g_.stack.hi = uintptr(noescape(unsafe.Pointer(&amp;size)))
	_g_.stack.lo = _g_.stack.hi - size + 1024
}
// Initialize stack guards so that we can start calling
// both Go and C functions with stack growth prologues.
_g_.stackguard0 = _g_.stack.lo + _StackGuard
_g_.stackguard1 = _g_.stackguard0
// å¯åŠ¨m
mstart1()

// Exit this thread.
if GOOS == "windows" || GOOS == "solaris" || GOOS == "plan9" || GOOS == "darwin" || GOOS == "aix" {
	// Window, Solaris, Darwin, AIX and Plan 9 always system-allocate
	// the stack, but put it in _g_.stack before mstart,
	// so the logic above hasn't set osStack yet.
	osStack = true
}
mexit(osStack) }
</code></pre></div></div>

<p>func mstart1() {
	<em>g</em> := getg()</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if _g_ != _g_.m.g0 {
	throw("bad runtimeÂ·mstart")
}

// Record the caller for use as the top of stack in mcall and
// for terminating the thread.
// We're never coming back to mstart1 after we call schedule,
// so other calls can reuse the current frame.
save(getcallerpc(), getcallersp())
asminit()
minit()

// Install signal handlers; after minit so that minit can
// prepare the thread to be able to handle the signals.
if _g_.m == &amp;m0 {
	mstartm0()
}

if fn := _g_.m.mstartfn; fn != nil {
	fn()
}
// å¦‚æœå½“å‰ m å¹¶é m0ï¼Œåˆ™è¦æ±‚ç»‘å®š p
if _g_.m != &amp;m0 {
	acquirep(_g_.m.nextp.ptr())
	_g_.m.nextp = 0
}
schedule() } å¤åˆ¶ä»£ç åœ¨mstart1ä¸­ï¼Œè°ƒç”¨äº†scheduleå‡½æ•°ï¼šä¸€è½®è°ƒåº¦ç¨‹åºï¼šæ‰¾åˆ°ä¸€ä¸ªå¯è¿è¡Œçš„goroutineå¹¶æ‰§è¡Œå®ƒã€‚æ°¸ä¸return. func schedule() {
_g_ := getg()

if _g_.m.locks != 0 {
	throw("schedule: holding locks")
}

if _g_.m.lockedg != 0 {
	stoplockedm()
	execute(_g_.m.lockedg.ptr(), false) // Never returns.
}

// We should not schedule away from a g that is executing a cgo call,
// since the cgo call is using the m's g0 stack.
if _g_.m.incgo {
	throw("schedule: in cgo")
}
</code></pre></div></div>

<p>top:
	if sched.gcwaiting != 0 {
		gcstopm()
		goto top
	}
	if <em>g</em>.m.p.ptr().runSafePointFn != 0 {
		runSafePointFn()
	}</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var gp *g
var inheritTime bool
if trace.enabled || trace.shutdown {
	gp = traceReader()
	if gp != nil {
		casgstatus(gp, _Gwaiting, _Grunnable)
		traceGoUnpark(gp, 0)
	}
}
if gp == nil &amp;&amp; gcBlackenEnabled != 0 {
	gp = gcController.findRunnableGCWorker(_g_.m.p.ptr())
}
if gp == nil {
	// // è¯´æ˜ä¸åœ¨ GC
	//
	// æ¯è°ƒåº¦ 61 æ¬¡ï¼Œå°±æ£€æŸ¥ä¸€æ¬¡å…¨å±€é˜Ÿåˆ—ï¼Œä¿è¯å…¬å¹³æ€§
	// å¦åˆ™ä¸¤ä¸ª goroutine å¯ä»¥é€šè¿‡äº’ç›¸ respawn ä¸€ç›´å é¢†æœ¬åœ°çš„ runqueue
	if _g_.m.p.ptr().schedtick%61 == 0 &amp;&amp; sched.runqsize &gt; 0 {
		lock(&amp;sched.lock)
		// ä»å…¨å±€é˜Ÿåˆ—ä¸­å· g
		gp = globrunqget(_g_.m.p.ptr(), 1)
		unlock(&amp;sched.lock)
	}
}
if gp == nil {
	gp, inheritTime = runqget(_g_.m.p.ptr())
	if gp != nil &amp;&amp; _g_.m.spinning {
		throw("schedule: spinning with local work")
	}
}
if gp == nil {
	gp, inheritTime = findrunnable() // å¦‚æœå·éƒ½å·ä¸åˆ°ï¼Œåˆ™ä¼‘çœ ï¼Œåœ¨æ­¤é˜»å¡
}

// è¯¥çº¿ç¨‹å°†è¿è¡Œgoroutineï¼Œå¹¶ä¸”ä¸å†è‡ªæ—‹ï¼Œ
// å› æ­¤ï¼Œå¦‚æœå°†å…¶æ ‡è®°ä¸ºæ­£åœ¨è‡ªæ—‹ï¼Œåˆ™éœ€è¦ç«‹å³å°†å…¶é‡ç½®å¹¶å¯èƒ½å¯åŠ¨æ–°è‡ªæ—‹çš„Mã€‚
if _g_.m.spinning {
	resetspinning()
}

if sched.disable.user &amp;&amp; !schedEnabled(gp) {
	// Scheduling of this goroutine is disabled. Put it on
	// the list of pending runnable goroutines for when we
	// re-enable user scheduling and look again.
	lock(&amp;sched.lock)
	if schedEnabled(gp) {
		// Something re-enabled scheduling while we
		// were acquiring the lock.
		unlock(&amp;sched.lock)
	} else {
		sched.disable.runnable.pushBack(gp)
		sched.disable.n++
		unlock(&amp;sched.lock)
		goto top
	}
}

if gp.lockedm != 0 {
	// Hands off own p to the locked m,
	// then blocks waiting for a new p.
	startlockedm(gp)
	goto top
}

// å¼€å§‹æ‰§è¡Œ
execute(gp, inheritTime) }
</code></pre></div></div>

<p>å¤åˆ¶ä»£ç å¦‚æœmå¤„åœ¨è‡ªæ—‹çš„çŠ¶æ€ï¼Œé‚£ä¹ˆå°†è°ƒç”¨resetspinningæ–¹æ³•ï¼Œ
func resetspinning() {
	<em>g</em> := getg()
	if !<em>g</em>.m.spinning {
		throw(â€œresetspinning: not a spinning mâ€)
	}
	<em>g</em>.m.spinning = false
	nmspinning := atomic.Xadd(&amp;sched.nmspinning, -1)
	if int32(nmspinning) &lt; 0 {
		throw(â€œfindrunnable: negative nmspinningâ€)
	}
	// Mçš„å”¤é†’ç­–ç•¥æ•…æ„æœ‰äº›ä¿å®ˆï¼Œå› æ­¤è¯·æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨æ­¤å¤„å”¤é†’å¦ä¸€ä¸ªPã€‚
	// æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§æ–‡ä»¶é¡¶éƒ¨çš„â€œå·¥ä½œçº¿ç¨‹park/unparkâ€æ³¨é‡Šã€‚
	if nmspinning == 0 &amp;&amp; atomic.Load(&amp;sched.npidle) &gt; 0 {
		wakep()
	}
}
å¤åˆ¶ä»£ç wakep()å°è¯•å†æ·»åŠ ä¸€ä¸ªPä»¥æ‰§è¡ŒGã€‚ å½“Gå˜ä¸ºå¯è¿è¡Œæ—¶è°ƒç”¨ï¼ˆnewprocï¼Œå°±ç»ªï¼‰.è¯¥å‡½æ•°ä¼šè°ƒç”¨startm(nil, true).startmå‡½æ•°è°ƒåº¦ä¸€äº›Mä»¥è¿è¡Œpï¼ˆå¿…è¦æ—¶åˆ›å»ºMï¼‰ã€‚ å¦‚æœp == nilï¼Œåˆ™å°è¯•è·å–ä¸€ä¸ªç©ºé—²Pï¼Œå¦‚æœæ²¡æœ‰ç©ºé—²Påˆ™ä¸æ‰§è¡Œä»»ä½•æ“ä½œã€‚ å¯ä»¥ä¸m.p == nilä¸€èµ·è¿è¡Œï¼Œå› æ­¤ä¸å…è®¸å†™éšœç¢ã€‚ å¦‚æœè®¾ç½®äº†æ—‹è½¬ï¼Œåˆ™è°ƒç”¨è€…å·²å¢åŠ nmspinningï¼Œå¹¶ä¸”startmå°†å‡å°‘nmspinningæˆ–åœ¨æ–°å¯åŠ¨çš„Mä¸­è®¾ç½®m.spinningã€‚</p>
:ET