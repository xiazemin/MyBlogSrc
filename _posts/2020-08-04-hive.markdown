---
title: pyspark hive
layout: post
category: storage
author: 夏泽民
---
from pyspark.sql import SparkSession, HiveContext
 
_SPARK_HOST = "spark://spark-master:7077"
_APP_NAME = "test"
 
spark = SparkSession.builder.master(_SPARK_HOST).appName(_APP_NAME).getOrCreate()
 
data = [
    (1,"3","145"),
    (1,"4","146"),
    (1,"5","25"),
    (1,"6","26"),
    (2,"32","32"),
    (2,"8","134"),
    (2,"8","134"),
    (2,"9","137")
]
df = spark.createDataFrame(data, ['id', "test_id", 'camera_id'])
 
# method one，default是默认数据库的名字，write_test 是要写到default中数据表的名字
df.registerTempTable('test_hive')
sqlContext.sql("create table default.write_test select * from test_hive")
<!-- more -->
https://blog.csdn.net/u011412768/article/details/93426353

spark用上面几种方式读写hive时，需要在提交任务时加上相应的配置,不然会报错：

spark-submit --conf spark.sql.catalogImplementation=hive test.py

Python中最常见括号的区别：

在Python语言中最常见的括号有三种，分别是：小括号（）、中括号[]、花括号{}；其作用也不相同，分别用来代表不同的Python基本内置数据类型。

Python中的小括号（）：

代表tuple元祖数据类型，元祖是一种不可变序列。创建方法很简单，大多数时候都是小括号括起来的。

　

复制代码
1 >>> tup = (1,2,3)
2 >>> tup
3 (1, 2, 3)
4 >>> () #空元祖
5 ()
6 >>> 55,#一个值的元祖
7 (55,)
复制代码
Python中的中括号[]：
代表list列表数据类型，列表是一种可变序列。创建方法既简单又特别。
1 >>> list('Python')
2 ['P', 'y', 't', 'h', 'o', 'n']
 

Python中的花括号{}：
代表dict字典数据类型，字典是Python中唯一内建的映射类型。字典中的值没有特殊的顺序，但都是存储在一个特定的键（key）下。键可以是数字、字符串甚至是元祖。
1 >>> dic = {'jon':'boy','lili"':'girl'}
2 >>> dic
3 {'jon': 'boy', 'lili"': 'girl'}