---
title: spark基本概念
layout: post
category: spark
author: 夏泽民
---
<!-- more -->
我们知道Spark总是以集群的方式运行的，Standalone的部署方式是集群方式中最为精简的一种（另外的是Mesos和Yarn）。Standalone模式中，资源调度是自己实现的，是MS架构的集群模式，故存在单点故障问题。
下面提出几个问题并解决：
1、Standalone部署方式下包含哪些节点？

由不同级别的三个节点组成，分别是Master主控节点、Worker工作节点、客户端节点；
（1）其中Master主控节点，顾名思义，类似于领导者，在整个集群中，最多只有一个Master处于Active状态。在使用spark-shell等交互式运行或者使用官方提供的run-example实例时，Driver运行在Master节点中；若是使用spark-submit工具进行任务的提交或者IDEA等工具开发运行任务时，Driver是运行在本地客户端的。
Master一方面负责各种信息，比如Driver、Worker、Application的注册；另一方面还负责Executor的启动，Worker心跳等诸多信息的处理。
（2）Woker节点，类似于yarn中的NodeManager，在整个集群中，可以有多个Worker（>0）。负责当前WorkerNode上的资源汇报、监督当前节点运行的Executor。并通过心跳机制来保持和Master的存活性连接。Executor受到Worker掌控，一个Worker启动Executor的个数受限于 机器中CPU核数。每个Worker节点存在一个多个CoarseGrainedExecutorBackend进程，每个进程包含一个Executor对象，该对象持有一个线程池，每个线程执行一个Task。
2、基本的概念？

（1）Application：指的是用户编写的Spark应用程序，包含了含有一个Driver功能的代码和分布在集群中多个节点上运行的Executor代码。
（2）Driver:运行Application的main函数并创建SparkContext，SparkContext的目的是为了准备Spark应用程序的运行环境。SparkContext负责资源的申请、任务分配和监控等。当Executor运行结束后，Driver负责关闭SparkContext；
（3）Job：一个Application可以产生多个Job，其中Job由Spark Action触发产生。每个Job包含多个Task组成的并行计算。
（4）Stage：每个Job会拆分为多个Task，作为一个TaskSet,称为Stage；Stage的划分和调度是由DAGScheduler负责的。Stage分为Result Stage和Shuffle Map Stage；
（5）Task：Application的运行基本单位，Executor上的工作单元。其调度和 管理又TaskScheduler负责。
（6）RDD：Spark基本计算单元，是Spark最核心的东西。表示已被分区、被序列化、不可变的、有容错机制的、能被并行操作的数据集合。
(7) DAGScheduler:根据Job构建基于Stage的DAG，划分Stage依据是RDD之间的依赖关系。
（8）TaskScheduler：将TaskSet提交给Worker运行，每个Worker运行了什么Task于此处分配。同时还负责监控、汇报任务运行情况等。
3、Standalone启动过程是啥？

（1）首先，启动master，worker节点。
worker启动后触发Master的RegisterWorker事件，进行注册。主要讲要注册的Worker信息封装成WorkerInfo对象，包括Worker节点的CPU、内存等基本信息。记录Worker的信息（IP、Address）到master缓存中（HashMap），若Worker节点的注册信息有效，持久化已注册的Worker信息。然后给个完成注册的反馈信号。
（2）提交Application
运行spark-shell时，会由Driver端的DAGScheduler向Master发送RegisterApplication请求。根据此请求信息会创建ApplicationInfo对象，将Application加入到Master的缓存apps中，这个结构是HashSet。
如果worker已经注册，发送lanchExecutor指令给相应的Worker。
（3）Worker收到lanchExecutor后，会由ExecutorRunner启动Excutor进程，启动的Executor进程会根据启动时的入参，将自己注册到Drive中的ScheduleBackend。
(4)ScheduleBackend收到Excutor的注册信息后，会将提交到的Spark Job分解为多个具体的Task，然后通过LaunchTask指令将这些Task分散到各个Executor上运行。
4、Standalone部署方式下某一节点出现问题时，系统如何处理？

出现问题的节点可能发生的情况有三种：
（1）Master崩掉了：这个坏掉了，就真的没法完了。单点故障的问题。
有两种解决办法：第一种基于文件系统的故障恢复，适合Master进程本身挂掉，那直接重启就Ok了。
第二种是基于ZookerKeep的HA方式。此方式被许多的分布式框架使用。
（2）某一Worker崩掉了：
若是所有的Worker挂掉，则整个集群就不可用；
Worker退出之前，会将管控的所有Executor进程kill；由于Worker挂掉，不能向master玩心跳了，根据超时处理会知道Worker挂了，然后Master将相应的情况汇报给Driver。Driver会根据master的信息和没有收到Executor的StatusUpdate确定这个Worker挂了，则Driver会将这个注册的Executor移除。
（3）某Worker的Excutor崩掉了：
Excutor的作为一个独立的进程在运行，由ExcutorRunner线程启动，并收到ExcutorRunner的监控，当Excutor挂了，ExcutorRunner会注意到异常情况，将ExecutorStateChanged汇报给Master，master会再次发送lanchExecutor指令给相应的Worker启动相应的Excutor。
