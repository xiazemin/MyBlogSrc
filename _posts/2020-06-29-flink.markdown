---
title: flink
layout: post
category: storage
author: 夏泽民
---
flink的sink是flink三大逻辑结构之一（source，transform，sink）,功能就是负责把flink处理后的数据输出到外部系统中，flink 的sink和source的代码结构类似。
Source  数据源  ---- > Compute  计算 -----> sink 落库

我们可以使用flink已经提供的sink，如kafka，jdbc,es等，当然我们也可以通过自定义的方式，来实现我们自己的sink。
<!-- more -->
flinkStreamSQL
基于开源的flink，对其实时sql进行扩展
自定义create table 语法（包括源表,输出表,维表）
自定义create view 语法
自定义create function 语法
实现了流与维表的join
支持原生FLinkSQL所有的语法
扩展了输入和输出的性能指标到promethus
新特性:
1.kafka源表支持not null语法,支持字符串类型的时间转换。
2.rdb维表与DB建立连接时，周期进行连接，防止连接断开。rdbsink写入时，对连接进行检查。
3.异步维表支持非等值连接，比如：<>,<,>。
4.增加kafka数组解析
5.增加kafka1.0以上版本的支持
6.增加postgresql、kudu、clickhouse维表、结果表的支持
7.支持插件的依赖方式,参考pluginLoadMode参数
8.支持cep处理
9.支持udaf
10.支持谓词下移
https://gitee.com/sunflower-git/flinkStreamSQL/

https://www.cnblogs.com/Springmoon-venn/p/11934995.html
根据官网Structure of Table API and SQL Programs的样例介绍，如果要测试一个streaming SQL，需要注册一个table source，然后执行一个SQL，最后在注册一个table sink并将结果插入。table source和table sink有很多种，本文将介绍基于内存的table source和sink方便进行测试sql。

https://www.jianshu.com/p/0b7869ee6417?utm_campaign=hugo

https://www.jianshu.com/p/9cfe9ff4609a

flink自定义source与自定义sink
flink 的source和sink即数据源和数据接收器。在原生的flink中提供了一些常用的数据源连接器，但是在日常开发中我们所使用的数据源和持久化工具是多种多样的，flink提供的 source和sink就不能满足我们的需求，这时就需要使用flink提供的接口自定义source和sink。

https://blog.csdn.net/k_wzzc/article/details/89888144

https://zhuanlan.zhihu.com/p/88307415
https://www.jianshu.com/p/63e12e7a9548
https://www.cnblogs.com/Allen-rg/p/11593245.html
https://www.jianshu.com/p/3af6b79b9beb
https://www.aboutyun.com/thread-26858-1-1.html

https://www.jianshu.com/p/441e9d1f739f
https://www.jianshu.com/p/2febf2216cbe
https://www.jianshu.com/p/3af6b79b9beb
https://blog.csdn.net/weixin_40318210/article/details/86762313

https://www.cnblogs.com/linkmust/p/10896051.html

flink在流处理上的source和在批处理上的source基本一致。大致有4大类

1.基于本地集合的source（Collection-based-source）

2.基于文件的source（File-based-source）

3.基于网络套接字的source（Socket-based-source）

4.自定义的source（Custom-source）

https://www.cnblogs.com/niutao/p/10548609.html