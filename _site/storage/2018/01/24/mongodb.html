<!DOCTYPE html>
<html>

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Sci blog jekyll theme">
    <meta name="author" content="AIR RAYA Group">
    <link href='/MyBlog/img/favicon.ico' type='image/icon' rel='shortcut icon'/>

    <title>泽民博客 | Jekyll theme</title>

    <link rel="stylesheet" href="/MyBlog/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="/MyBlog/css/font-awesome.min.css">
    <link href="/MyBlog/css/simple-sidebar.css" rel="stylesheet">
	<link href="/MyBlog/css/classic-10_7.css" rel="stylesheet" type="text/css">
    <!-- Custom CSS -->
    <link href="/MyBlog/css/style.css" rel="stylesheet">
    <link href="/MyBlog/css/pygments.css" rel="stylesheet">
    <!-- Fonts -->
 <link href="/MyBlog/css/front.css" rel="stylesheet" type="text/css">
 <link href="/MyBlog/css/Josefin_Slab.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Architects_Daughter.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Schoolbell.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Codystar.css" rel="stylesheet" type="text/css">

 <script type="text/javascript" src="/MyBlog/js/jquery-1.12.0.min.js"></script>	

<link href="/MyBlog/css/calendar/common.css" type="text/css"  rel="stylesheet">
<script type="text/javascript" src="/MyBlog/js/calendar/calendar.js"></script>
	<!-- share this -->
	<script type="text/javascript">var switchTo5x=true;</script>
	<script type="text/javascript" src="/MyBlog/js/buttons.js"></script>
	<script type="text/javascript">stLight.options({publisher: "b28464c3-d287-4257-ad18-058346dd35f7", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="/MyBlog/js/html5shiv.js"></script>
        <script src="/MyBlog/js/respond.min.js"></script>
    <![endif]-->
   
   <!--百度统计-->
    <script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e965cab8c73512b8b23939e7051d93bd";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <script async src="/MyBlog/katex/katex.js"></script>
    <link rel="stylesheet" href="/MyBlog/katex/katex.css">

    <!--轮播图片-->
    <!--script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.stripesrotator.js"></script>
    <script type="text/javascript">
                    $(document).ready(function() {
                    alert($('#rotator_xzm'));
                     alert($('#rotator_xzm').fn);
                    $('#rotator_xzm').stripesRotator({ images: [ "https://xiazemin.github.io/MyBlog/img/BPlusTree.png", "https://xiazemin.github.io/MyBlog/img/linuxMMap.jpeg"] });
                    });
    </script-->

    <!--水印-->
    <script type="text/javascript" src="/MyBlog/js/waterMark.js"></script>
    <script type="text/javascript">
    $(document).ready(function(){
    watermark({watermark_txt0:'泽民博客',watermark_txt1:'zemin',watermark_txt2:(new Date()).Format("yyyy-MM-dd hh:mm:ss.S")});
    })
    </script>
     <!--水印-->
     <!--adscene-->
    <script data-ad-client="ca-pub-6672721494777557" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

</head>

 <body>
<div id="wrapper">
 <!-- Navigation -->
    <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="/MyBlog">
                        Home
                    </a>
                </li>
                <li>
                    <a href="#">About</a>
                </li>
                <li>
                    <a href="#">Services</a>
                </li>
                <li>
                    <a href="#">Portfolio</a>
                </li>
                <li>
                    <a href="#">Events</a>
                </li>
                <li>
                    <a href="#">Blog</a>
                </li>
                <li>
                    <a href="#">FAQ</a>
                </li>
                <li>
                    <a href="#">Contact</a>
                </li>
            </ul>
        </div>


    <header class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="heading text-center">
                        <a href="https://xiazemin.github.io/MyBlog/" style="color: #fff; font-size: 4em; font-family: 'Schoolbell', cursive;">泽民博客</a>
                        <a href="#menu-toggle" class="btn btn-default sciblog" id="menu-toggle" style="font-weight: bold;">&#9776; Menu</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

     <script async src="/MyBlog/js/busuanzi.pure.mini.js"></script>

    <script type="text/javascript" src="/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="/MyBlog/js/jquery.stripesrotator.js"></script>


 <div class="container">
	<div class="row">
        <div class="box">
                <div class="col-lg-12">
                    <div class="intro-text text-center">
					<h1 class="post-title" itemprop="name headline">mongodb</h1>
					<p class="post-meta"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">by 夏泽民</span></span> <time datetime="2018-01-24T00:00:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Jan 24, 2018</time></p>
					</div>
					 <!-- more --><br />
<p>一、概念：</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  分片（sharding）是指将数据库拆分，将其分散在不同的机器上的过程。将数据分散到不同的机器上，不需要功能强大的服务器就可以存储更多的数据和处理更大的负载。基本思想就是将集合切成小块，这些块分散到若干片里，每个片只负责总数据的一部分，最后通过一个均衡器来对各个分片进行均衡（数据迁移）。通过一个名为mongos的路由进程进行操作，mongos知道数据和片的对应关系（通过配置服务器）。大部分使用场景都是解决磁盘空间的问题，对于写入有可能会变差（+++里面的说明+++），查询则尽量避免跨分片查询。使用分片的时机：<br />
</code></pre></div></div><br />
<br />
<p>1，机器的磁盘不够用了。使用分片解决磁盘空间的问题。<br />
2，单个mongod已经不能满足写数据的性能要求。通过分片让写压力分散到各个分片上面，使用分片服务器自身的资源。<br />
3，想把大量数据放到内存里提高性能。和上面一样，通过分片使用分片服务器自身的资源。<br />
二、部署安装： 前提是安装了mongodb（本文用3.0测试）</p><br />
<br />
<p>在搭建分片之前，先了解下分片中各个角色的作用。</p><br />
<br />
<p>① 配置服务器。是一个独立的mongod进程，保存集群和分片的元数据，即各分片包含了哪些数据的信息。最先开始建立，启用日志功能。像启动普通的mongod一样启动配置服务器，指定configsvr选项。不需要太多的空间和资源，配置服务器的1KB空间相当于真是数据的200MB。保存的只是数据的分布表。当服务不可用，则变成只读，无法分块、迁移数据。<br />
② 路由服务器。即mongos，起到一个路由的功能，供程序连接。本身不保存数据，在启动时从配置服务器加载集群信息，开启mongos进程需要知道配置服务器的地址，指定configdb选项。<br />
③ 分片服务器。是一个独立普通的mongod进程，保存数据信息。可以是一个副本集也可以是单独的一台服务器。<br />
部署环境：3台机子</p><br />
<br />
<p>A：配置(3)、路由1、分片1；</p><br />
<br />
<p>B：分片2，路由2；</p><br />
<br />
<p>C：分片3</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  在部署之前先明白片键的意义，一个好的片键对分片至关重要。片键必须是一个索引，数据根据这个片键进行拆分分散。通过sh.shardCollection加会自动创建索引。一个自增的片键对写入和数据均匀分布就不是很好，因为自增的片键总会在一个分片上写入，后续达到某个阀值可能会写到别的分片。但是按照片键查询会非常高效。随机片键对数据的均匀分布效果很好。注意尽量避免在多个分片上进行查询。在所有分片上查询，mongos会对结果进行归并排序。<br />
</code></pre></div></div><br />
<br />
<p>启动上面这些服务，因为在后台运行，所以用配置文件启动，配置文件说明。</p><br />
<br />
<p>1）配置服务器的启动。(A上开启3个，Port：20000、21000、22000)</p><br />
<br />
<p>配置服务器是一个普通的mongod进程，所以只需要新开一个实例即可。配置服务器必须开启1个或则3个，开启2个则会报错：</p><br />
<br />
<p>BadValue need either 1 or 3 configdbs<br />
因为要放到后台用用配置文件启动，需要修改配置文件：</p><br />
<br />
<p>/etc/mongod_20000.conf</p><br />
<br />
<p>复制代码<br />
#数据目录<br />
dbpath=/usr/local/config/<br />
#日志文件<br />
logpath=/var/log/mongodb/mongodb_config.log<br />
#日志追加<br />
logappend=true<br />
#端口<br />
port = 20000<br />
#最大连接数<br />
maxConns = 50<br />
pidfilepath = /var/run/mongo_20000.pid<br />
#日志,redo log<br />
journal = true<br />
#刷写提交机制<br />
journalCommitInterval = 200<br />
#守护进程模式<br />
fork = true<br />
#刷写数据到日志的频率<br />
syncdelay = 60<br />
#storageEngine = wiredTiger<br />
#操作日志,单位M<br />
oplogSize = 1000<br />
#命名空间的文件大小,默认16M，最大2G。<br />
nssize = 16<br />
noauth = true<br />
unixSocketPrefix = /tmp<br />
configsvr = true<br />
复制代码<br />
/etc/mongod_21000.conf</p><br />
<br />
<p>复制代码<br />
数据目录<br />
dbpath=/usr/local/config1/<br />
#日志文件<br />
logpath=/var/log/mongodb/mongodb_config1.log<br />
#日志追加<br />
logappend=true<br />
#端口<br />
port = 21000<br />
#最大连接数<br />
maxConns = 50<br />
pidfilepath = /var/run/mongo_21000.pid<br />
#日志,redo log<br />
journal = true<br />
#刷写提交机制<br />
journalCommitInterval = 200<br />
#守护进程模式<br />
fork = true<br />
#刷写数据到日志的频率<br />
syncdelay = 60<br />
#storageEngine = wiredTiger<br />
#操作日志,单位M<br />
oplogSize = 1000<br />
#命名空间的文件大小,默认16M，最大2G。<br />
nssize = 16<br />
noauth = true<br />
unixSocketPrefix = /tmp<br />
configsvr = true<br />
复制代码<br />
开启配置服务器：</p><br />
<br />
<p>复制代码<br />
root@mongo1:~# mongod -f /etc/mongod_20000.conf <br />
about to fork child process, waiting until server is ready for connections.<br />
forked process: 8545<br />
child process started successfully, parent exiting</p><br />
<br />
<p>root@mongo1:~# mongod -f /etc/mongod_21000.conf <br />
about to fork child process, waiting until server is ready for connections.<br />
forked process: 8595<br />
child process started successfully, parent exiting<br />
复制代码<br />
同理再起一个22000端口的配置服务器。</p><br />
<br />
<p>View Code<br />
2）路由服务器的启动。(A、B上各开启1个，Port：30000)</p><br />
<br />
<p>路由服务器不保存数据，把日志记录一下即可。</p><br />
<br />
<p>复制代码</p><br />
<h1 id="mongos">mongos</h1><br />
<br />
<p>#日志文件<br />
logpath=/var/log/mongodb/mongodb_route.log<br />
#日志追加<br />
logappend=true<br />
#端口<br />
port = 30000<br />
#最大连接数<br />
maxConns = 100<br />
#绑定地址<br />
#bind_ip=192.168.200.*,…,</p><br />
<br />
<p>pidfilepath = /var/run/mongo_30000.pid</p><br />
<br />
<p>configdb=192.168.200.A:20000,192.168.200.A:21000,192.168.200.A:22000  #必须是1个或则3个配置 。<br />
#configdb=127.0.0.1:20000  #报错<br />
#守护进程模式 fork = true<br />
复制代码<br />
其中最重要的参数是configdb，不能在其后面带的配置服务器的地址写成localhost或则127.0.0.1，需要设置成其他分片也能访问的地址，即192.168.200.A:20000/21000/22000。否则在addshard的时候会报错：</p><br />
<br />
<p>{<br />
“ok” : 0,<br />
“errmsg” : “can’t use localhost as a shard since all shards need to communicate. either use all shards and configdbs in localhost or all in actual IPs  host: 172.16.5.104:20000 isLocalHost:0”<br />
}<br />
开启mongos：</p><br />
<br />
<p>root@mongo1:~# mongos -f /etc/mongod_30000.conf <br />
2015-07-10T14:42:58.741+0800 W SHARDING running with 1 config server should be done only for testing purposes and is not recommended for production<br />
about to fork child process, waiting until server is ready for connections.<br />
forked process: 8965<br />
child process started successfully, parent exiting<br />
3）分片服务器的启动：</p><br />
<br />
<p>就是一个普通的mongod进程：</p><br />
<br />
<p>root@mongo1:~# mongod -f /etc/mongod_40000.conf <br />
note: noprealloc may hurt performance in many applications<br />
about to fork child process, waiting until server is ready for connections.<br />
forked process: 9020<br />
child process started successfully, parent exiting<br />
A服务器上面的服务开启完毕</p><br />
<br />
<p>root@mongo1:~# ps -ef | grep mongo<br />
root      9020     1  0 14:47 ?        00:00:06 mongod -f /etc/mongod_40000.conf<br />
root      9990     1  0 15:14 ?        00:00:02 mongod -f /etc/mongod_20000.conf<br />
root     10004     1  0 15:14 ?        00:00:01 mongod -f /etc/mongod_21000.conf<br />
root     10076     1  0 15:20 ?        00:00:00 mongod -f /etc/mongod_22000.conf<br />
root     10096     1  0 15:20 ?        00:00:00 mongos -f /etc/mongod_30000.conf<br />
按照上面的方法再到B上开启分片服务和路由服务(配置文件一样)，以及在C上开启分片服务。到此分片的配置服务器、路由服务器、分片服务器都已经部署完成。</p><br />
<br />
<p>三、配置分片：下面的操作都是在mongodb的命令行里执行</p><br />
<br />
<p>1）添加分片：sh.addShard(“IP:Port”)</p><br />
<br />
<p>登陆路由服务器mongos 操作：</p><br />
<br />
<p>root@mongo1:~# mongo –port=30000<br />
MongoDB shell version: 3.0.4<br />
connecting to: 127.0.0.1:30000/test<br />
mongos&gt; <br />
添加分片：</p><br />
<br />
<p>复制代码<br />
mongos&gt; sh.status()    #查看集群的信息<br />
— Sharding Status — <br />
  sharding version: {<br />
    “_id” : 1,<br />
    “minCompatibleVersion” : 5,<br />
    “currentVersion” : 6,<br />
    “clusterId” : ObjectId(“559f72470f93270ba60b26c6”)<br />
}<br />
  shards:<br />
  balancer:<br />
    Currently enabled:  yes<br />
    Currently running:  no<br />
    Failed balancer rounds in last 5 attempts:  0<br />
    Migration Results for the last 24 hours: <br />
        No recent migrations<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }</p><br />
<br />
<p>mongos&gt; sh.addShard(“192.168.200.A:40000”) #添加分片<br />
{ “shardAdded” : “shard0000”, “ok” : 1 }<br />
mongos&gt; sh.addShard(“192.168.200.B:40000”) #添加分片<br />
{ “shardAdded” : “shard0001”, “ok” : 1 }<br />
mongos&gt; sh.addShard(“192.168.200.C:40000”) #添加分片<br />
{ “shardAdded” : “shard0002”, “ok” : 1 }</p><br />
<br />
<p>mongos&gt; sh.status()    #查看集群信息<br />
— Sharding Status — <br />
  sharding version: {<br />
    “_id” : 1,<br />
    “minCompatibleVersion” : 5,<br />
    “currentVersion” : 6,<br />
    “clusterId” : ObjectId(“559f72470f93270ba60b26c6”)<br />
}<br />
  shards:  #分片信息<br />
    {  “_id” : “shard0000”,  “host” : “192.168.200.A:40000” }<br />
    {  “_id” : “shard0001”,  “host” : “192.168.200.B:40000” }<br />
    {  “_id” : “shard0002”,  “host” : “192.168.200.C:40000” }<br />
  balancer:<br />
    Currently enabled:  yes<br />
    Currently running:  no<br />
    Failed balancer rounds in last 5 attempts:  0<br />
    Migration Results for the last 24 hours: <br />
        No recent migrations<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
复制代码<br />
2）开启分片功能：sh.enableSharding(“库名”)、sh.shardCollection(“库名.集合名”,{“key”:1})</p><br />
<br />
<p>复制代码<br />
mongos&gt; sh.enableSharding(“dba”)  #首先对数据库启用分片<br />
{ “ok” : 1 }<br />
mongos&gt; sh.status()               #查看分片信息<br />
— Sharding Status —…<br />
…<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }</p><br />
<br />
<p>mongos&gt; sh.shardCollection(“dba.account”,{“name”:1})    #再对集合进行分片，name字段是片键。片键的选择：利于分块、分散写请求、查询数据。<br />
{ “collectionsharded” : “dba.account”, “ok” : 1 }<br />
mongos&gt; sh.status()<br />
— Sharding Status —…<br />
  shards:<br />
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }<br />
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }<br />
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }<br />
…<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }  #库<br />
        dba.account<br />
            shard key: { “name” : 1 }                                    #集合<br />
            chunks:<br />
                shard0000    1<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(1, 0) <br />
复制代码<br />
上面加粗部分表示分片信息已经配置完成。要是出现：</p><br />
<br />
<p>too many chunks to print, use verbose if you want to force print<br />
想要看到详细的信息则需要执行：</p><br />
<br />
<p>mongos&gt; sh.status({“verbose”:1})<br />
或则<br />
mongos&gt; db.printShardingStatus(“vvvv”)<br />
或则<br />
mongos&gt; printShardingStatus(db.getSisterDB(“config”),1)<br />
四、测试 ：对dba库的account集合进行测试，随机写入，查看是否分散到3个分片中。</p><br />
<br />
<p>判断是否为shard：db.runCommand({isdbgrid:1})</p><br />
<br />
<p>mongos&gt; db.runCommand({isdbgrid:1})<br />
{ “isdbgrid” : 1, “hostname” : “mongo3c”, “ok” : 1 }<br />
通过一个python脚本进行随机写入：分别向A、B 2个mongos各写入10万条记录。</p><br />
<br />
<p>View Code<br />
查看是否分片：db.collection.stats()</p><br />
<br />
<p>复制代码<br />
mongos&gt; db.account.stats() #查看集合的分布情况<br />
…<br />
…<br />
    “shards” : {<br />
        “shard0000” : {<br />
            “ns” : “dba.account”,<br />
            “count” : 89710,<br />
            “size” : 10047520,<br />
…<br />
…<br />
        “shard0001” : {<br />
            “ns” : “dba.account”,<br />
            “count” : 19273,<br />
            “size” : 2158576,<br />
…<br />
…<br />
        “shard0002” : {<br />
            “ns” : “dba.account”,<br />
            “count” : 91017,<br />
            “size” : 10193904,<br />
…<br />
…<br />
复制代码<br />
上面加粗部分为集合的基本信息，可以看到分片成功，各个分片都有数据(count)。到此MongoDB分片集群搭建成功。</p><br />
<br />
<p>++++++++++++++++++++++++++++++++++++++++++++++++</p><br />
<br />
<p>感兴趣的同学可以看下面这个比较有趣的现象：</p><br />
<br />
<p>复制代码<br />
#在写之前分片的基本信息：<br />
mongos&gt; sh.status()<br />
— Sharding Status — <br />
…<br />
…<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }<br />
        dba.account<br />
            shard key: { “name” : 1 }<br />
            chunks:<br />
                shard0000    1<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(1, 0)   #可以看到这里片键的写入，都是写在shard0000里面的。</p><br />
<br />
<p>#在写期间的分片基本信息：<br />
mongos&gt; sh.status()<br />
— Sharding Status — <br />
…<br />
…<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }<br />
        dba.account<br />
            shard key: { “name” : 1 }<br />
            chunks:          #数据块分布<br />
                shard0000    1<br />
                shard0001    1<br />
                shard0002    1<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) <br />
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 0) <br />
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(3, 1)   #可以看到片键写入的基本分布</p><br />
<br />
<p>#在写完成后的基本信息：<br />
mongos&gt; sh.status()<br />
— Sharding Status — <br />
…<br />
…<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }<br />
        dba.account<br />
            shard key: { “name” : 1 }<br />
            chunks:          #数据块分布<br />
                shard0000    2<br />
                shard0001    1<br />
                shard0002    2<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) <br />
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : shard0000 Timestamp(4, 0) <br />
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) <br />
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) <br />
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(3, 1)  #最后片键写入的分布<br />
复制代码<br />
上面加粗的信息对比上看到，本来在每个分片上都只有一个块，最后在shard0000、shard0002上有2个块，被拆分了。shard0001不变。这是因为mongos在收到写请求的时候，会检查当前块的拆分阀值点。到达该阀值的时候，会向分片发起一个拆分的请求。例子中shard0000和shard0002里的块被拆分了。分片内的数据进行了迁移（有一定的消耗），最后通过一个均衡器来对数据进行转移分配。所以在写入途中要是看到一个分片中集合的数量变小也是正常的。</p><br />
<br />
<p>balancer:  #均衡器<br />
    Currently enabled:  yes<br />
    Currently running:  yes   #正在转移<br />
        Balancer lock taken at Fri Jul 10 2015 22:57:27 GMT+0800 (CST) by mongo2:30000:1436540125:1804289383:Balancer:846930886<br />
均衡器：均衡器负责数据迁移，周期性的检查分片是否存在不均衡，如果不存在则会开始块的迁移，config.locks集合里的state表示均衡器是否找正在运行，0表示非活动状态，2表示正在均衡。均衡迁移数据的过程会增加系统的负载：目标分片必须查询源分片的所有文档，将文档插入目标分片中，再清除源分片的数据。可以关闭均衡器（不建议）：关闭会导致各分片数据分布不均衡，磁盘空间得不到有效的利用。</p><br />
<br />
<p>mongos&gt; sh.setBalancerState(false)  #关闭自动均衡器，手动均衡，打开：sh.setBalancerState(true)<br />
mongos&gt; db.settings.find()          #查看均衡器状态<br />
{ “_id” : “balancer”, “stopped” : true }<br />
可以为均衡器设置一个均衡时间窗口：activeWindow</p><br />
<br />
<p>mongos&gt; db.settings.update({“_id”:”balancer”},{“$set”:{“activeWindow”:{“start”:”08:00”,”stop”:”02:00”}}},true)<br />
WriteResult({ “nMatched” : 1, “nUpserted” : 0, “nModified” : 1 })<br />
mongos&gt; db.settings.find({“_id”:”balancer”})<br />
{ “_id” : “balancer”, “stopped” : false, “activeWindow” : { “start” : “08:00”, “stop” : “02:00” } }<br />
上面说明：均衡只会在早上8点到凌晨2点进行均衡操作。均衡器是以块的数量作为迁移指标，而非数据大小，块的大小默认是64M，可以修改:(config.settings)</p><br />
<br />
<p>mongos&gt; db.settings.find()<br />
{ “_id” : “chunksize”, “value” : 64 }<br />
mongos&gt; db.settings.save({“_id”:”chunksize”,”value”:32})<br />
WriteResult({ “nMatched” : 1, “nUpserted” : 0, “nModified” : 1 })<br />
mongos&gt; db.settings.find()<br />
{ “_id” : “chunksize”, “value” : 32 }<br />
上面把块的默认大小改成了32M，除了通过均衡器自动迁移外，还可以手动迁移数据：sh.moveChunk(“db.collection”,{块地址},”新片名称”)</p><br />
<br />
<p>复制代码<br />
mongos&gt; db.chunks.find({“<em>id” : “abc.account-name</em>"wPeFnJEvendSTbH"”}).pretty() #先到config.chunks上任意找一个块<br />
{<br />
    “<em>id” : “abc.account-name</em>"wPeFnJEvendSTbH"”,<br />
    “lastmod” : Timestamp(3, 1),<br />
    “lastmodEpoch” : ObjectId(“55a52ff1fdd9a605a0371327”),<br />
    “ns” : “abc.account”,<br />
    “min” : {<br />
        “name” : “wPeFnJEvendSTbH”              #被移动的块<br />
    },<br />
    “max” : {<br />
        “name” : { “$maxKey” : 1 }<br />
    },<br />
    “shard” : “shard0000”                       #原先所在的分片<br />
}<br />
mongos&gt; sh.moveChunk(“abc.account”,{“name” : “wPeFnJEvendSTbH”},”mablevi”)  #把abc.account集合中包含name(片键)为”“的快迁移到mablevi分片中<br />
{ “millis” : 6800, “ok” : 1 }<br />
mongos&gt; db.chunks.find({“<em>id” : “abc.account-name</em>"wPeFnJEvendSTbH"”}).pretty()<br /><br />
{<br />
    “<em>id” : “abc.account-name</em>"wPeFnJEvendSTbH"”,<br />
    “lastmod” : Timestamp(5, 0),<br />
    “lastmodEpoch” : ObjectId(“55a52ff1fdd9a605a0371327”),<br />
    “ns” : “abc.account”,<br />
    “min” : {<br />
        “name” : “wPeFnJEvendSTbH”<br />
    },<br />
    “max” : {<br />
        “name” : { “$maxKey” : 1 }<br />
    },<br />
    “shard” : “mablevi”                        #已被迁移到新片<br />
}<br />
复制代码<br />
上面是手动移动数据的操作，数据被移动。 要是块超出了64M限制【原因是片键没选好(日期、状态值等)，导致一个块无限增大】，则无法进行自动均衡，无法分块。有2个办法：1是加大块的大小(setting)，2是拆分sh.splitAt()（推荐）。</p><br />
<br />
<p>所以要是遇到分片写入比单点写入慢就是因为分片路由服务（mongos）需要维护元数据、数据迁移、路由开销等。</p><br />
<br />
<p>++++++++++++++++++++++++++++++++++++++++++++++++</p><br />
<br />
<p>五、高可用：Sharding+Replset</p><br />
<br />
<p>上面的分片都是单点的，要是一个分片坏了，则数据会丢失，利用之前减少的副本集，能否把副本集加入到分片中？下面就来说明下。</p><br />
<br />
<p>1）添加副本集分片服务器（mmm副本集名称）：这里测试就只对一个分片加副本集，要实现完全的高可用就需要对所有分片加副本集，避免单点故障</p><br />
<br />
<p>一个普通的副本集：</p><br />
<br />
<p>View Code<br />
现在需要把这个副本集加入到分片中：</p><br />
<br />
<p>复制代码<br />
mongos&gt; sh.addShard(“mmm/192.168.200.25:27017,192.168.200.245:27017,192.168.200.245:37017”) #加入副本集分片<br />
{ “shardAdded” : “mmm”, “ok” : 1 }</p><br />
<br />
<p>mongos&gt; sh.status()<br />
— Sharding Status — <br />
…<br />
…<br />
shards:<br />
    {  “_id” : “mmm”,  “host” : “mmm/192.168.200.245:27017,192.168.200.245:37017,192.168.200.25:27017” }<br />
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }<br />
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }<br />
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }<br />
  balancer:<br />
    Currently enabled:  yes<br />
    Currently running:  no<br />
    Failed balancer rounds in last 5 attempts:  0<br />
    Migration Results for the last 24 hours: <br />
        4 : Success<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }<br />
        dba.account<br />
            shard key: { “name” : 1 }<br />
            chunks:<br />
                mmm    1<br />
                shard0000    1<br />
                shard0001    1<br />
                shard0002    2<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) <br />
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : mmm Timestamp(5, 0) <br />
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) <br />
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) <br />
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(5, 1) <br />
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }   #未设置分片<br />
复制代码<br />
上面加粗部分表示副本集分片已经成功加入，并且新加入的分片会分到已有的分片数据。</p><br />
<br />
<p>复制代码<br />
mongos&gt; db.account.stats()<br />
…<br />
…<br />
    “shards” : {<br />
        “mmm” : {<br />
            “ns” : “dba.account”,<br />
            “count” : 7723,        #后加入的分片得到了数据<br />
            “size” : 741408,<br />
            “avgObjSize” : 96,<br />
            “storageSize” : 2793472,<br />
            “numExtents” : 5,<br />
            “nindexes” : 2,<br />
            “lastExtentSize” : 2097152,<br />
            “paddingFactor” : 1,<br />
            “systemFlags” : 1,<br />
            “userFlags” : 0,<br />
            “totalIndexSize” : 719488,<br />
            “indexSizes” : {<br />
                “<em>id</em>” : 343392,<br />
                “name_1” : 376096<br />
            },<br />
            “ok” : 1<br />
        },<br />
…<br />
…<br />
复制代码<br />
2）继续用python脚本写数据，填充到副本集中</p><br />
<br />
<p>由于之前的副本集是比较老的版本（2.4），所以在写入副本集分片的时候报错：</p><br />
<br />
<p>复制代码<br />
mongos&gt; db.account.insert({“name”:”UavMbMlfsz1OFrz”})<br />
WriteResult({<br />
    “nInserted” : 0,<br />
    “writeError” : {<br />
        “code” : 83,<br />
        “errmsg” : “write results unavailable from 192.168.200.25:27017 :: caused by :: Location28563 cannot send batch write operation to server 192.168.200.25:27017 (192.168.200.25)”<br />
    }<br />
})<br />
复制代码<br />
太混蛋了，错误提示不太人性化，搞了半天。所以说版本一致性还是很重要的。现在重新开了一个副本集：</p><br />
<br />
<p>View Code<br />
把之前的副本集分片删除了，如何删除见下面3）。</p><br />
<br />
<p>新的副本集加入分片中：</p><br />
<br />
<p>复制代码<br />
mongos&gt; sh.addShard(“mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002”)<br />
{ “shardAdded” : “mablevi”, “ok” : 1 }</p><br />
<br />
<p>mongos&gt; sh.status()<br />
— Sharding Status — <br />
…<br />
…<br />
  shards:<br />
    {  “_id” : “mablevi”,  “host” : “mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002” }<br />
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }<br />
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }<br />
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }<br />
…<br />
…<br />
        dba.account<br />
            shard key: { “name” : 1 }<br />
            chunks:<br />
                mablevi    1<br />
                shard0000    1<br />
                shard0001    1<br />
                shard0002    2<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) <br />
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : mablevi Timestamp(9, 0) #新加入的分片得到数据<br />
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) <br />
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) <br />
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(9, 1) <br />
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “mablevi”,  “partitioned” : false,  “primary” : “shard0001” }<br />
复制代码<br />
继续用python写入操作：</p><br />
<br />
<p>复制代码<br />
mongos&gt; db.account.stats()<br />
{<br />
…<br />
…<br />
    “shards” : {<br />
        “mablevi” : {<br />
            “ns” : “dba.account”,<br />
            “count” : 47240,<br />
            “size” : 5290880,<br />
…<br />
…<br />
复制代码<br />
副本集的分片被写入了47240条记录。此时把副本集分片的Primary shutdown掉，再查看：</p><br />
<br />
<p>复制代码<br />
mongos&gt; db.account.stats()<br />
{<br />
    “sharded” : true,<br />
    “code” : 13639,<br />
    “ok” : 0,<br />
    “errmsg” : “exception: can’t connect to new replica set master [192.168.200.53:50000], err: couldn’t connect to server 192.168.200.53:50000 (192.168.200.53), connection attempt failed”  #由于副本集的Primary被shutdown之后，选举新主还是要几秒的时间，期间数据不能访问，导致分片数据也不能访问<br />
}<br />
mongos&gt; db.account.stats()<br />
…<br />
…<br />
    “shards” : {<br />
        “mablevi” : {<br />
            “ns” : “dba.account”,<br />
            “count” : 47240,       #副本集新主选举完毕之后，分片数据访问正常。数据没有丢失，高可用得到了实现。<br />
            “size” : 5290880,<br />
…<br />
…<br />
复制代码<br />
要是让副本集分片只剩下一台（Secondary），则分片会报错：</p><br />
<br />
<p>复制代码<br />
mongos&gt; db.account.stats()<br />
{<br />
    “sharded” : true,<br />
    “code” : 10009,<br />
    “ok” : 0,<br />
    “errmsg” : “exception: ReplicaSetMonitor no master found for set: mablevi” #数据不能访问<br />
}<br />
复制代码<br />
3）删除分片： db.runCommand({“removeshard”:”mmm”})</p><br />
<br />
<p>要是觉得分片太多了，想删除，则：</p><br />
<br />
<p>复制代码<br />
mongos&gt; use admin   #需要到admin下面删除<br />
switched to db admin<br />
mongos&gt; db.runCommand({“removeshard”:”mmm”})<br />
{<br />
    “msg” : “draining started successfully”,<br />
    “state” : “started”,   #开始删除，数据正在转移<br />
    “shard” : “mmm”,<br />
    “ok” : 1<br />
}<br />
mongos&gt; sh.status()<br />
— Sharding Status —…<br />
…<br />
  shards:<br />
    {  “_id” : “mmm”,  “host” : “mmm/192.168.200.245:27017,192.168.200.245:37017,192.168.200.25:27017”,  “draining” : true }  #删除的分片数据移动到其他分片<br />
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }<br />
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }<br />
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }<br />
…<br />
…<br />
  databases:<br />
    {  “_id” : “admin”,  “partitioned” : false,  “primary” : “config” }<br />
    {  “_id” : “test”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “dba”,  “partitioned” : true,  “primary” : “shard0000” }<br />
        dba.account<br />
            shard key: { “name” : 1 }<br />
            chunks:<br />
                shard0000    2<br />
                shard0001    1<br />
                shard0002    2<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) <br />
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : shard0000 Timestamp(8, 0) <br />
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) #这里已经没有了被删除分片信息<br />
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) <br />
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(7, 1) <br />
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “mablevi”,  “partitioned” : false,  “primary” : “shard0001” }</p><br />
<br />
<p>mongos&gt; db.runCommand({“removeshard”:”mmm”})   #再次执行，直到执行成功，要是原来分片的数据比较大，这里比较费时，要是一个主分片则需要执行movePrimary<br />
{<br />
    “msg” : “removeshard completed successfully”,<br />
    “state” : “completed”,  #完成删除<br />
    “shard” : “mmm”,<br />
    “ok” : 1<br />
}<br />
mongos&gt; sh.status()<br />
— Sharding Status —…<br />
  shards:   #分片消失<br />
    {  “_id” : “shard0000”,  “host” : “192.168.200.51:40000” }<br />
    {  “_id” : “shard0001”,  “host” : “192.168.200.52:40000” }<br />
    {  “_id” : “shard0002”,  “host” : “192.168.200.53:40000” }<br />
…<br />
…<br />
            { “name” : { “$minKey” : 1 } } –» { “name” : “5yyfY8mmR5HyhGJ” } on : shard0001 Timestamp(2, 0) <br />
            { “name” : “5yyfY8mmR5HyhGJ” } –» { “name” : “UavMbMlfszZOFrz” } on : shard0000 Timestamp(8, 0) <br />
            { “name” : “UavMbMlfszZOFrz” } –» { “name” : “t9LyVSNXDmf6esP” } on : shard0002 Timestamp(4, 1) #已经没有了被删除分片的信息<br />
            { “name” : “t9LyVSNXDmf6esP” } –» { “name” : “woQAv99Pq1FVoMX” } on : shard0002 Timestamp(3, 4) <br />
            { “name” : “woQAv99Pq1FVoMX” } –» { “name” : { “$maxKey” : 1 } } on : shard0000 Timestamp(7, 1) <br />
    {  “_id” : “abc”,  “partitioned” : false,  “primary” : “shard0000” }<br />
    {  “_id” : “mablevi”,  “partitioned” : false,  “primary” : “shard0001” }<br />
复制代码<br />
分片被删除之后，数据被移到其他分片中，不会丢失。要是想让主分片进行转移则(movePrimary):</p><br />
<br />
<p>mongos&gt; db.adminCommand({“movePrimary”:”test”,”to”:”shard0001”}) #把test的主分片从shard0000迁移到shard0001 <br />
刷新下配置服务器：db.adminCommand({“flushRouterConfig”:1})</p><br />
<br />
<p>db.adminCommand({“flushRouterConfig”:1})<br />
最后来查看下分片成员：db.runCommand({ listshards : 1 })</p><br />
<br />
<p>复制代码<br />
mongos&gt; use admin  #需要进入admin才能执行<br />
switched to db admin<br />
mongos&gt; db.runCommand({ listshards : 1 })<br />
{<br />
    “shards” : [<br />
        {<br />
            “_id” : “shard0000”,<br />
            “host” : “192.168.200.51:40000”<br />
        },<br />
        {<br />
            “_id” : “shard0001”,<br />
            “host” : “192.168.200.52:40000”<br />
        },<br />
        {<br />
            “_id” : “shard0002”,<br />
            “host” : “192.168.200.53:40000”<br />
        },<br />
        {<br />
            “_id” : “mablevi”,<br />
            “host” : “mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002”<br />
        }<br />
    ],<br />
    “ok” : 1<br />
}<br />
复制代码<br />
到此已经把MongoDB分片原理、搭建、应用大致已经介绍完。</p><br />
<br />
<p>六、认证分配</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  上面的所有操作都是在无账号密码下进行的，这样是不安全的，那如何使用账号密码呢？和副本级一样，需要添加KeyFile参数，但是针对上面的三个角色（config、mongos、mongod）账号密码怎么添加呢？官网上已经做了说明：http://docs.mongodb.org/manual/tutorial/enable-authentication-in-sharded-cluster/。下面就对有账号密码认证分片进行相关设置说明。<br />
</code></pre></div></div><br />
<br />
<p>首先要创建账号(Root角色)和生成一个KeyFile文件，其中mongos 不需要创建账号。</p><br />
<br />
<p>openssl rand -base64 741 &gt; mongodb-keyfile<br />
chmod 600 mongodb-keyfile<br />
其实这个文件也可以直接用明文，只要保证各个地方指定的文件是同一个就可以了。</p><br />
<br />
<p>1）mongd： 首先在mongod角色的分片成员上生成key file文件，特别注意的是有副本级的分片，再把这个文件分别复制到其他角色的服务器上。再添加参数：</p><br />
<br />
<p>auth = true<br />
keyFile = /usr/local/mongodb-keyfile<br />
2）Config上添加参数：</p><br />
<br />
<p>auth = true<br />
keyFile = /usr/local/mongodb-keyfile<br />
3）mongos上添加参数，因为mongos本来就是从config里加载数据的，所以只需要添加keyfile文件即可，不需要找上面createUser。</p><br />
<br />
<p>keyFile = /usr/local/mongodb-keyfile<br />
最后重启各个服务，再进入mongos里查看：</p><br />
<br />
<p>复制代码<br />
root@mongo1:/usr/local# mongo –port=30000<br />
MongoDB shell version: 3.0.4<br />
connecting to: 127.0.0.1:30000/test<br />
mongos&gt; sh.status()      #没有认证，没有权限报错。<br />
2015-07-14T23:42:11.800+0800 E QUERY    Error: error: { “$err” : “not authorized for query on config.version”, “code” : 13 }<br />
    at Error (<anonymous>)<br />
    at DBQuery.next (src/mongo/shell/query.js:259:15)<br />
    at DBCollection.findOne (src/mongo/shell/collection.js:189:22)<br />
    at printShardingStatus (src/mongo/shell/shardingtest.js:659:55)<br />
    at Function.sh.status (src/mongo/shell/utils_sh.js:60:5)<br />
    at (shell):1:4 at src/mongo/shell/query.js:259<br />
mongos&gt; use admin<br />
switched to db admin<br />
mongos&gt; db.auth('dba','dba')   #认证<br />
1<br />
mongos&gt; sh.status()            #有权限<br />
--- Sharding Status --- <br />
  sharding version: {<br />
    "_id" : 1,<br />
    "minCompatibleVersion" : 5,<br />
    "currentVersion" : 6,<br />
    "clusterId" : ObjectId("55a51ef18bd517d4acec5ef9")<br />
}<br />
  shards:<br />
    {  "_id" : "mablevi",  "host" : "mablevi/192.168.200.53:50000,192.168.200.53:50001,192.168.200.53:50002" }<br />
    {  "_id" : "shard0000",  "host" : "192.168.200.51:40000" }<br />
    {  "_id" : "shard0001",  "host" : "192.168.200.52:40000" }<br />
    {  "_id" : "shard0002",  "host" : "192.168.200.53:40000" }<br />
  balancer:<br />
  ...<br />
  ...<br />
  databases:<br />
    {  "_id" : "admin",  "partitioned" : false,  "primary" : "config" }<br />
    {  "_id" : "test",  "partitioned" : false,  "primary" : "shard0000" }<br />
    {  "_id" : "dba",  "partitioned" : true,  "primary" : "shard0000" }<br />
        dba.account<br />
            shard key: { "name" : 1 }<br />
            chunks:<br />
                mablevi    1<br />
                shard0000    1<br />
                shard0001    2<br />
                shard0002    1<br />
            { "name" : { "$minKey" : 1 } } --&gt;&gt; { "name" : "9XXqCaBhfhPIXLq" } on : mablevi Timestamp(2, 0) <br />
            { "name" : "9XXqCaBhfhPIXLq" } --&gt;&gt; { "name" : "RWINvgjYYQmbZds" } on : shard0002 Timestamp(4, 0) <br />
            { "name" : "RWINvgjYYQmbZds" } --&gt;&gt; { "name" : "jSPRBNH8rvnzblG" } on : shard0001 Timestamp(4, 1) <br />
            { "name" : "jSPRBNH8rvnzblG" } --&gt;&gt; { "name" : "okmjUUZuuKgftDC" } on : shard0001 Timestamp(3, 4) <br />
            { "name" : "okmjUUZuuKgftDC" } --&gt;&gt; { "name" : { "$maxKey" : 1 } } on : shard0000 Timestamp(3, 1) <br />
复制代码<br />
七、分片备份、还原</anonymous></p><br />
<br />
<p>因为分片机制里面会有平衡器来迁移数据，所以各个分片里的数据很可能会移动，所以在备份分片时需要做：</p><br />
<br />
<p>①：先停止平衡器的工作，并检查没有chunk move动作，保证dump的时候没有进行数据迁移。</p><br />
<br />
<p>mongos&gt; sh.stopBalancer()<br />
②：锁定数据库，保证数据没有写入：在各个分片上和配置服务器上执行。</p><br />
<br />
<blockquote><br />
  <p>db.fsyncLock()<br />
{<br />
    “info” : “now locked against writes, use db.fsyncUnlock() to unlock”,<br />
    “seeAlso” : “http://dochub.mongodb.org/core/fsynccommand”,<br />
    “ok” : 1<br />
}<br />
③：执行备份操作，备份各个分片服务器和配置服务器。</p><br />
</blockquote><br />
<br />
<p>mongodump -udba -p12345 -d dba_test –authenticationDatabase admin -o backup/<br />
④：解锁数据库，备份完成之后在分片和配置服务器上解锁数据库，允许修改。</p><br />
<br />
<blockquote><br />
  <p>db.fsyncUnlock()<br />
{ “ok” : 1, “info” : “unlock completed” }<br />
当数据库出现问题，需要还原的时候，需要还原各个分片和配置服务器，并且重启MongoDB实例。还原数据库需要做：</p><br />
</blockquote><br />
<br />
<p>①：还原各个分片和配置服务器。</p><br />
<br />
<p>mongorestore –host=127.0.0.1 –port=27017 -udba -p12345 -d dba_test –authenticationDatabase admin –drop backup/dba_test<br />
②：重启各个实例</p><br />
<br />
<p>为什么需要索引？<br />
当你抱怨MongoDB集合查询效率低的时候，可能你就需要考虑使用索引了，为了方便后续介绍，先科普下MongoDB里的索引机制（同样适用于其他的数据库比如mysql）。</p><br />
<br />
<p>mongo-9552:PRIMARY&gt; db.person.find()<br />
{ “_id” : ObjectId(“571b5da31b0d530a03b3ce82”), “name” : “jack”, “age” : 19 }<br />
{ “_id” : ObjectId(“571b5dae1b0d530a03b3ce83”), “name” : “rose”, “age” : 20 }<br />
{ “_id” : ObjectId(“571b5db81b0d530a03b3ce84”), “name” : “jack”, “age” : 18 }<br />
{ “_id” : ObjectId(“571b5dc21b0d530a03b3ce85”), “name” : “tony”, “age” : 21 }<br />
{ “_id” : ObjectId(“571b5dc21b0d530a03b3ce86”), “name” : “adam”, “age” : 18 }<br />
当你往某各个集合插入多个文档后，每个文档在经过底层的存储引擎持久化后，会有一个位置信息，通过这个位置信息，就能从存储引擎里读出该文档。比如mmapv1引擎里，位置信息是『文件id + 文件内offset 』， 在wiredtiger存储引擎（一个KV存储引擎）里，位置信息是wiredtiger在存储文档时生成的一个key，通过这个key能访问到对应的文档；为方便介绍，统一用pos(position的缩写)来代表位置信息。</p><br />
<br />
<p>比如上面的例子里，person集合里包含插入了4个文档，假设其存储后位置信息如下(为方便描述，文档省去_id字段)</p><br />
<br />
<p>位置信息	文档<br />
pos1	{“name” : “jack”, “age” : 19 }<br />
pos2	{“name” : “rose”, “age” : 20 }<br />
pos3	{“name” : “jack”, “age” : 18 }<br />
pos4	{“name” : “tony”, “age” : 21}<br />
pos5	{“name” : “adam”, “age” : 18}<br />
假设现在有个查询 db.person.find( {age: 18} ), 查询所有年龄为18岁的人，这时需要遍历所有的文档（『全表扫描』），根据位置信息读出文档，对比age字段是否为18。当然如果只有4个文档，全表扫描的开销并不大，但如果集合文档数量到百万、甚至千万上亿的时候，对集合进行全表扫描开销是非常大的，一个查询耗费数十秒甚至几分钟都有可能。</p><br />
<br />
<p>如果想加速 db.person.find( {age: 18} ），就可以考虑对person表的age字段建立索引。</p><br />
<br />
<p>db.person.createIndex( {age: 1} )  // 按age字段创建升序索引<br />
建立索引后，MongoDB会额外存储一份按age字段升序排序的索引数据，索引结构类似如下，索引通常采用类似btree的结构持久化存储，以保证从索引里快速（O(logN)的时间复杂度）找出某个age值对应的位置信息，然后根据位置信息就能读取出对应的文档。</p><br />
<br />
<p>AGE	位置信息<br />
18	pos3<br />
18	pos5<br />
19	pos1<br />
20	pos2<br />
21	pos4<br />
简单的说，索引就是将文档按照某个（或某些）字段顺序组织起来，以便能根据该字段高效的查询。有了索引，至少能优化如下场景的效率：</p><br />
<br />
<p>查询，比如查询年龄为18的所有人<br />
更新/删除，将年龄为18的所有人的信息更新或删除，因为更新或删除时，需要根据条件先查询出所有符合条件的文档，所以本质上还是在优化查询<br />
排序，将所有人的信息按年龄排序，如果没有索引，需要全表扫描文档，然后再对扫描的结果进行排序<br />
众所周知，MongoDB默认会为插入的文档生成_id字段（如果应用本身没有指定该字段），_id是文档唯一的标识，为了保证能根据文档id快递查询文档，MongoDB默认会为集合创建_id字段的索引。</p><br />
<br />
<p>mongo-9552:PRIMARY&gt; db.person.getIndexes() // 查询集合的索引信息<br />
[<br />
    {<br />
        “ns” : “test.person”,  // 集合名<br />
        “v” : 1,               // 索引版本<br />
        “key” : {              // 索引的字段及排序方向<br />
            “<em>id” : 1           // 根据_id字段升序索引<br />
        },<br />
        “name” : “_id</em>”        // 索引的名称<br />
    }<br />
]<br />
MongoDB索引类型<br />
MongoDB支持多种类型的索引，包括单字段索引、复合索引、多key索引、文本索引等，每种类型的索引有不同的使用场合。</p><br />
<br />
<p>单字段索引 （Single Field Index）<br />
    db.person.createIndex( {age: 1} ) <br />
上述语句针对age创建了单字段索引，其能加速对age字段的各种查询请求，是最常见的索引形式，MongoDB默认创建的id索引也是这种类型。</p><br />
<br />
<p>{age: 1} 代表升序索引，也可以通过{age: -1}来指定降序索引，对于单字段索引，升序/降序效果是一样的。</p><br />
<br />
<p>复合索引 (Compound Index)<br />
复合索引是Single Field Index的升级版本，它针对多个字段联合创建索引，先按第一个字段排序，第一个字段相同的文档按第二个字段排序，依次类推，如下针对age, name这2个字段创建一个复合索引。</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>db.person.createIndex( {age: 1, name: 1} )  上述索引对应的数据组织类似下表，与{age: 1}索引不同的时，当age字段相同时，在根据name字段进行排序，所以pos5对应的文档排在pos3之前。<br />
</code></pre></div></div><br />
<br />
<p>AGE,NAME	位置信息<br />
18,adam	pos5<br />
18,jack	pos3<br />
19,jack	pos1<br />
20,rose	pos2<br />
21,tony	pos4<br />
复合索引能满足的查询场景比单字段索引更丰富，不光能满足多个字段组合起来的查询，比如db.person.find( {age： 18， name: “jack”} )，也能满足所以能匹配符合索引前缀的查询，这里{age: 1}即为{age: 1, name: 1}的前缀，所以类似db.person.find( {age： 18} )的查询也能通过该索引来加速；但db.person.find( {name: “jack”} )则无法使用该复合索引。如果经常需要根据『name字段』以及『name和age字段组合』来查询，则应该创建如下的复合索引</p><br />
<br />
<p>db.person.createIndex( {name: 1, age: 1} ) <br />
除了查询的需求能够影响索引的顺序，字段的值分布也是一个重要的考量因素，即使person集合所有的查询都是『name和age字段组合』（指定特定的name和age），字段的顺序也是有影响的。</p><br />
<br />
<p>age字段的取值很有限，即拥有相同age字段的文档会有很多；而name字段的取值则丰富很多，拥有相同name字段的文档很少；显然先按name字段查找，再在相同name的文档里查找age字段更为高效。</p><br />
<br />
<p>多key索引 （Multikey Index）<br />
当索引的字段为数组时，创建出的索引称为多key索引，多key索引会为数组的每个元素建立一条索引，比如person表加入一个habbit字段（数组）用于描述兴趣爱好，需要查询有相同兴趣爱好的人就可以利用habbit字段的多key索引。</p><br />
<br />
<p>{“name” : “jack”, “age” : 19, habbit: [“football, runnning”]}<br />
db.person.createIndex( {habbit: 1} )  // 自动创建多key索引<br />
db.person.find( {habbit: “football”} )<br />
其他类型索引<br />
哈希索引（Hashed Index）是指按照某个字段的hash值来建立索引，目前主要用于MongoDB Sharded Cluster的Hash分片，hash索引只能满足字段完全匹配的查询，不能满足范围查询等。</p><br />
<br />
<p>地理位置索引（Geospatial Index）能很好的解决O2O的应用场景，比如『查找附近的美食』、『查找某个区域内的车站』等。</p><br />
<br />
<p>文本索引（Text Index）能解决快速文本查找的需求，比如有一个博客文章集合，需要根据博客的内容来快速查找，则可以针对博客内容建立文本索引。</p><br />
<br />
<p>索引额外属性<br />
MongoDB除了支持多种不同类型的索引，还能对索引定制一些特殊的属性。</p><br />
<br />
<p>唯一索引 (unique index)：保证索引对应的字段不会出现相同的值，比如_id索引就是唯一索引<br />
TTL索引：可以针对某个时间字段，指定文档的过期时间（经过指定时间后过期 或 在某个时间点过期）<br />
部分索引 (partial index): 只针对符合某个特定条件的文档建立索引，3.2版本才支持该特性<br />
稀疏索引(sparse index): 只针对存在索引字段的文档建立索引，可看做是部分索引的一种特殊情况<br />
索引优化<br />
db profiling<br />
MongoDB支持对DB的请求进行profiling，目前支持3种级别的profiling。</p><br />
<br />
<p>0： 不开启profiling<br />
1： 将处理时间超过某个阈值(默认100ms)的请求都记录到DB下的system.profile集合 （类似于mysql、redis的slowlog）<br />
2： 将所有的请求都记录到DB下的system.profile集合（生产环境慎用）<br />
通常，生产环境建议使用1级别的profiling，并根据自身需求配置合理的阈值，用于监测慢请求的情况，并及时的做索引优化。</p><br />
<br />
<p>如果能在集合创建的时候就能『根据业务查询需求决定应该创建哪些索引』，当然是最佳的选择；但由于业务需求多变，要根据实际情况不断的进行优化。索引并不是越多越好，集合的索引太多，会影响写入、更新的性能，每次写入都需要更新所有索引的数据；所以你system.profile里的慢请求可能是索引建立的不够导致，也可能是索引过多导致。</p><br />
<br />
<p>查询计划<br />
索引已经建立了，但查询还是很慢怎么破？这时就得深入的分析下索引的使用情况了，可通过查看下详细的查询计划来决定如何优化。通过执行计划可以看出如下问题</p><br />
<br />
<p>根据某个/些字段查询，但没有建立索引<br />
根据某个/些字段查询，但建立了多个索引，执行查询时没有使用预期的索引。<br />
建立索引前，db.person.find( {age： 18} )必须执行COLLSCAN，即全表扫描。</p><br />
<br />
<p>mongo-9552:PRIMARY&gt; db.person.find({age: 18}).explain()<br />
{<br />
    “queryPlanner” : {<br />
        “plannerVersion” : 1,<br />
        “namespace” : “test.person”,<br />
        “indexFilterSet” : false,<br />
        “parsedQuery” : {<br />
            “age” : {<br />
                “$eq” : 18<br />
            }<br />
        },<br />
        “winningPlan” : {<br />
            “stage” : “COLLSCAN”,<br />
            “filter” : {<br />
                “age” : {<br />
                    “$eq” : 18<br />
                }<br />
            },<br />
            “direction” : “forward”<br />
        },<br />
        “rejectedPlans” : [ ]<br />
    },<br />
    “serverInfo” : {<br />
        “host” : “localhost”,<br />
        “port” : 9552,<br />
        “version” : “3.2.3”,<br />
        “gitVersion” : “b326ba837cf6f49d65c2f85e1b70f6f31ece7937”<br />
    },<br />
    “ok” : 1<br />
}<br />
建立索引后，通过查询计划可以看出，先进行[IXSCAN]((https://docs.mongodb.org/manual/reference/explain-results/#queryplanner)(从索引中查找)，然后FETCH，读取出满足条件的文档。</p><br />
<br />
<p>mongo-9552:PRIMARY&gt; db.person.find({age: 18}).explain()<br />
{<br />
    “queryPlanner” : {<br />
        “plannerVersion” : 1,<br />
        “namespace” : “test.person”,<br />
        “indexFilterSet” : false,<br />
        “parsedQuery” : {<br />
            “age” : {<br />
                “$eq” : 18<br />
            }<br />
        },<br />
        “winningPlan” : {<br />
            “stage” : “FETCH”,<br />
            “inputStage” : {<br />
                “stage” : “IXSCAN”,<br />
                “keyPattern” : {<br />
                    “age” : 1<br />
                },<br />
                “indexName” : “age_1”,<br />
                “isMultiKey” : false,<br />
                “isUnique” : false,<br />
                “isSparse” : false,<br />
                “isPartial” : false,<br />
                “indexVersion” : 1,<br />
                “direction” : “forward”,<br />
                “indexBounds” : {<br />
                    “age” : [<br />
                        “[18.0, 18.0]”<br />
                    ]<br />
                }<br />
            }<br />
        },<br />
        “rejectedPlans” : [ ]<br />
    },<br />
    “serverInfo” : {<br />
        “host” : “localhost”,<br />
        “port” : 9552,<br />
        “version” : “3.2.3”,<br />
        “gitVersion” : “b326ba837cf6f49d65c2f85e1b70f6f31ece7937”<br />
    },<br />
    “ok” : 1<br />
}</p><br />
<br />
<p>一、存储引擎（Storage）</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mongodb 3.0默认存储引擎为MMAPV1，还有一个新引擎wiredTiger可选，或许可以提高一定的性能。<br />
<br />
mongodb中有多个databases，每个database可以创建多个collections，collection是底层数据分区（partition）的单位，每个collection都有多个底层的数据文件组成。（参见下文data files存储原理）<br />
<br />
 <br />
<br />
wiredTiger引擎：3.0新增引擎，官方宣称在read、insert和复杂的update下具有更高的性能。所以后续版本，我们建议使用wiredTiger。所有的write请求都基于“文档级别”的lock，因此多个客户端可以同时更新一个colleciton中的不同文档，这种更细颗粒度的lock，可以支撑更高的读写负载和并发量。因为对于production环境，更多的CPU可以有效提升wireTiger的性能，因为它是的IO是多线程的。wiredTiger不像MMAPV1引擎那样尽可能的耗尽内存，它可以通过在配置文件中指定“cacheSizeGB”参数设定引擎使用的内存量，此内存用于缓存工作集数据（索引、namespace，未提交的write，query缓冲等）。<br />
<br />
journal就是一个预写事务日志，来确保数据的持久性，wiredTiger每隔60秒（默认）或者待写入的数据达到2G时，mongodb将对journal文件提交一个checkpoint（检测点，将内存中的数据变更flush到磁盘中的数据文件中，并做一个标记点，表示此前的数据表示已经持久存储在了数据文件中，此后的数据变更存在于内存和journal日志）。对于write操作，首先被持久写入journal，然后在内存中保存变更数据，条件满足后提交一个新的检测点，即检测点之前的数据只是在journal中持久存储，但并没有在mongodb的数据文件中持久化，延迟持久化可以提升磁盘效率，如果在提交checkpoint之前，mongodb异常退出，此后再次启动可以根据journal日志恢复数据。journal日志默认每个100毫秒同步磁盘一次，每100M数据生成一个新的journal文件，journal默认使用了snappy压缩，检测点创建后，此前的journal日志即可清除。mongod可以禁用journal，这在一定程度上可以降低它带来的开支；对于单点mongod，关闭journal可能会在异常关闭时丢失checkpoint之间的数据（那些尚未提交到磁盘数据文件的数据）；对于replica set架构，持久性的保证稍高，但仍然不能保证绝对的安全（比如replica set中所有节点几乎同时退出时）。<br />
<br />
<br />
<br />
 <br />
<br />
MMAPv1引擎：mongodb原生的存储引擎，比较简单，直接使用系统级的内存映射文件机制（memory mapped files），一直是mongodb的默认存储引擎，对于insert、read和in-place update（update不导致文档的size变大）性能较高；不过MMAPV1在lock的并发级别上，支持到collection级别，所以对于同一个collection同时只能有一个write操作执行，这一点相对于wiredTiger而言，在write并发性上就稍弱一些。对于production环境而言，较大的内存可以使此引擎更加高效，有效减少“page fault”频率，但是因为其并发级别的限制，多核CPU并不能使其受益。此引擎将不会使用到swap空间，但是对于wiredTiger而言需要一定的swap空间。（核心：对于大文件MAP操作，比较忌讳的就是在文件的中间修改数据，而且导致文件长度增长，这会涉及到索引引用的大面积调整）<br />
<br />
 <br />
<br />
为了确保数据的安全性，mongodb将所有的变更操作写入journal并间歇性的持久到磁盘上，对于实际数据文件将延迟写入，和wiredTiger一样journal也是用于数据恢复。所有的记录在磁盘上连续存储，当一个document尺寸变大时，mongodb需要重新分配一个新的记录（旧的record标记删除，新的记record在文件尾部重新分配空间），这意味着mongodb同时还需要更新此文档的索引（指向新的record的offset），与in-place update相比，将消耗更多的时间和存储开支。由此可见，如果你的mongodb的使用场景中有大量的这种update，那么或许MMAPv1引擎并不太适合，同时也反映出如果document没有索引，是无法保证document在read中的顺序（即自然顺序）。3.0之后，mongodb默认采用“Power of 2 Sized Allocations”，所以每个document对应的record将有实际数据和一些padding组成，这padding可以允许document的尺寸在update时适度的增长，以最小化重新分配record的可能性。此外重新分配空间，也会导致磁盘碎片（旧的record空间）。<br />
<br />
 <br />
<br />
Power of 2 Sized Allocations：默认情况下，MMAPv1中空间分配使用此策略，每个document的size是2的次幂，比如32、64、128、256...2MB，如果文档尺寸大于2MB，则空间为2MB的倍数（2M,4M,6M等）。这种策略有2种优势，首先那些删除或者update变大而产生的磁盘碎片空间（尺寸变大，意味着开辟新空间存储此document，旧的空间被mark为deleted）可以被其他insert重用，再者padding可以允许文档尺寸有限度的增长，而无需每次update变大都重新分配空间。此外，mongodb还提供了一个可选的“No padding Allocation”策略（即按照实际数据尺寸分配空间），如果你确信数据绝大多数情况下都是insert、in-place update，极少的delete，此策略将可以有效的节约磁盘空间，看起来数据更加紧凑，磁盘利用率也更高。<br />
<br />
 <br />
<br />
备注：mongodb 3.2+之后，默认的存储引擎为“wiredTiger”，大量优化了存储性能，建议升级到3.2+版本。<br />
</code></pre></div></div><br />
<br />
<p>二、Capped Collections：一种特殊的collection，其尺寸大小是固定值，类似于一个可循环使用的buffer，如果空间被填满之后，新的插入将会覆盖最旧的文档，我们通常不会对Capped进行删除或者update操作，所以这种类型的collection能够支撑较高的write和read，通常情况下我们不需要对这种collection构建索引，因为insert是append（insert的数据保存是严格有序的）、read是iterator方式，几乎没有随机读；在replica set模式下，其oplog就是使用这种colleciton实现的。    Capped Collection的设计目的就是用来保存“最近的”一定尺寸的document。</p><br />
<br />
<p>Java代码  收藏代码<br />
db.createCollection(“capped_collections”,new CreateCollectionOptions()<br /><br />
                .capped(true)<br /><br />
                .maxDocuments(6552350)<br /><br />
                .usePowerOf2Sizes(false).autoIndex(true));//不会涉及到更新，所以可以不用power of 2</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Capped Collection在语义上，类似于“FIFO”队列，而且是有界队列。适用于数据缓存，消息类型的存储。Capped支持update，但是我们通常不建议，如果更新导致document的尺寸变大，操作将会失败，只能使用in-place update，而且还需要建立合适的索引。在capped中使用remove操作是允许的。autoIndex属性表示默认对_id字段建立索引，我们推荐这么做。在上文中我们提到了Tailable Cursor，就是为Capped而设计的，效果类似于“tail -f ”。<br />
</code></pre></div></div><br />
<br />
<p>三、数据模型（Data Model）</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>上文已经描述过，mongodb是一个模式自由的NOSQL，不像其他RDBMS一样需要预先定义Schema而且所有的数据都“整齐划一”，mongodb的document是BSON格式，松散的，原则上说任何一个Colleciton都可以保存任意结构的document，甚至它们的格式千差万别，不过从应用角度考虑，包括业务数据分类和查询优化机制等，我们仍然建议每个colleciton中的document数据结构应该比较接近。<br />
<br />
对于有些update，比如对array新增元素等，会导致document尺寸的增加，无论任何存储系统包括MYSQL、Hbase等，对于这种情况都需要额外的考虑，这归结于磁盘空间的分配是连续的（连续意味着读取性能将更高，存储文件空间通常是预分配固定尺寸，我们需要尽可能的利用磁盘IO的这种优势）。对于MMAPV1引擎，如果文档尺寸超过了原分配的空间（上文提到Power of 2 Allocate），mongodb将会重新分配新的空间来保存整个文档（旧文档空间回收，可以被后续的insert重用）。<br />
<br />
 <br />
<br />
document模型的设计与存储，需要兼顾应用的实际需要，否则可能会影响性能。mongodb支持内嵌document，即document中一个字段的值也是一个document，可以形成类似于RDBMS中的“one-to-one”、“one-to-many”，只需要对reference作为一个内嵌文档保存即可。这种情况就需要考虑mongodb存储引擎的机制了，如果你的内嵌文档（即reference文档）尺寸是动态的，比如一个user可以有多个card，因为card数量无法预估，这就会导致document的尺寸可能不断增加以至于超过“Power of 2 Allocate”，从而触发空间重新分配，带来性能开销，这种情况下，我们需要将内嵌文档单独保存到一个额外的collection中，作为一个或者多个document存储，比如把card列表保存在card collection中。“one-to-one”的情况也需要个别考虑，如果reference文档尺寸较小，可以内嵌，如果尺寸较大，建议单独存储。此外内嵌文档还有个优点就是write的原子性，如果使用reference的话，就无法保证了。<br />
<br />
 <br />
<br />
索引：提高查询性能，默认情况下_id字段会被创建唯一索引；因为索引不仅需要占用大量内存而且也会占用磁盘，所以我们需要建立有限个索引，而且最好不要建立重复索引；每个索引需要8KB的空间，同时update、insert操作会导致索引的调整，会稍微影响write的性能，索引只能使read操作收益，所以读写比高的应用可以考虑建立索引。<br />
<br />
 <br />
<br />
大集合拆分：比如一个用于存储log的collection，log分为有两种“dev”、“debug”，结果大致为{"log":"dev","content":"...."},{"log":"debug","content":"....."}。这两种日志的document个数比较接近，对于查询时，即使给log字段建立索引，这个索引也不是高效的，所以可以考虑将它们分别放在2个Collection中，比如：log_dev和log_debug。<br />
<br />
 <br />
<br />
数据生命周期管理：mongodb提供了expire机制，即可以指定文档保存的时长，过期后自动删除，即TTL特性，这个特性在很多场合将是非常有用的，比如“验证码保留15分钟有效期”、“消息保存7天”等等，mongodb会启动一个后台线程来删除那些过期的document。需要对一个日期字段创建“TTL索引”，比如插入一个文档：{"check_code":"101010",$currentDate:{"created":true}}}，其中created字段默认值为系统时间Date；然后我们对created字段建立TTL索引：<br />
</code></pre></div></div><br />
<br />
<p>Java代码  收藏代码<br />
collection.createIndex(new Document(“created”,1),new IndexOptions().expireAfter(15L,TimeUnit.MILLISECONDS));//15分钟<br /><br />
    我们向collection中insert文档时，created的时间为系统当前时间，其中在creatd字段上建立了“TTL”索引，索引TTL为15分钟，mongodb后台线程将会扫描并检测每条document的（created时间 + 15分钟）与当前时间比较，如果发现过期，则删除索引条目（连带删除document）。</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>某些情况下，我们可能需要实现“在某个指定的时刻过期”，我们只需要将上述文档和索引变通改造即可，即created指定为“目标时间”，expiredAfter指定为0。 <br />
</code></pre></div></div><br />
<br />
<p>四、架构模式</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群，有“primary”和secondary等多中角色（稍后详细介绍），其中primary负责读写请求，secondary可以负责读请求，这有配置决定，其中secondary紧跟primary并应用write操作；如果primay失效，则集群进行“多数派”选举，选举出新的primary，即failover机制，即HA架构。复制集解决了单点故障问题，也是mongodb垂直扩展的最小部署单位，当然sharding cluster中每个shard节点也可以使用Replica set提高数据可用性。<br />
<br />
 <br />
<br />
Sharding cluster：分片集群，数据水平扩展的手段之一；replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。<br />
<br />
 <br />
<br />
系统配置：1）建议mongodb部署在linux系统上，较高版本，选择合适的底层文件系统（ext4），开启合适的swap空间  2）无论是MMAPV1或者wiredTiger引擎，较大的内存总能带来直接收益。3）对数据存储文件关闭“atime”（文件每次access都会更改这个时间值，表示文件最近被访问的时间），可以提升文件访问效率。 4）ulimit参数调整，这个在基于网络IO或者磁盘IO操作的应用中，通常都会调整，上调系统允许打开的文件个数（ulimit -n 65535）。<br />
</code></pre></div></div><br />
<br />
<p>五、数据文件存储原理（Data Files storage，MMAPV1引擎）</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1、Data Files<br />
<br />
mongodb的数据将会保存在底层文件系统中，比如我们dbpath设定为“/data/db”目录，我们创建一个database为“test”，collection为“sample”，然后在此collection中插入数条documents。我们查看dbpath下生成的文件列表：<br />
</code></pre></div></div><br />
<br />
<p>Java代码  收藏代码</p><br />
<blockquote><br />
  <p>ls -lh<br /><br />
-rw——-  1 mongo  mongo    16M 11  6 17:24 test.0<br /><br />
-rw——-  1 mongo  mongo    32M 11  6 17:24 test.1<br /><br />
-rw——-  1 mongo  mongo    64M 11  6 17:24 test.2<br /><br />
-rw——-  1 mongo  mongo   128M 11  6 17:24 test.3<br /><br />
-rw——-  1 mongo  mongo   256M 11  6 17:24 test.4<br /><br />
-rw——-  1 mongo  mongo   512M 11  6 17:24 test.5<br /><br />
-rw——-  1 mongo  mongo   512M 11  6 17:24 test.6<br /><br />
-rw——-  1 mongo  mongo    16M 11  6 17:24 test.ns</p><br />
</blockquote><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>可以看到test这个数据库目前已经有6个数据文件（data files），每个文件以“database”的名字 + 序列数字组成，序列号从0开始，逐个递增，数据文件从16M开始，每次扩张一倍（16M、32M、64M、128M...），在默认情况下单个data file的最大尺寸为2G，如果设置了smallFiles属性（配置文件中）则最大限定为512M；mongodb中每个database最多支持16000个数据文件，即约32T，如果设置了smallFiles则单个database的最大数据量为8T。如果你的database中的数据文件很多，可以使用directoryPerDB配置项将每个db的数据文件放置在各自的目录中。当最后一个data file有数据写入后，mongodb将会立即预分配下一个data file，可以通过“--nopreallocate”启动命令参数来关闭此选项。<br />
<br />
 <br />
<br />
一个database中所有的collections以及索引信息会分散存储在多个数据文件中，即mongodb并没有像SQL数据库那样，每个表的数据、索引分别存储；数据分块的单位为extent（范围，区域），即一个data file中有多个extents组成，extent中可以保存collection数据或者indexes数据，一个extent只能保存同一个collection数据，不同的collections数据分布在不同的extents中，indexes数据也保存在各自的extents中；最终，一个collection有一个或者多个extents构成，最小size为8K，最大可以为2G，依次增大；它们分散在多个data files中。对于一个data file而言，可能包含多个collection的数据，即有多个不同collections的extents、index extents混合构成。每个extent包含多条documents（或者index entries），每个extent的大小可能不相等，但一个extent不会跨越2个data files。<br />
<br />
 <br />
<br />
<br />
<br />
 <br />
<br />
有人肯定疑问：一个collection中有哪些extents，这种信息mongodb存在哪里？在每个database的namespace文件中，比如test.ns文件中，每个collection只保存了第一个extent的位置信息，并不保存所有的extents列表，但每个extent都维护者一个链表关系，即每个extent都在其header信息中记录了此extent的上一个、下一个extent的位置信息，这样当对此collection进行scan操作时（比如全表扫描），可以提供很大的便利性。<br />
<br />
 <br />
<br />
我们可以通过db.stats()指令查看当前database中extents的信息：<br />
</code></pre></div></div><br />
<br />
<p>Java代码  收藏代码</p><br />
<blockquote><br />
  <p>use test<br /><br />
switched to db test<br /><br />
db.stats();<br /><br />
{<br /><br />
    “db” : “test”,<br /><br />
    “collections” : 3,  ##collection的个数<br /><br />
    “objects” : 1000006, ##documents总条数<br /><br />
    “avgObjSize” : 495.9974400153599, ##record的平均大小，单位byte<br /><br />
    “dataSize” : 496000416, ##document所占空间的总量<br /><br />
    “storageSize” : 629649408, ##<br /><br />
    “numExtents” : 18,  ##extents个数<br /><br />
    “indexes” : 2,<br /><br />
    “indexSize” : 108282944,<br /><br />
    “fileSize” : 1006632960,<br /><br />
    “nsSizeMB” : 16, ##namespace文件大小<br /><br />
    “extentFreeList” : {   ##尚未使用（已分配尚未使用、已删除但尚未被重用）的extent列表<br /><br />
        “num” : 0,<br /><br />
        “totalSize” : 0<br /><br />
    },<br /><br />
    “dataFileVersion” : {<br /><br />
        “major” : 4,<br /><br />
        “minor” : 22<br /><br />
    },<br /><br />
    “ok” : 1<br /><br />
}<br /><br />
    列表信息中有几个字段简单介绍一下：</p><br />
</blockquote><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1） dataSize：documents所占的空间总量，mongodb将会为每个document分配一定空间用于保存数据，每个document所占空间包括“文档实际大小” + “padding”，对于MMAPV1引擎，mongodb默认采用了“Power of 2 Sized Allocations”策略，这也意味着通常会有padding，不过如果你的document不会被update（或者update为in-place方式，不会导致文档尺寸变大），可以在在createCollection是指定noPadding属性为true，这样dataSize的大小就是documents实际大小；当documents被删除后，将导致dataSize减小；不过如果在原有document的空间内（包括其padding空间）update（或者replace），则不会导致dataSize的变大，因为mongodb并没有分配任何新的document空间。<br />
<br />
2）storageSize：所有collection的documents占用总空间，包括那些已经删除的documents所占的空间，为存储documents的extents所占空间总和。文档的删除或者收缩不会导致storageSize变小。<br />
<br />
3）indexSize：所用collection的索引数据的大小，为存储indexes的extents所占空间的总和。<br />
<br />
4）fileSize：为底层所有data files的大小总和，但不包括namespace文件。为storageSize、indexSize、以及一些尚未使用的空间等等。当删除database、collections时会导致此值变小。<br />
<br />
 <br />
<br />
此外，如果你想查看一个collection中extents的分配情况，可以使用db.&lt;collection名称&gt;.stats()，结构与上述类似；如果你希望更细致的了解collection中extents的全部信息，则可以使用db.&lt;collection名称&gt;.validate()，此方法接收一个boolean值，表示是否查看明细，这个指令会scan全部的data files，因此比较耗时：<br />
</code></pre></div></div><br />
<br />
<p>Java代码  收藏代码</p><br />
<blockquote><br />
  <p>db.sample.validate(true);<br /><br />
{<br /><br />
    “ns” : “test.sample”,<br /><br />
    “datasize” : 496000000,<br /><br />
    “nrecords” : 1000000,<br /><br />
    “lastExtentSize” : 168742912,<br /><br />
    “firstExtent” : “0:5000 ns:test.sample”,<br /><br />
    “lastExtent” : “3:a05f000 ns:test.sample”,<br /><br />
    “extentCount” : 16,<br /><br />
    “extents” : [<br /><br />
        {<br /><br />
            “loc” : “0:5000”,<br /><br />
            “xnext” : “0:49000”,<br /><br />
            “xprev” : “null”,<br /><br />
            “nsdiag” : “test.sample”,<br /><br />
            “size” : 8192,<br /><br />
            “firstRecord” : “0:50b0”,<br /><br />
            “lastRecord” : “0:6cb0”<br /><br />
        },<br /><br />
        …<br /><br />
        ]<br /><br />
        …<br /><br />
}<br /><br />
    可以看到extents在逻辑上是链表形式，以及每个extent的数据量、以及所在data file的offset位置。具体参见【validate方法】</p><br />
</blockquote><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>从上文中我们已经得知，删除document会导致磁盘碎片，有些update也会导致磁盘碎片，比如update导致文档尺寸变大，进而超过原来分配的空间；当有新的insert操作时，mongodb会检测现有的extents中是否合适的碎片空间可以被重用，如果有，则重用这些fragment，否则分配新的存储空间。磁盘碎片，对write操作有一定的性能影响，而且会导致磁盘空间浪费；如果你需要删除某个collection中大部分数据，则可以考虑将有效数据先转存到新的collection，然后直接drop()原有的collection。或者使用db.runCommand({compact: '&lt;collection&gt;'})。<br />
<br />
如果你的database已经运行一段时间，数据已经有很大的磁盘碎片（storageSize与dataSize比较），可以通过mongodump将指定database的所有数据导出，然后将原有的db删除，再通过mongorestore指令将数据重新导入。（同compact，这种操作需要停机维护）<br />
<br />
 <br />
<br />
mongod中还有2个默认的database，系统级的，“admin”和“local”；它们的存储原理同上，其中“admin”用于存储“用户授权信息”，比如每个database中用户的role、权限等；“local”即为本地数据库，我们常说的oplog（replication架构中使用，类似与binlog）即保存在此数据库中。<br />
<br />
 <br />
<br />
2、Namespace文件<br />
<br />
对于namespace文件，比如“test.ns”文件，默认大小为16M，此文件中主要用于保存“collection”、index的命名信息，比如collection的“属性”信息、每个索引的属性类型等，如果你的database中需要存储大量的collection（比如每一小时生成一个collection，在数据分析应用中），那么我们可以通过配置文件“nsSize”选项来指定。参见【mongodb配置文件】<br />
<br />
 <br />
<br />
3、journal文件<br />
<br />
journal日志为mongodb提供了数据保障能力，它本质上与mysql binlog没有太大区别，用于当mongodb异常crash后，重启时进行数据恢复；这归结于mongodb的数据持久写入磁盘是滞后的。默认情况下，“journal”特性是开启的，特别在production环境中，我们没有理由来关闭它。（除非，数据丢失对应用而言，是无关紧要的）<br />
<br />
 <br />
<br />
一个mongodb实例中所有的databases共享journal文件。<br />
<br />
 <br />
<br />
对于write操作而言，首先写入journal日志，然后将数据在内存中修改（mmap），此后后台线程间歇性的将内存中变更的数据flush到底层的data files中，时间间隔为60秒（参见配置项“syncPeriodSecs”）；write操作在journal文件中是有序的，为了提升性能，write将会首先写入journal日志的内存buffer中，当buffer数据达到100M或者每隔100毫秒，buffer中的数据将会flush到磁盘中的journal文件中；如果mongodb异常退出，将可能导致最多100M数据或者最近100ms内的数据丢失，flush磁盘的时间间隔有配置项“commitIntervalMs”决定，默认为100毫秒。mongodb之所以不能对每个write都将journal同步磁盘，这也是对性能的考虑，mysql的binlog也采用了类似的权衡方式。开启journal日志功能，将会导致write性能有所降低，可能降低5~30%，因为它直接加剧了磁盘的写入负载，我们可以将journal日志单独放置在其他磁盘驱动器中来提高写入并发能力（与data files分别使用不同的磁盘驱动器）。<br />
<br />
 <br />
<br />
如果你希望数据尽可能的不丢失，可以考虑：1）减小commitIntervalMs的值 2）每个write指定“write concern”中指定“j”参数为true  3）最佳手段就是采用“replica set”架构模式，通过数据备份方式解决，同时还需要在“write concern”中指定“w”选项，且保障级别不低于“majority”。【参见mongodb复制集】最终我们需要在“写入性能”和“数据一致性”两个方面权衡，即CAP理论。<br />
<br />
 <br />
<br />
根据write并发量，journal日志文件为1G，如果指定了smallFiles配置项，则最大为128M，和data files一样journal文件也采用了“preallocated”方式，journal日志保存在dbpath下“journal”子目录中，一般会有三个journal文件，每个journal文件格式类似于“j._&lt;序列数字&gt;”。并不是每次buffer flush都生成一个新的journal日志，而是当前journal文件即将满时会预创建一个新的文件，journal文件中保存了write操作的记录，每条记录中包含write操作内容之外，还包含一个“lsn”（last sequence number），表示此记录的ID；此外我们会发现在journal目录下，还有一个“lsn”文件，这个文件非常小，只保存了一个数字，当write变更的数据被flush到磁盘中的data files后，也意味着这些数据已经持久化了，那么它们在“异常恢复”时也不需要了，那么其对应的journal日志将可以删除，“lsn”文件中记录的就是write持久化的最后一个journal记录的ID，此ID之前的write操作已经被持久写入data files，此ID之前的journal在“异常恢复”时则不需要关注；如果某个journal文件中最大 ID小于“lsn”，则此journal可以被删除或者重用。<br />
</code></pre></div></div><br />
<br />

					 <span class='st_sharethis_large' displayText='ShareThis'></span>
						<span class='st_facebook_large' displayText='Facebook'></span>
						<span class='st_twitter_large' displayText='Tweet'></span>
						<span class='st_linkedin_large' displayText='LinkedIn'></span>
						<span class='st_pinterest_large' displayText='Pinterest'></span>
						<span class='st_email_large' displayText='Email'></span>
                </div>
                Category storage
        </div>
	</div>
  
  
       <!--赞-->
    	  <div class="row">
            <div class="col-lg-6">
                <img src="https://xiazemin.github.io/MyBlog/img/webwxgetmsgimg.jpeg"  height="400" width="auto" />
            </div>
          </div>

        <div class="row">
                <div class="col-md-12">
			<div id="disqus_thread"></div>

<div id="gitmentContainer"></div>
<link rel="stylesheet" href="/MyBlog/css/default.css">
<script src="/MyBlog/js/gitment.browser.js"></script>
<script type="text/javascript" src="/MyBlog/js/json2.js"></script>
<script>
var gitment = new Gitment({
    owner: 'xiazemin',
    repo: 'MyBlogComment',
    oauth: {
        client_id: '981ba8c916c262631ea0',
        client_secret: 'a52260ef92de69011ccd1cf355b973ef11d6da0e',
    },
});

var MyGitmentContainer=gitment.render('gitmentContainer');
window.setTimeout(MyGitMentBtnclick,1000); 
//document.ready(function(){ 
//window.onload=function(){}

function MyGitMentBtnclick(){
//var MyGitmentContainer=document.getElementById('gitmentContainer');
	var ele=[],all=MyGitmentContainer.getElementsByTagName("*");
	for(var i=0;i<all.length;i++){
	  if(all[i].className=='gitment-comments-init-btn'){
		MyGitMentBtn=all[i];
		console.log(MyGitMentBtn);
		MyGitMentBtn.click();
	  }
	}
}

</script>



			<!--script>
			/**
			* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
			* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
			*/
			/*
			var disqus_config = function () {
			this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
			this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
			};
			*/
			(function() { // DON'T EDIT BELOW THIS LINE
			var d = document, s = d.createElement('script');

			s.src = '//airrayagroup.disqus.com/embed.js';

			s.setAttribute('data-timestamp', +new Date());
			(d.head || d.body).appendChild(s);
			})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			<script id="dsq-count-scr" src="//airrayagroup.disqus.com/count.js" async></script-->
          </div>
       </div>

</div>
<hr>
     <footer>
        <div class="container">
             <a href="/MyBlog/" style="color: green; font-size: 2em; font-family: 'Schoolbell', cursive;">首页</a>
            <div class="row">
                <div class="col-lg-6">
                    <p>Copyright &copy; 2017 465474307@qq.com <p>
                </div>
                <div class="col-lg-6">
                    <p style="float: right;">Jekyll theme by <a href="https://github.com/xiazemin/">夏泽民</a></p>
                </div>
            </div>
        </div>
    </footer>
	
    <!-- jQuery -->
    <script src="/MyBlog/js/jquery-1.12.0.min.js"></script>
    <script src="/MyBlog/js/jquery-migrate-1.2.1.min.js"></script>

    <!-- Latest compiled and minified JavaScript -->
    <script src="/MyBlog/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
        <!-- Menu Toggle Script -->
    <script>
    $("#menu-toggle").click(function(e) {
        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
    </script>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"6","bdPos":"right","bdTop":"100"},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/MyBlog/shareapi/js/share.js?v=89860593.js?'];</script>


<!-- 2d  -->
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.0.min.js"></script>
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.min.js"></script>
<script type="text/javascript">
 setTimeout(()=> {
/*L2Dwidget.init({"display": {
        "superSample": 2,
        "width": 200,
        "height": 400,
             "position": "right",
                 "hOffset": 0,
        "vOffset": 0
          }
     });
*/
 L2Dwidget
        .on('*', (name) => {
          console.log('%c EVENT ' + '%c -> ' + name, 'background: #222; color: yellow', 'background: #fff; color: #000')
        })
        .init({
          dialog: {
            // 开启对话框
            enable: true,
            script: {
              // 每空闲 10 秒钟，显示一条一言
              'every idle 10s': '$hitokoto$',
              // 当触摸到星星图案
              'hover .star': '星星在天上而你在我心里 (*/ω＼*)',
              // 当触摸到角色身体
              'tap body': '哎呀！别碰我！',
              // 当触摸到角色头部
              'tap face': '人家已经不是小孩子了！'
            }
          }
        });

})
</script>



    <!--html xmlns:wb="http://open.weibo.com/wb">
    <script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
    <wb:follow-button uid="2165491993" type="red_1" width="67" height="24" ></wb:follow-button-->

      <!--本文来自-->
     <script type="text/javascript">
      /* 仅IE
     document.body.oncopy = function(){
        setTimeout( 
            function () { 
        var text =window.clipboardData.getData("text"); 
        if (text) { 
            text = text + "/r/n本篇文章来源于 xiazemin 的 泽民博客|https://xiazemin.github.io/MyBlog/index.html 原文链接："+location.href; clipboardData.setData("text", text); 
          }
       },
     100 )
    }
     */
     //绑定在了body上，也可以绑定在其他可用元素行，但是不是所有元素都支持copy和past事件。

     /*
$(document.body).bind({
    copy: function(event) {//copy事件
        //var cpTxt = "复制的数据";
        var clipboardData = window.clipboardData; //for IE
        if (!clipboardData) { // for chrome
            clipboardData = event.originalEvent.clipboardData;
        }

        if (event.clipboardData != null/false/undefined) { //ignore the incorrectness of the truncation
        clipboarddata = event.clipboardData;
        } else if (window.clipboardData != null/false/undefined) {
         clipboarddata = window.clipboardData;
        } else { //default to the last option even if it is null/false/undefined
         clipboarddata = event.originalEvent.clipboardData;
        }

        //e.clipboardData.getData('text');//可以获取用户选中复制的数据
        //clipboardData.setData('Text', cpTxt);
        alert(clipboarddata.getData('text'));
        //$('#message').text('Copy Data : ' + cpTxt);
        return false;//否则设不生效
    },paste: function(e) {//paste事件
        var eve = e.originalEvent
        var cp = eve.clipboardData;
        var data = null;
        var clipboardData = window.clipboardData; // IE
        if (!clipboardData) { //chrome
            clipboardData = e.originalEvent.clipboardData
        }
        data = clipboardData.getData('Text');
        //$('#message').html(data);
    }
});     
*/
function addLink() {
    var body_element = document.getElementsByTagName('body')[0];
    var selection;
    selection = window.getSelection();
    var pagelink = "<br /><br />本文来源：xiazemin 的 泽民博客 <a href='"+document.location.href+"'>"+document.location.href+"</a>";
//+document.location.href+当前页面链接
    var copy_text = selection + pagelink;
    console.log(copy_text);
    var new_div = document.createElement('div');
    new_div.style.left='-99999px';
    new_div.style.position='absolute';
    body_element.appendChild(new_div );
    new_div.innerHTML = copy_text ;
    selection.selectAllChildren(new_div );
    window.setTimeout(function() {
        body_element.removeChild(new_div );
    },0);
}
document.oncopy = addLink;
     </script>
    <!--本文来自-->

</div>
  </body>

</html>