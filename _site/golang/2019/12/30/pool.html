<!DOCTYPE html>
<html>

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Sci blog jekyll theme">
    <meta name="author" content="AIR RAYA Group">
    <link href='/MyBlog/img/favicon.ico' type='image/icon' rel='shortcut icon'/>

    <title>泽民博客 | Jekyll theme</title>

    <link rel="stylesheet" href="/MyBlog/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="/MyBlog/css/font-awesome.min.css">
    <link href="/MyBlog/css/simple-sidebar.css" rel="stylesheet">
	<link href="/MyBlog/css/classic-10_7.css" rel="stylesheet" type="text/css">
    <!-- Custom CSS -->
    <link href="/MyBlog/css/style.css" rel="stylesheet">
    <link href="/MyBlog/css/pygments.css" rel="stylesheet">
    <!-- Fonts -->
 <link href="/MyBlog/css/front.css" rel="stylesheet" type="text/css">
 <link href="/MyBlog/css/Josefin_Slab.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Architects_Daughter.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Schoolbell.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Codystar.css" rel="stylesheet" type="text/css">

 <script type="text/javascript" src="/MyBlog/js/jquery-1.12.0.min.js"></script>	

<link href="/MyBlog/css/calendar/common.css" type="text/css"  rel="stylesheet">
<script type="text/javascript" src="/MyBlog/js/calendar/calendar.js"></script>
	<!-- share this -->
	<script type="text/javascript">var switchTo5x=true;</script>
	<script type="text/javascript" src="/MyBlog/js/buttons.js"></script>
	<script type="text/javascript">stLight.options({publisher: "b28464c3-d287-4257-ad18-058346dd35f7", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="/MyBlog/js/html5shiv.js"></script>
        <script src="/MyBlog/js/respond.min.js"></script>
    <![endif]-->
   
   <!--百度统计-->
    <script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e965cab8c73512b8b23939e7051d93bd";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <script async src="/MyBlog/katex/katex.js"></script>
    <link rel="stylesheet" href="/MyBlog/katex/katex.css">

    <!--轮播图片-->
    <!--script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.stripesrotator.js"></script>
    <script type="text/javascript">
                    $(document).ready(function() {
                    alert($('#rotator_xzm'));
                     alert($('#rotator_xzm').fn);
                    $('#rotator_xzm').stripesRotator({ images: [ "https://xiazemin.github.io/MyBlog/img/BPlusTree.png", "https://xiazemin.github.io/MyBlog/img/linuxMMap.jpeg"] });
                    });
    </script-->

    <!--水印-->
    <script type="text/javascript" src="/MyBlog/js/waterMark.js"></script>
    <script type="text/javascript">
    $(document).ready(function(){
    watermark({watermark_txt0:'泽民博客',watermark_txt1:'zemin',watermark_txt2:(new Date()).Format("yyyy-MM-dd hh:mm:ss.S")});
    })
    </script>
     <!--水印-->
     <!--adscene-->
    <script data-ad-client="ca-pub-6672721494777557" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

</head>

 <body>
<div id="wrapper">
 <!-- Navigation -->
    <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="/MyBlog">
                        Home
                    </a>
                </li>
                <li>
                    <a href="#">About</a>
                </li>
                <li>
                    <a href="#">Services</a>
                </li>
                <li>
                    <a href="#">Portfolio</a>
                </li>
                <li>
                    <a href="#">Events</a>
                </li>
                <li>
                    <a href="#">Blog</a>
                </li>
                <li>
                    <a href="#">FAQ</a>
                </li>
                <li>
                    <a href="#">Contact</a>
                </li>
            </ul>
        </div>


    <header class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="heading text-center">
                        <a href="https://xiazemin.github.io/MyBlog/" style="color: #fff; font-size: 4em; font-family: 'Schoolbell', cursive;">泽民博客</a>
                        <a href="#menu-toggle" class="btn btn-default sciblog" id="menu-toggle" style="font-weight: bold;">&#9776; Menu</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

     <script async src="/MyBlog/js/busuanzi.pure.mini.js"></script>

    <script type="text/javascript" src="/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="/MyBlog/js/jquery.stripesrotator.js"></script>


 <div class="container">
	<div class="row">
        <div class="box">
                <div class="col-lg-12">
                    <div class="intro-text text-center">
					<h1 class="post-title" itemprop="name headline">sync.Pool</h1>
					<p class="post-meta"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">by 夏泽民</span></span> <time datetime="2019-12-30T00:00:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Dec 30, 2019</time></p>
					</div>
					 <p>sync.Pool是一个可以存或取的临时对象池。对外提供New、Get、Put等API，利用mutex支持多线程并发。</p><br />
<br />
<p>目标<br />
sync.Pool解决以下问题：</p><br />
<br />
<p>增加临时对象的用复用率，减少GC负担<br />
通过对象的复用，减少内存申请开销，有利于提高一部分性能<br />
<!-- more --><br />
实现<br />
这一部分回答如何实现的问题。</p><br />
<br />
<p>关于了解实现，最好的办法就是看代码。</p><br />
<br />
<p>描述<br />
type Pool struct {<br />
    noCopy noCopy</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal<br />
localSize uintptr        // size of the local array<br />
<br />
// New optionally specifies a function to generate<br />
// a value when Get would otherwise return nil.<br />
// It may not be changed concurrently with calls to Get.<br />
New func() interface{} } 各个成员含义如下：<br />
</code></pre></div></div><br />
<br />
<p>noCopy： 防止sync.Pool被复制</p><br />
<br />
<p>local： poolLocal数组的指针</p><br />
<br />
<p>localSize： poolLocal数组大小</p><br />
<br />
<p>New： 函数指针申请具体的对象，便于用户定制各种类型的对象</p><br />
<br />
<p>// Local per-P Pool appendix.<br />
type poolLocalInternal struct {<br />
    private interface{}   // Can be used only by the respective P.<br />
    shared  []interface{} // Can be used by any P.<br />
    Mutex                 // Protects shared.<br />
}</p><br />
<br />
<p>type poolLocal struct {<br />
    poolLocalInternal</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// Prevents false sharing on widespread platforms with<br />
// 128 mod (cache line size) = 0 .<br />
pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } private：private私有池，只能被对应P使用（说明：P是指goroutine执行所占用的处理器，下同）<br />
</code></pre></div></div><br />
<br />
<p>shared： shared共享池，能被任何P使用</p><br />
<br />
<p>Mutex： 保护shared共享池</p><br />
<br />
<p>pad：poolLocal结构体中特别增加了pad成员，这是为了防止false sharing。</p><br />
<br />
<p>操作<br />
操作分为四种类型：</p><br />
<br />
<p>New<br />
Get<br />
Put<br />
CleanUp<br />
New<br />
这部分主要解决问题：如何创建一个具体对象池？</p><br />
<br />
<p>具体参考代码如下：</p><br />
<br />
<p>// Object Object<br />
type Object struct {<br />
    a int<br />
    b int<br />
}</p><br />
<br />
<p>var pool = sync.Pool{<br />
    New: func() interface{} { return new(Object) },<br />
}<br />
Get<br />
Get解决了如何从具体sync.Pool中获取对象的问题。</p><br />
<br />
<p>获取对象有三个来源：</p><br />
<br />
<p>private池<br />
shared池<br />
系统的Heap内存<br />
获取对象顺序是先从private池获取，如果不成功则从shared池获取，如果继续不成功，则从Heap中申请一个对象。这是不是有熟悉的味道？在两级cache的情况下，CPU获取数据，先从L1 cache开始，再是L2 cache， 是内存。</p><br />
<br />
<p>具体代码实现如下：</p><br />
<br />
<p>func (p *Pool) Get() interface{} {<br />
    if race.Enabled {<br />
        race.Disable()<br />
    }<br />
    l := p.pin() // 绑定private池和P<br />
    x := l.private<br />
    l.private = nil<br />
    runtime_procUnpin() // 去绑定private池和P<br />
    if x == nil { //  private池获取失败<br />
        l.Lock()<br />
        last := len(l.shared) - 1<br />
        if last &gt;= 0 {<br />
            x = l.shared[last] // 从shared池获取最后一个对象 <br />
            l.shared = l.shared[:last] // 从shared池删除最后一个对象<br />
        }<br />
        l.Unlock()<br />
        if x == nil { <br />
            x = p.getSlow() // pid对应poolLocal没有获取成功，开始遍历整个poolLocal数组<br />
        }<br />
    }<br />
    if race.Enabled {<br />
        race.Enable()<br />
        if x != nil {<br />
            race.Acquire(poolRaceAddr(x))<br />
        }<br />
    }<br />
    if x == nil &amp;&amp; p.New != nil {<br />
        x = p.New() // 从heap申请对象<br />
    }<br />
    return x<br />
}</p><br />
<br />
<p>func (p *Pool) getSlow() (x interface{}) {<br />
    // See the comment in pin regarding ordering of the loads.<br />
    size := atomic.LoadUintptr(&amp;p.localSize) // load-acquire<br />
    local := p.local                         // load-consume<br />
    // Try to steal one element from other procs.<br />
    pid := runtime_procPin()<br />
    runtime_procUnpin()<br />
    for i := 0; i &lt; int(size); i++ { // 遍历poolLocal数组<br />
        l := indexLocal(local, (pid+i+1)%int(size)) // 注意pid+i+1 这样可以从pid+1位置开始整个遍历<br />
        l.Lock()<br />
        last := len(l.shared) - 1<br />
        if last &gt;= 0 {<br />
            x = l.shared[last]<br />
            l.shared = l.shared[:last]<br />
            l.Unlock()<br />
            break<br />
        }<br />
        l.Unlock()<br />
    }<br />
    return x<br />
}</p><br />
<br />
<p>// pin pins the current goroutine to P, disables preemption and returns poolLocal pool for the P.<br />
// Caller must call runtime_procUnpin() when done with the pool.<br />
func (p *Pool) pin() *poolLocal {<br />
    pid := runtime_procPin()<br />
    // In pinSlow we store to localSize and then to local, here we load in opposite order.<br />
    // Since we’ve disabled preemption, GC cannot happen in between.<br />
    // Thus here we must observe local at least as large localSize.<br />
    // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness).<br />
    s := atomic.LoadUintptr(&amp;p.localSize) // load-acquire<br />
    l := p.local                          // load-consume<br />
    if uintptr(pid) &lt; s {<br />
        return indexLocal(l, pid)<br />
    }<br />
    return p.pinSlow() // 没有对应poolLocal，进入慢路径处理<br />
}</p><br />
<br />
<p>func (p *Pool) pinSlow() *poolLocal {<br />
    // Retry under the mutex.<br />
    // Can not lock the mutex while pinned.<br />
    runtime_procUnpin()<br />
    allPoolsMu.Lock()<br />
    defer allPoolsMu.Unlock()<br />
    pid := runtime_procPin()<br />
    // poolCleanup won’t be called while we are pinned.<br />
    s := p.localSize<br />
    l := p.local<br />
    if uintptr(pid) &lt; s { // 根据pid获取poolLocal<br />
        return indexLocal(l, pid) <br />
    }<br />
    if p.local == nil {<br />
        allPools = append(allPools, p)<br />
    }<br />
    // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one.<br />
    size := runtime.GOMAXPROCS(0)<br />
    local := make([]poolLocal, size) // 重新分配poolLocal<br />
    atomic.StorePointer(&amp;p.local, unsafe.Pointer(&amp;local[0])) // store-release<br />
    atomic.StoreUintptr(&amp;p.localSize, uintptr(size))         // store-release<br />
    return &amp;local[pid] // 返回新的poolLocal<br />
}</p><br />
<br />
<p>总结Get主要要点如下：</p><br />
<br />
<p>先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象<br />
上一步没有成功获取对象，再从其他P的shared池获取对象<br />
上一步没有成功获取对象，则从Heap申请对象<br />
Put<br />
Put完成将对象放回对象池。</p><br />
<br />
<p>// Put adds x to the pool.<br />
func (p *Pool) Put(x interface{}) {<br />
    if x == nil {<br />
        return<br />
    }<br />
    if race.Enabled {<br />
        if fastrand()%4 == 0 {<br />
            // Randomly drop x on floor.<br />
            return<br />
        }<br />
        race.ReleaseMerge(poolRaceAddr(x))<br />
        race.Disable()<br />
    }<br />
    l := p.pin() // 绑定private池和P<br />
    if l.private == nil {<br />
        l.private = x   // 放回private池中<br />
        x = nil<br />
    }<br />
    runtime_procUnpin() // 去绑定private池和P<br />
    if x != nil {<br />
        l.Lock()<br />
        l.shared = append(l.shared, x)  // 放回shared池<br />
        l.Unlock()<br />
    }<br />
    if race.Enabled {<br />
        race.Enable()<br />
    }<br />
}<br />
上面的代码总结如下：</p><br />
<br />
<p>如果poolLocalInternal的private为空，则将回收的对象放到private池中<br />
如果poolLocalInternal的private非空，则将回收的对象放到shared池中<br />
CleanUp<br />
CleanUp实现<br />
注册poolCleanup函数。</p><br />
<br />
<p>func init() {<br />
   runtime_registerPoolCleanup(poolCleanup)<br />
}</p><br />
<br />
<p>poolCleanup函数具体实现，</p><br />
<br />
<p>func poolCleanup() {<br />
    // This function is called with the world stopped, at the beginning of a garbage collection.<br />
    // It must not allocate and probably should not call any runtime functions.<br />
    // Defensively zero out everything, 2 reasons:<br />
    // 1. To prevent false retention of whole Pools.<br />
    // 2. If GC happens while a goroutine works with l.shared in Put/Get,<br />
    //    it will retain whole Pool. So next cycle memory consumption would be doubled.<br />
    for i, p := range allPools {<br />
        allPools[i] = nil<br />
        for i := 0; i &lt; int(p.localSize); i++ {<br />
            l := indexLocal(p.local, i)<br />
            l.private = nil<br />
            for j := range l.shared {<br />
                l.shared[j] = nil<br />
            }<br />
            l.shared = nil<br />
        }<br />
        p.local = nil<br />
        p.localSize = 0<br />
    }<br />
    allPools = []*Pool{}<br />
}<br />
CleanUp时机<br />
什么时候进行CleanUp回收对象池？在gc开始前。</p><br />
<br />
<p>具体代码(代码文件为runtime/mgc.go)如下：</p><br />
<br />
<p>func gcStart(trigger gcTrigger) {<br />
    … <br />
    // clearpools before we start the GC. If we wait they memory will not be<br />
    // reclaimed until the next GC cycle.<br />
    clearpools() // 在这里清理sync.Pool</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>work.cycles++<br />
<br />
gcController.startCycle()<br />
work.heapGoal = memstats.next_gc<br />
<br />
// In STW mode, disable scheduling of user Gs. This may also<br />
// disable scheduling of this goroutine, so it may block as<br />
// soon as we start the world again.<br />
if mode != gcBackgroundMode {<br />
    schedEnableUser(false)<br />
}<br />
... } func clearpools() {<br />
// clear sync.Pools<br />
if poolcleanup != nil {<br />
    poolcleanup() // 如果poolcleanup不为空，调用poolcleanup函数<br />
}<br />
<br />
// Clear central sudog cache.<br />
// Leave per-P caches alone, they have strictly bounded size.<br />
// Disconnect cached list before dropping it on the floor,<br />
// so that a dangling ref to one entry does not pin all of them.<br />
lock(&amp;sched.sudoglock)<br />
var sg, sgnext *sudog<br />
for sg = sched.sudogcache; sg != nil; sg = sgnext {<br />
    sgnext = sg.next<br />
    sg.next = nil<br />
}<br />
sched.sudogcache = nil<br />
unlock(&amp;sched.sudoglock)<br />
<br />
// Clear central defer pools.<br />
// Leave per-P pools alone, they have strictly bounded size.<br />
lock(&amp;sched.deferlock)<br />
for i := range sched.deferpool {<br />
    // disconnect cached list before dropping it on the floor,<br />
    // so that a dangling ref to one entry does not pin all of them.<br />
    var d, dlink *_defer<br />
    for d = sched.deferpool[i]; d != nil; d = dlink {<br />
        dlink = d.link<br />
        d.link = nil<br />
    }<br />
    sched.deferpool[i] = nil<br />
}<br />
unlock(&amp;sched.deferlock) } 总结 总结一下sync.Pool的实现，要点如下：<br />
</code></pre></div></div><br />
<br />
<p>提供New定义实现用户自定义对象<br />
需要使用对象调用Get从对象池获取临时对象，Get优先级首先是本P绑定的poolLocal, 其次是其他P绑定的poolLocal，最后是Heap内存<br />
对象使用完毕调用Put将临时对象放回对象池<br />
未被使用的对象会定时GC回收<br />
对象没有类似于linux cache object对应的free函数<br />
应用<br />
sync.Pool并不是万能药。要根据具体情境而定是否使用sync.Pool。</p><br />
<br />
<p>总结不适合使用sync.Pool的情境，具体如下：</p><br />
<br />
<p>对象中分配的系统资源如socket，buffer<br />
对象需要进行异步处理<br />
对象是组合对象，如存在指针指向其他的对象<br />
批量对象需要并发处理<br />
复用对象大小存在的波动，如对象结构成员存在slice<br />
在排除上面情境下，适合使用的sync.Pool应满足以下条件，具体如下：</p><br />
<br />
<p>对象是buffer或非组合类型如buffer reader, json decode, bufio writer<br />
对象内存可以重复使用<br />
同时在使用应该注意问题：</p><br />
<br />
<p>Put对象之前完成初始化，避免数据污染带来问题, 这可能带来各种各样的问题<br />
写代码时要满足one Get， one Put的要求<br />
注意获取对象后是否存在修改对象内存存局的代码<br />
关注应用场景是否容易出现Pool竞争的情况<br />
sync.Pool不是万能药，不要拿着锤子，看什么都是钉子</p><br />
<br />
<p>https://github.com/golang/go/issues/23199</p><br />
<br />
<p>Go 1.13持续对 sync.Pool进行了改进，这里我们有两个简单的灵魂拷问：</p><br />
<br />
<p>1、做了哪些改进？<br />
2、如何做的改进？</p><br />
<br />
<p>首先回答第一个问题：</p><br />
<br />
<p>对STW暂停时间做了优化, 避免大的sync.Pool严重影响STW时间<br />
第二个优化是GC时入股对sync.Pool进行回收，不会一次将池化对象全部回收，这就避免了sync.Pool释放对象和重建对象导致的性能尖刺，造福于sync.Pool重度用户。<br />
第三个就是对性能的优化。<br />
对以上的改进主要是两次提交：: sync: use lock-free structure for Pool stealing和sync: use lock-free structure for Pool stealing。</p><br />
<br />
<p>两次提交都不同程度的对性能有所提升，依据不同的场景，提升0.7% ～ 92%不同。 Go开发者有一个很好的习惯，或者叫做约定，或者是他们的开发规范，对于标准库的修改都会执行性能的比较，代码的修改不应该带来性能的降低。这两次提交的注释文档都详细的介绍了性能的比较结果。</p><br />
<br />
<p>知道了第一个问题的答案可以让我们对sync.Pool有信心，在一些场景下可以考虑使用sync.Pool，以便减少对象的创建和回收对GC的影响。</p><br />
<br />
<p>了解第二个问题可以让我们学到Go开发者的优化手段，或许在我们自己的项目中也使用这些优化手段来优化我们自己的代码。</p><br />
<br />
<p>sync: use lock-free structure for Pool stealing<br />
第一次提交提升用来提高sync.Pool的性能，减少STW时间。</p><br />
<br />
<p>Go 1.13之前，Pool使用一个Mutex保护的slice来存储每个shard的overflow对象。(sync.Pool使用shard方式存储池化对象，减少竞争。 每个P对应一个shard。如果需要创建多于一个池化对象，这些对象就叫做overflow)。</p><br />
<br />
<p>1<br />
2<br />
3<br />
4<br />
5<br />
type poolLocalInternal struct {		 type poolLocalInternal struct {<br />
 	private interface{}   // Can be used only by the respective P.	by the respective P.<br />
 	shared  []interface{} // Can be used by any P.<br />
 	Mutex                 // Protects shared.		<br />
 }<br />
那么在Go 1.13中，使用是以 lock-free的数据结构代替slice + Mutex的方式：</p><br />
<br />
<p>1<br />
2<br />
3<br />
4<br />
type poolLocalInternal struct {<br />
	private interface{} // Can be used only by the respective P.<br />
	shared  poolChain   // Local P can pushHead/popHead; any P can popTail.<br />
}<br />
这个lock-free的数据结构的实现很特别。</p><br />
<br />
<p>我们知道，实现lock-free的数据结构一般采用atomic的方式实现，通过CAS避免操作block住。sync.Pool也是采用这种方式，它定义了一个lock-free的双向链表:</p><br />
<br />
<p>1<br />
2<br />
3<br />
4<br />
type poolDequeue struct {<br />
	headTail uint64<br />
	vals []eface<br />
}<br />
poolDequeue是一个特别的队列，有以下特点：</p><br />
<br />
<p>lock-free<br />
固定大小，ring形结构(底层存储使用数组,使用两个指针标记ehead、tail)<br />
单生产者<br />
多消费者<br />
生产者可以从head进行pushHead、popHead<br />
消费者可以从tail进行popTail<br />
它的head和tail是采用一个uint64数值来表示的，好处就是我们可以通过atomic对这两个值整体进行CAS。它提供了unpack、pack可以从headTail中解析初独立的head和tail, 以及执行相反的操作。</p><br />
<br />
<p>数组存储在vals数组中，它采用interface的结构进行存储。</p><br />
<br />
<p>如果你看它的pushHead、popHead和popTail代码，可以看到它主要使用atomic来实现lock-free。lock-free代码比较简单，本文就不进行详细解读了，阅读的时候注意head和tail的边界问题。因为它是使用一个数组(准确的说是slice)实现一个ringbuffer的数据结构，这样能充分利用分配的空间。</p><br />
<br />
<p>sync.Pool还不是直接使用poolDequeue这样一个数据结构，原因在于poolDequeue是一个固定大小的队列，这个大小取什么值才合理呢？取的太小，以后可能不得不grow, 取的太大，又可能浪费。</p><br />
<br />
<p>解决这个问题就是采用动态增长的方式。它定义了一个队列链表池,可以实现动态的上述队列的增减:<br />
type poolChain struct {<br />
	head <em>poolChainElt //只会被生产者使用<br />
	tail *poolChainElt //只会被消费者使用<br />
}<br />
一开始，它会使用长度为8的poolDequeue做存储，一旦这个队列满了，就会再创建一个长度为16的队列，以此类推，只要当前的队列满了，就会新创建一 2</em>n的poolDequeue做存储。如果当前的poolDequeue消费完，就会丢弃。</p><br />
<br />
<p>这样一个动态可变的lock-free队列正是sync.Pool所要的,当然为了CPU缓存优化还进行了缓存行的对齐：<br />
type poolLocalInternal struct {<br />
	private interface{} // Can be used only by the respective P.<br />
	shared  poolChain   // Local P can pushHead/popHead; any P can popTail.<br />
}<br />
type poolLocal struct {<br />
	poolLocalInternal<br />
	pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte<br />
}<br />
type Pool struct {<br />
	noCopy noCopy<br />
	local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal<br />
	localSize uintptr        // size of the local array<br />
	New func() interface{}<br />
}<br />
Pool使用shard的方式实现池(local实际上是[P]poolLocal, 这里采用指针的方式)，它的Get、Put移除了Mutex的加锁控制，而是采用lock-free数据结构poolChain实现。</p><br />
<br />
<p>当然有人可能提出质疑: lock-free真的比Mutex性能好吗？在一定的竞争条件下，确实lock-free的性能要好于Mutex, 如果你举极端的例子，比如竞争非常激烈的情况，或许会有不同的结果，但是绝大部分情况下，lock-free性能还是要好一些。</p><br />
<br />
<p>注意Pool的实现中使用了runtime_procPin()方法，它可以将一个goroutine死死占用当前使用的P(P-M-G中的processor)，不允许其它goroutine/M抢占,这样它就可以自由的使用shard中和这个P相关的local，不必担心竞争的问题。释放pin的方法是runtime_procUnpin。</p><br />
<br />
<p>此时的poolCleanup (GC的时候对池化对象的释放)还是全部清空，进一步的优化在下一个提交中。</p><br />
<br />
<p>sync: smooth out Pool behavior over GC with a victim cache<br />
上一节提到每次Pool清理的时候都是把所有的池化对象都释放掉，这会带来两个问题：</p><br />
<br />
<p>浪费: 池化对象全部释放后等需要的时候又不得不重新创建<br />
GC尖峰:突然释放大量的池化对象会导致GC耗时增加<br />
所以这次提交引入了victim cache的机制。victim cache原是CPU硬件处理缓存的一种技术,</p><br />
<br />
<p>所谓受害者缓存（Victim Cache），是一个与直接匹配或低相联缓存并用的、容量很小的全相联缓存。当一个数据块被逐出缓存时，并不直接丢弃，而是暂先进入受害者缓存。如果受害者缓存已满，就替换掉其中一项。当进行缓存标签匹配时，在与索引指向标签匹配的同时，并行查看受害者缓存，如果在受害者缓存发现匹配，就将其此数据块与缓存中的不匹配数据块做交换，同时返回给处理器。</p><br />
<br />
<p>from wikipedia</p><br />
<br />
<p>相比较先前的直接清除Pool, 这次修改后是清除victim cache，然后将primary cache转移给victim cache。如果sync.Pool的获取释放速度稳定，那么就不会又新的池对象进行分配。如果获取的速度下降了，那么对象可能会在两个GC周期内被释放，而不是以前的一个GC周期。</p><br />
<br />
<p>同时，victim cache的设计也间接的提升GC的性能，因为稳定的sync.Pool使用导致池化的对象都是long-live的对象，而GC的主要对象是short-live的对象，所以会减少GC的执行。</p><br />
<br />
<p>相对于以前的实现，现在的sync.Pool的实现增加了victim相关的两个字段:<br />
type Pool struct {<br />
	noCopy noCopy<br />
	local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal<br />
	localSize uintptr        // size of the local array<br />
	victim     unsafe.Pointer // local from previous cycle<br />
	victimSize uintptr        // size of victims array<br />
	New func() interface{}<br />
}<br />
它主要影响两个方法的实现: getSlow和poolCleanup。</p><br />
<br />
<p>当前goroutine从自己的P对应的本地获取不到free的池化对象的话，就会调用getSlow, 尝试从其它shard中”偷取”。</p><br />
<br />
<p>如果不幸的是其它shard也没有free的池化对象的话，那么就就尝试从victim中找一个，寻找的方法和从本地中寻找是一样一样的。</p><br />
<br />
<p>找到的话就返回，找不到的话如果定义New创建函数，就创建一个，如果没定义New返回空。</p><br />
<br />
<p>清理的时候就是把每一个sync.Pool的victim都清空,然后再把本地local的池化对象赋值给victim， 本地对象都清空。</p><br />
<br />
<p>sync.Pool 整体 Get/Put 逻辑<br />
Vincent Blanchon曾在他的Go: Understand the Design of Sync.Pool一文中给出了sync.Pool go 1.12版本的Get/Put的流程图。这里我画了一个go 1.13版本的流程图，可以很好的理解sync.Pool处理的过程。<br />
https://colobu.com/2019/10/08/how-is-sync-Pool-improved-in-Go-1-13/<br />
Sync包提供了强大的可被重复利用实例池，为了降低垃圾回收的压力。在使用这个包之前，需要将你的应用跑出使用pool之前与之后的benchmark数据，因为在一些情况下使用如果你不清楚pool内部原理的话，反而会让应用的性能下降。<br />
pool的局限性<br />
我们先来看看一些基础的例子，来看看他在一个相当简单情况下（分配1K内存）是如何工作的：<br />
type Small struct {<br />
   a int<br />
}</p><br />
<br />
<p>var pool = sync.Pool{<br />
   New: func() interface{} { return new(Small) },<br />
}</p><br />
<br />
<p>//go:noinline<br />
func inc(s *Small) { s.a++ }</p><br />
<br />
<p>func BenchmarkWithoutPool(b *testing.B) {<br />
   var s *Small<br />
   for i := 0; i &lt; b.N; i++ {<br />
      for j := 0; j &lt; 10000; j++ {<br />
         s = &amp;Small{ a: 1, }<br />
         b.StopTimer(); inc(s); b.StartTimer()<br />
      }<br />
   }<br />
}</p><br />
<br />
<p>func BenchmarkWithPool(b <em>testing.B) {<br />
   var s *Small<br />
   for i := 0; i &lt; b.N; i++ {<br />
      for j := 0; j &lt; 10000; j++ {<br />
         s = pool.Get().(</em>Small)<br />
         s.a = 1<br />
         b.StopTimer(); inc(s); b.StartTimer()<br />
         pool.Put(s)<br />
      }<br />
   }<br />
}<br />
复制代码下面是两个benchmarks，一个是使用了sync.pool一个没有使用<br />
name           time/op        alloc/op        allocs/op<br />
WithoutPool-8  3.02ms ± 1%    160kB ± 0%      1.05kB ± 1%<br />
WithPool-8     1.36ms ± 6%   1.05kB ± 0%        3.00 ± 0%<br />
复制代码由于这个遍历有10k的迭代，那个没有使用pool的benchmark显示在堆上创建了10k的内存分配，而使用了pool的只使用了3. 3个分配由pool进行的，但只有一个结构体的实例被分配到内存。到目前为止可以看到使用pool对于内存的处理以及内存消耗上面更加友善。<br />
但是，在实际例子里面，当你使用pool，你的应用将会有很多新在堆上的内存分配。这种情况下，当内存升高了，就会触发垃圾回收。<br />
我们可以强制垃圾回收的发生通过使用runtime.GC()来模拟这种情形<br />
name           time/op        alloc/op        allocs/op<br />
WithoutPool-8  993ms ± 1%    249kB ± 2%      10.9k ± 0%<br />
WithPool-8     1.03s ± 4%    10.6MB ± 0%     31.0k ± 0%<br />
复制代码我们现在可以看到使用了pool的情况反而内存分配比不使用pool的时候高了。我们来深入地看一下这个包的源码来理解为什么会这样。<br />
内部工作流<br />
看一下sync/pool.go文件会给我们展示一个初始化函数，这个函数里面的内容能解释我们刚刚的情景：<br />
func init() {<br />
   runtime_registerPoolCleanup(poolCleanup)<br />
}<br />
复制代码这里在运行时注册成了一个方法去清理pools。并且同样的方法在垃圾回收里面也会触发，在文件runtime/mgc.go里面<br />
func gcStart(trigger gcTrigger) {<br />
   […]<br />
   // clearpools before we start the GC<br />
   clearpools()<br />
复制代码这就解释了为什么当调用垃圾回收时，性能会下降。pools在每次垃圾回收启动时都会被清理。这个文档其实已经有警告我们<br />
Any item stored in the Pool may be removed automatically at any time without notification<br />
复制代码接下来让我们创建一个工作流来理解一下这里面是如何管理的</p><br />
<br />
<p>sync.Pool workflow in Go 1.12</p><br />
<br />
<p>我们创建的每一个sync.Pool，go都会生成一个内部池poolLocal连接着各个processer（GMP中的P）。这些内部的池由两个属性组成private和shared。前者只是他的所有者可以访问(push以及pop操作，也因此不需要锁)，而`shared可以被任何processer读取并且是需要自己维持并发安全。而实际上，pool不是一个简单的本地缓存，他有可能在我们的程序中被用于任何的协程或者goroutines<br />
Go的1.13版将改善对shared的访问，还将带来一个新的缓存，该缓存解决与垃圾回收器和清除池有关的问题。<br />
新的无需锁pool和victim cache<br />
Go 1.13版本使用了一个新的双向链表作为shared pool，去除了锁，提高了shared的访问效率。这个改造主要是为了提高缓存性能。这里是一个访问shared的流程</p><br />
<br />
<p>new shared pools in Go 1.13</p><br />
<br />
<p>在这个新的链式pool里面，每一个processpr都可以在链表的头进行push与pop，然后访问shared可以从链表的尾pop出子块。结构体的大小在扩容的时候会变成原来的两倍，然后结构体之间使用next/prev指针进行连接。结构体默认大小是可以放下8个子项。这意味着第二个结构体可以容纳16个子项，第三个是32个子项以此类推。同样地，我们现在不再需要锁，代码执行具有原子性。<br />
关于新缓存，新策略非常简单。 现在有2组池：活动池和已归档池。 当垃圾收集器运行时，它将保留每个池对该池内新属性的引用，然后在清理当前池之前将池的集合复制到归档池中：<br />
// Drop victim caches from all pools.<br />
for _, p := range oldPools {<br />
   p.victim = nil<br />
   p.victimSize = 0<br />
}</p><br />
<br />
<p>// Move primary cache to victim cache.<br />
for _, p := range allPools {<br />
   p.victim = p.local<br />
   p.victimSize = p.localSize<br />
   p.local = nil<br />
   p.localSize = 0<br />
}</p><br />
<br />
<p>// The pools with non-empty primary caches now have non-empty<br />
// victim caches and no pools have primary caches.<br />
oldPools, allPools = allPools, nil<br />
复制代码通过这种策略，由于受害者缓存，该应用程序现在将有一个更多的垃圾收集器周期来创建/收集带有备份的新项目。 在工作流中，将在共享池之后在过程结束时请求牺牲者缓存。</p><br />
<br />
<p>一般 sync.Pool 用作小对像池，比如前公司同事，在 thrift golang lib 增加了 sync.Pool 实现 []byte 等对象的复用。网上也有很多 objectPool 的轮子，但总体实现都不如 sync.Pool 高效。</p><br />
<br />
<p>基本原理与演进初探<br />
想象一下如果我们自己实现，该怎么做呢？用一个定长的 channel 保存对象，拿到了就用，拿不到就 new 创建一个，伪代码大致如下：</p><br />
<br />
<p>type ObjectPool struct {<br />
    ch chan {}interface<br />
    newFunc func() {}interface<br />
}</p><br />
<br />
<p>func (o *ObjectPool) Get() {}interface {<br />
    select {<br />
        v := &lt;-o.ch:<br />
          return v<br />
        default:<br />
    }<br />
    return o.newFunc()<br />
}</p><br />
<br />
<p>func (o *ObjectPool) Put(v {}interface) {<br />
    select {<br />
        o.ch &lt;- v:<br />
        default:<br />
    }<br />
}<br />
代码很简洁，利用 select default 语法实现无阻塞操作。这里最大的问题就是 channel 也是有代价的，一把大锁让性能会变得很低，参考我之前的关 dpvs 性能优化。那怎么优化呢？多核 cpu 高并发编程，就是要每个 cpu 拥有自己的本地数据，这样就避免了锁争用的开销。而事实上 sync.Pool 也是这么做的。</p><br />
<br />
<p>看了下提交记录，从增加该功能后实现的大方现基本没变：</p><br />
<br />
<p>每个 P (逻辑并发模型，参考 GMP) 拥有本地缓存队列，如果本地获取不到对象，再从其它 P 去偷一个，其它 P 也没的话，调 new factory 创建新的返回。<br />
Pool 里的对象不是永生的，老的实现，对象如果仅由 Pool 引用，那么会在下次 GC 之间被销毁。但是最新优化 22950 里，为了优化 GC 后 Pool 为空导致的冷启动性能抖动，增加了 victim cache, 用来保存上一次 GC 本应被销毁的对象，也就是说，对象至少存活两次 GC 间隔。<br />
性能优化，将本地队列变成无锁队列( 单生产者，多消费者模型，严格来讲不通用)，还有一些 fix bug…<br />
数据结构及演进<br />
type Pool struct {<br />
    local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal<br />
    localSize uintptr        // size of the local array</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// New optionally specifies a function to generate<br />
// a value when Get would otherwise return nil.<br />
// It may not be changed concurrently with calls to Get.<br />
New func() interface{} }<br />
</code></pre></div></div><br />
<br />
<p>// Local per-P Pool appendix.<br />
type poolLocal struct {<br />
    private interface{}   // Can be used only by the respective P.<br />
    shared  []interface{} // Can be used by any P.<br />
    Mutex                 // Protects shared.<br />
    pad     [128]byte     // Prevents false sharing.<br />
}<br />
对象是存储在 poolLocal 里的，private 字段表示最新生成的单个对象，只能由本地 P 访问，shared 是一个 slice, 可以被任意 P 访问，Mutex 用来保护 shared. pad 用来对齐，作用参考我之前的 cpu cache</p><br />
<br />
<p>再加头看 Pool 结构体，New 是创建对象的工厂方法。local 是一个指向 []poolLocal 的指针(准确说，是 slice 底层数组的首地址)，localSize 是 slice 的长度，由于 P 的个数是可以在线调整的，所以 localSize 运行时可能会变化。访问时，P 的 id 对应 []poolLocal 下标索引。</p><br />
<br />
<p>type Pool struct {<br />
    noCopy noCopy</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal<br />
localSize uintptr        // size of the local array<br />
<br />
victim     unsafe.Pointer // local from previous cycle<br />
victimSize uintptr        // size of victims array<br />
<br />
// New optionally specifies a function to generate<br />
// a value when Get would otherwise return nil.<br />
// It may not be changed concurrently with calls to Get.<br />
New func() interface{} }<br />
</code></pre></div></div><br />
<br />
<p>// Local per-P Pool appendix.<br />
type poolLocalInternal struct {<br />
    private interface{} // Can be used only by the respective P.<br />
    shared  poolChain   // Local P can pushHead/popHead; any P can popTail.<br />
}</p><br />
<br />
<p>type poolLocal struct {<br />
    poolLocalInternal</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// Prevents false sharing on widespread platforms with<br />
// 128 mod (cache line size) = 0 .<br />
pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } Pool 增加了 noCopy 字段，Pool 默认创建后禁止拷贝，必须使用指针。noCopy 用来编绎时 go vet 检查，静态语言就是爽，编绎期干了好多脏活累活。参考 issue 8005 , 里面有很多讨论，关于禁止拷贝如何实现。 增加 victim cache, 以减少 GC 后冷启动导致的性能抖动。 poolLocal 拆成了两个结构体，pad 实现也稍微变了下，为了兼容更多硬件 cache line size. 另外最重要的优化，就是 shared slice 变成了无锁队列。 第一版本实现 对象 put // Put adds x to the pool. func (p *Pool) Put(x interface{}) {<br />
if raceenabled {<br />
    // Under race detector the Pool degenerates into no-op.<br />
    // It's conforming, simple and does not introduce excessive<br />
    // happens-before edges between unrelated goroutines.<br />
    return<br />
}<br />
if x == nil {<br />
    return<br />
}<br />
l := p.pin()<br />
if l.private == nil {<br />
    l.private = x<br />
    x = nil<br />
}<br />
runtime_procUnpin()<br />
if x == nil {<br />
    return<br />
}<br />
l.Lock()<br />
l.shared = append(l.shared, x)<br />
l.Unlock() } 逻辑很简单，先 pin 住，如果 private 字段为空，将对象放到 private 字段，否则添加到 share 池里。<br />
</code></pre></div></div><br />
<br />
<p>对象 get<br />
func (p *Pool) Get() interface{} {<br />
    if raceenabled { // race 检测时禁用 Pool 功能，后续去掉了这个<br />
        if p.New != nil {<br />
            return p.New()<br />
        }<br />
        return nil<br />
    }<br />
    l := p.pin() // pin 会禁止 P 被抢占，并返回本地 P 对应的 poolLocal 信息。<br />
    x := l.private<br />
    l.private = nil<br />
    runtime_procUnpin()<br />
    if x != nil { // 如果 private 有了，就不用去看 share 直接返回就好<br />
        return x<br />
    }<br />
    l.Lock() // 上锁保护 share<br />
    last := len(l.shared) - 1<br />
    if last &gt;= 0 {<br />
        x = l.shared[last]<br />
        l.shared = l.shared[:last]<br />
    }<br />
    l.Unlock()<br />
    if x != nil { // 此时从 share 中拿到了对象，返回即可<br />
        return x<br />
    }<br />
    return p.getSlow() // 走慢的逻辑：从其它 P 偷或是调用 new 工厂方法创建<br />
}</p><br />
<br />
<p>func (p *Pool) getSlow() (x interface{}) {<br />
    // See the comment in pin regarding ordering of the loads.<br />
    size := atomic.LoadUintptr(&amp;p.localSize) // load-acquire<br />
    local := p.local                         // load-consume<br />
    // Try to steal one element from other procs.<br />
    pid := runtime_procPin()<br />
    runtime_procUnpin()<br />
    for i := 0; i &lt; int(size); i++ { // 轮循从下一个 P 本地队列偷数据<br />
        l := indexLocal(local, (pid+i+1)%int(size))<br />
        l.Lock()<br />
        last := len(l.shared) - 1<br />
        if last &gt;= 0 {<br />
            x = l.shared[last]<br />
            l.shared = l.shared[:last]<br />
            l.Unlock()<br />
            break<br />
        }<br />
        l.Unlock()<br />
    }</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>if x == nil &amp;&amp; p.New != nil { // 其它 P 中也没偷到，New 一个<br />
    x = p.New()<br />
}<br />
return x } 从这里，可以看到大体逻辑，和之前描述基本一致，那具体 pin 如何实现的呢？有什么作用呢？接着看源码<br />
</code></pre></div></div><br />
<br />
<p>func sync·runtime_procPin() (p int) {<br />
    M *mp;</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mp = m;<br />
// Disable preemption.<br />
mp-&gt;locks++;<br />
p = mp-&gt;p-&gt;id; }<br />
</code></pre></div></div><br />
<br />
<p>func sync·runtime_procUnpin() {<br />
    m-&gt;locks–;<br />
}<br />
实际上 sync·runtime_procPin 和 sync·runtime_procUnpin 就是针对 M 进行加锁，防止被 runtime 抢占而己。Pin 除了上锁，会返回 P 的 id</p><br />
<br />
<p>// pin pins the current goroutine to P, disables preemption and returns poolLocal pool for the P.<br />
// Caller must call runtime_procUnpin() when done with the pool.<br />
func (p *Pool) pin() *poolLocal {<br />
    pid := runtime_procPin()<br />
    // In pinSlow we store to localSize and then to local, here we load in opposite order.<br />
    // Since we’ve disabled preemption, GC can not happen in between.<br />
    // Thus here we must observe local at least as large localSize.<br />
    // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness).<br />
    s := atomic.LoadUintptr(&amp;p.localSize) // load-acquire 获取 []poolLocal slice 长度<br />
    l := p.local                          // load-consume 获取 []poolLocal 首地址<br />
    if uintptr(pid) &lt; s { // 由于 P 的 id 就是 []poolLocal 下标<br />
        return indexLocal(l, pid)<br />
    }<br />
    return p.pinSlow()<br />
}</p><br />
<br />
<p>func (p <em>Pool) pinSlow() *poolLocal {<br />
    // Retry under the mutex.<br />
    // Can not lock the mutex while pinned.<br />
    runtime_procUnpin()<br />
    allPoolsMu.Lock()<br />
    defer allPoolsMu.Unlock()<br />
    pid := runtime_procPin()<br />
    // poolCleanup won’t be called while we are pinned.<br />
    s := p.localSize<br />
    l := p.local<br />
    if uintptr(pid) &lt; s { // pid 就是 slice 的下村，所以如果 pid 小于 s 就查找 slice<br />
        return indexLocal(l, pid)<br />
    }<br />
    if p.local == nil { // 第一次使用，把 Pool 添加到全局 allPools <br />
        allPools = append(allPools, p)<br />
    }<br />
    // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one. 走扩容逻辑<br />
    size := runtime.GOMAXPROCS(0)<br />
    local := make([]poolLocal, size)<br />
    atomic.StorePointer((</em>unsafe.Pointer)(&amp;p.local), unsafe.Pointer(&amp;local[0])) // store-release<br />
    atomic.StoreUintptr(&amp;p.localSize, uintptr(size))                            // store-release<br />
    return &amp;local[pid]<br />
}<br />
    // l 是指针地地，做类型转换，然后返回下标 i 的 poolLocal<br />
func indexLocal(l unsafe.Pointer, i int) <em>poolLocal {<br />
    return &amp;(</em>[1000000]poolLocal)(l)[i]<br />
}<br />
pin 的作用将当前 goroutine 和 P 进行绑定，禁止抢占，然后返回当前 P 所对应的 poolLocal 结构体。</p><br />
<br />
<p>localSize 是 []poolLocal slice 长度，由于是用 pid 做下标索引，所以如果 pid 小于 localSize，直接返回，否则走 pinSlow 逻辑<br />
pinSlow 触发有两点：Pool 第一次被使用，GOMAXPROCS 运行时个改。这时可以看到 p.local 直接用一个新的 slice 覆盖了，旧的对象池会被丢弃。<br />
可以看到，整体实现不是很复杂，最新版本与第一版变化不太大。</p><br />
<br />
<p>对象 cleanup<br />
func poolCleanup() {<br />
    // This function is called with the world stopped, at the beginning of a garbage collection.<br />
    // It must not allocate and probably should not call any runtime functions.<br />
    // Defensively zero out everything, 2 reasons:<br />
    // 1. To prevent false retention of whole Pools.<br />
    // 2. If GC happens while a goroutine works with l.shared in Put/Get,<br />
    //    it will retain whole Pool. So next cycle memory consumption would be doubled.<br />
    for i, p := range allPools {<br />
        allPools[i] = nil<br />
        for i := 0; i &lt; int(p.localSize); i++ {<br />
            l := indexLocal(p.local, i)<br />
            l.private = nil<br />
            for j := range l.shared {<br />
                l.shared[j] = nil<br />
            }<br />
            l.shared = nil<br />
        }<br />
    }<br />
    allPools = []*Pool{}<br />
}</p><br />
<br />
<p>var (<br />
    allPoolsMu Mutex<br />
    allPools   []*Pool<br />
)</p><br />
<br />
<p>func init() {<br />
    runtime_registerPoolCleanup(poolCleanup)<br />
}<br />
代码很简单，init 函数会将 poolCleanup 注册到 runtime, 在 GC 开始，STW 后执行，遍历 poolLocal 然后解引用即可。</p><br />
<br />
<p>indexLocal 性能优化<br />
参见官方 commit，修改如下</p><br />
<br />
<p>func indexLocal(l unsafe.Pointer, i int) *poolLocal {</p><br />
<ul><br />
  <li>return &amp;(*[1000000]poolLocal)(l)[i]</li><br />
  <li>lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{}))</li><br />
  <li>return (*poolLocal)(lp)<br />
 }<br />
    Performance results on linux/amd64:</li><br />
</ul><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>name            old time/op  new time/op  delta<br />
Pool-4          19.1ns ± 2%  10.1ns ± 1%  -47.15%  (p=0.000 n=10+8)<br />
PoolOverflow-4  3.11µs ± 1%  2.10µs ± 2%  -32.66%  (p=0.000 n=10+10)<br />
<br />
Performance results on linux/386:<br />
<br />
name            old time/op  new time/op  delta<br />
Pool-4          20.0ns ± 2%  13.1ns ± 1%  -34.59%  (p=0.000 n=10+9)<br />
PoolOverflow-4  3.51µs ± 1%  2.49µs ± 0%  -28.99%  (p=0.000 n=10+8) 可以看到，修改后性能大幅提升，那么这次性能优化的原理是什么呢？？？原版本是转化成 [1000000]poolLocal 定长数组后寻址，一个是直接根据 offset 定位到指定内存，然后做 poolLocal 类型转换。先看下汇编实现<br />
</code></pre></div></div><br />
<br />
<p>”“.indexLocal STEXT nosplit size=20 args=0x18 locals=0x0<br />
    0x0000 00000 (test.go:11)   TEXT    ““.indexLocal(SB), NOSPLIT|ABIInternal, $0-24<br />
    0x0000 00000 (test.go:11)   FUNCDATA    $0, gclocals·9fad110d66c97cf0b58d28cccea80b12(SB)<br />
    0x0000 00000 (test.go:11)   FUNCDATA    $1, gclocals·7d2d5fca80364273fb07d5820a76fef4(SB)<br />
    0x0000 00000 (test.go:11)   FUNCDATA    $3, gclocals·9a26515dfaeddd28bcbc040f1199f48d(SB)<br />
    0x0000 00000 (test.go:12)   PCDATA  $2, $0<br />
    0x0000 00000 (test.go:12)   PCDATA  $0, $0<br />
    0x0000 00000 (test.go:12)   MOVQ    ““.i+16(SP), AX<br />
    0x0005 00005 (test.go:12)   PCDATA  $2, $1<br />
    0x0005 00005 (test.go:12)   PCDATA  $0, $1<br />
    0x0005 00005 (test.go:12)   MOVQ    ““.l+8(SP), CX<br />
    0x000a 00010 (test.go:12)   PCDATA  $2, $2<br />
    0x000a 00010 (test.go:12)   LEAQ    (CX)(AX<em>8), AX<br />
    0x000e 00014 (test.go:13)   PCDATA  $2, $0<br />
    0x000e 00014 (test.go:13)   PCDATA  $0, $2<br />
    0x000e 00014 (test.go:13)   MOVQ    AX, “”.~r2+24(SP)<br />
    0x0013 00019 (test.go:13)   RET<br />
    0x0000 48 8b 44 24 10 48 8b 4c 24 08 48 8d 04 c1 48 89  H.D$.H.L$.H…H.<br />
    0x0010 44 24 18 c3                                      D$..<br />
““.indexLocal2 STEXT nosplit size=58 args=0x18 locals=0x8<br />
    0x0000 00000 (test.go:16)   TEXT    ““.indexLocal2(SB), NOSPLIT|ABIInternal, $8-24<br />
    0x0000 00000 (test.go:16)   SUBQ    $8, SP<br />
    0x0004 00004 (test.go:16)   MOVQ    BP, (SP)<br />
    0x0008 00008 (test.go:16)   LEAQ    (SP), BP<br />
    0x000c 00012 (test.go:16)   FUNCDATA    $0, gclocals·9fad110d66c97cf0b58d28cccea80b12(SB)<br />
    0x000c 00012 (test.go:16)   FUNCDATA    $1, gclocals·7d2d5fca80364273fb07d5820a76fef4(SB)<br />
    0x000c 00012 (test.go:16)   FUNCDATA    $3, gclocals·9fb7f0986f647f17cb53dda1484e0f7a(SB)<br />
    0x000c 00012 (test.go:17)   PCDATA  $2, $1<br />
    0x000c 00012 (test.go:17)   PCDATA  $0, $1<br />
    0x000c 00012 (test.go:17)   MOVQ    ““.l+16(SP), AX<br />
    0x0011 00017 (test.go:17)   TESTB   AL, (AX)<br />
    0x0013 00019 (test.go:17)   MOVQ    ““.i+24(SP), CX<br />
    0x0018 00024 (test.go:17)   CMPQ    CX, $1000000<br />
    0x001f 00031 (test.go:17)   JCC 51<br />
    0x0021 00033 (test.go:17)   LEAQ    (AX)(CX</em>8), AX<br />
    0x0025 00037 (test.go:17)   PCDATA  $2, $0<br />
    0x0025 00037 (test.go:17)   PCDATA  $0, $2<br />
    0x0025 00037 (test.go:17)   MOVQ    AX, “”.~r2+32(SP)<br />
    0x002a 00042 (test.go:17)   MOVQ    (SP), BP<br />
    0x002e 00046 (test.go:17)   ADDQ    $8, SP<br />
    0x0032 00050 (test.go:17)   RET<br />
    0x0033 00051 (test.go:17)   PCDATA  $0, $1<br />
    0x0033 00051 (test.go:17)   CALL    runtime.panicindex(SB)<br />
    0x0038 00056 (test.go:17)   UNDEF<br />
indexLocal 是优化之后的，indexLocal2 是优化前的代码。可以看多，老版本多了个 CMPQ, 也就是查看是否数组越界的检查，多了层分支预测的逻辑。想不到吧，两种转换方式还有性能差距。</p><br />
<br />
<p>增加无锁队列<br />
poolLocal.share 字段由 []interface{} 变成了 poolChain, 这个队列专为 Pool 而设计，单生产者多消费者，多消费者消费时使用 CAS 实现无锁，参见 commit. 个人觉得不如 dpdk ring 实现的好。</p><br />
<br />
<p>Currently, Pool stores each per-P shard’s overflow in a slice<br />
protected by a Mutex. In order to store to the overflow or steal from<br />
another shard, a P must lock that shard’s Mutex. This allows for<br />
simple synchronization between Put and Get, but has unfortunate<br />
consequences for clearing pools.</p><br />
<br />
<p>Pools are cleared during STW sweep termination, and hence rely on<br />
pinning a goroutine to its P to synchronize between Get/Put and<br />
clearing. This makes the Get/Put fast path extremely fast because it<br />
can rely on quiescence-style coordination, which doesn’t even require<br />
atomic writes, much less locking.</p><br />
<br />
<p>The catch is that a goroutine cannot acquire a Mutex while pinned to<br />
its P (as this could deadlock). Hence, it must drop the pin on the<br />
slow path. But this means the slow path is not synchronized with<br />
clearing. As a result,</p><br />
<br />
<p>1) It’s difficult to reason about races between clearing and the slow<br />
path. Furthermore, this reasoning often depends on unspecified nuances<br />
of where preemption points can occur.</p><br />
<br />
<p>2) Clearing must zero out the pointer to every object in every Pool to<br />
prevent a concurrent slow path from causing all objects to be<br />
retained. Since this happens during STW, this has an O(# objects in<br />
Pools) effect on STW time.</p><br />
<br />
<p>3) We can’t implement a victim cache without making clearing even<br />
slower.</p><br />
<br />
<p>This CL solves these problems by replacing the locked overflow slice<br />
with a lock-free structure. This allows Gets and Puts to be pinned the<br />
whole time they’re manipulating the shards slice (Pool.local), which<br />
eliminates the races between Get/Put and clearing. This, in turn,<br />
eliminates the need to zero all object pointers, reducing clearing to<br />
O(# of Pools) during STW.</p><br />
<br />
<p>In addition to significantly reducing STW impact, this also happens to<br />
speed up the Get/Put fast-path and the slow path. It somewhat<br />
increases the cost of PoolExpensiveNew, but we’ll fix that in the next<br />
CL.</p><br />
<br />
<p>name                 old time/op     new time/op     delta<br />
Pool-12                 3.00ns ± 0%     2.21ns ±36%  -26.32%  (p=0.000 n=18+19)<br />
PoolOverflow-12          600ns ± 1%      587ns ± 1%   -2.21%  (p=0.000 n=16+18)<br />
PoolSTW-12              71.0µs ± 2%      5.6µs ± 3%  -92.15%  (p=0.000 n=20+20)<br />
PoolExpensiveNew-12     3.14ms ± 5%     3.69ms ± 7%  +17.67%  (p=0.000 n=19+20)</p><br />
<br />
<p>name                 old p50-ns/STW  new p50-ns/STW  delta<br />
PoolSTW-12               70.7k ± 1%       5.5k ± 2%  -92.25%  (p=0.000 n=20+20)</p><br />
<br />
<p>name                 old p95-ns/STW  new p95-ns/STW  delta<br />
PoolSTW-12               73.1k ± 2%       6.7k ± 4%  -90.86%  (p=0.000 n=18+19)</p><br />
<br />
<p>name                 old GCs/op      new GCs/op      delta<br />
PoolExpensiveNew-12       0.38 ± 1%       0.39 ± 1%   +2.07%  (p=0.000 n=20+18)</p><br />
<br />
<p>name                 old New/op      new New/op      delta<br />
PoolExpensiveNew-12       33.9 ± 6%       40.0 ± 6%  +17.97%  (p=0.000 n=19+20)<br />
完整的看下 Get 代码实现：</p><br />
<br />
<p>func (p *Pool) Get() interface{} {<br />
    if race.Enabled {<br />
        race.Disable()<br />
    }<br />
    l, pid := p.pin()<br />
    x := l.private<br />
    l.private = nil<br />
    if x == nil {<br />
        // Try to pop the head of the local shard. We prefer<br />
        // the head over the tail for temporal locality of<br />
        // reuse.<br />
        x, _ = l.shared.popHead()<br />
        if x == nil {<br />
            x = p.getSlow(pid)<br />
        }<br />
    }<br />
    runtime_procUnpin()<br />
    if race.Enabled {<br />
        race.Enable()<br />
        if x != nil {<br />
            race.Acquire(poolRaceAddr(x))<br />
        }<br />
    }<br />
    if x == nil &amp;&amp; p.New != nil {<br />
        x = p.New()<br />
    }<br />
    return x<br />
}</p><br />
<br />
<p>func (p *Pool) getSlow(pid int) interface{} {<br />
    // See the comment in pin regarding ordering of the loads.<br />
    size := atomic.LoadUintptr(&amp;p.localSize) // load-acquire<br />
    local := p.local                         // load-consume<br />
    // Try to steal one element from other procs.<br />
    for i := 0; i &lt; int(size); i++ {<br />
        l := indexLocal(local, (pid+i+1)%int(size))<br />
        if x, _ := l.shared.popTail(); x != nil {<br />
            return x<br />
        }<br />
    }<br />
    return nil<br />
}<br />
具体无锁队列怎么实现的，就不贴了，各种 CAS… 没啥特别的。</p><br />
<br />
<p>增加 victim cache<br />
为什么要增加 victim cache 看这个 22950，说白了，就是要减少 GC 清除所有 Pool 后的冷启动问题，让分配对象更平滑。参见 commit.</p><br />
<br />
<p>Currently, every Pool is cleared completely at the start of each GC.<br />
This is a problem for heavy users of Pool because it causes an<br />
allocation spike immediately after Pools are clear, which impacts both<br />
throughput and latency.</p><br />
<br />
<p>This CL fixes this by introducing a victim cache mechanism. Instead of<br />
clearing Pools, the victim cache is dropped and the primary cache is<br />
moved to the victim cache. As a result, in steady-state, there are<br />
(roughly) no new allocations, but if Pool usage drops, objects will<br />
still be collected within two GCs (as opposed to one).</p><br />
<br />
<p>This victim cache approach also improves Pool’s impact on GC dynamics.<br />
The current approach causes all objects in Pools to be short lived.<br />
However, if an application is in steady state and is just going to<br />
repopulate its Pools, then these objects impact the live heap size <em>as<br />
if</em> they were long lived. Since Pooled objects count as short lived<br />
when computing the GC trigger and goal, but act as long lived objects<br />
in the live heap, this causes GC to trigger too frequently. If Pooled<br />
objects are a non-trivial portion of an application’s heap, this<br />
increases the CPU overhead of GC. The victim cache lets Pooled objects<br />
affect the GC trigger and goal as long-lived objects.</p><br />
<br />
<p>This has no impact on Get/Put performance, but substantially reduces<br />
the impact to the Pool user when a GC happens. PoolExpensiveNew<br />
demonstrates this in the substantially reduction in the rate at which<br />
the “New” function is called.</p><br />
<br />
<p>name                 old time/op     new time/op     delta<br />
Pool-12                 2.21ns ±36%     2.00ns ± 0%     ~     (p=0.070 n=19+16)<br />
PoolOverflow-12          587ns ± 1%      583ns ± 1%   -0.77%  (p=0.000 n=18+18)<br />
PoolSTW-12              5.57µs ± 3%     4.52µs ± 4%  -18.82%  (p=0.000 n=20+19)<br />
PoolExpensiveNew-12     3.69ms ± 7%     1.25ms ± 5%  -66.25%  (p=0.000 n=20+19)</p><br />
<br />
<p>name                 old p50-ns/STW  new p50-ns/STW  delta<br />
PoolSTW-12               5.48k ± 2%      4.53k ± 2%  -17.32%  (p=0.000 n=20+20)</p><br />
<br />
<p>name                 old p95-ns/STW  new p95-ns/STW  delta<br />
PoolSTW-12               6.69k ± 4%      5.13k ± 3%  -23.31%  (p=0.000 n=19+18)</p><br />
<br />
<p>name                 old GCs/op      new GCs/op      delta<br />
PoolExpensiveNew-12       0.39 ± 1%       0.32 ± 2%  -17.95%  (p=0.000 n=18+20)</p><br />
<br />
<p>name                 old New/op      new New/op      delta<br />
PoolExpensiveNew-12       40.0 ± 6%       12.4 ± 6%  -68.91%  (p=0.000 n=20+19)<br />
重点在注释的第一段，以前 Pool 的原理：如果对象在 GC 时只有 Pool 引用这个对象，那么会在 GC 时被释放掉。但是对于 Pool 重度用户来讲，GC 后会有大量的对象分配创建，影响吞吐和性能。这个 patch 就是为了让更平滑，变成了对象至少存活两个 GC 区间。</p><br />
<br />
<p>func poolCleanup() {<br />
    // This function is called with the world stopped, at the beginning of a garbage collection.<br />
    // It must not allocate and probably should not call any runtime functions.</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// Because the world is stopped, no pool user can be in a<br />
// pinned section (in effect, this has all Ps pinned).<br />
<br />
// Drop victim caches from all pools.<br />
for _, p := range oldPools {<br />
    p.victim = nil<br />
    p.victimSize = 0<br />
}<br />
<br />
// Move primary cache to victim cache.<br />
for _, p := range allPools {<br />
    p.victim = p.local<br />
    p.victimSize = p.localSize<br />
    p.local = nil<br />
    p.localSize = 0<br />
}<br />
<br />
// The pools with non-empty primary caches now have non-empty<br />
// victim caches and no pools have primary caches.<br />
oldPools, allPools = allPools, nil } 可以看下新版 poolCleanup 函数最后一行。使用时 Get 会在 slow path 逻辑里调用 victim cache.<br />
</code></pre></div></div><br />
<br />
<p>总结<br />
衡量一个基础组件，不仅要看他的性能，还要考滤稳定性，尤其是这种语言标准库。</p><br />
<br />
<p>最近golang的1.13版本发布了，有很多新特性与改进合入。这里主要分析sync.pool的优化。</p><br />
<br />
<p>本文主要解答以下几个问题：</p><br />
<br />
<p>sync.pool优化体现在哪里？<br />
优化是如何实现？<br />
优化的好处有哪些？<br />
优化<br />
具体优化项如下：</p><br />
<br />
<p>无锁化<br />
GC策略<br />
无锁化<br />
sync.pool实现了无锁化，具体如下：</p><br />
<br />
<p>go1.12.1版本实现</p><br />
<br />
<p>// Local per-P Pool appendix.<br />
type poolLocalInternal struct {<br />
    private interface{}   // Can be used only by the respective P.<br />
    shared  []interface{} // Can be used by any P.<br />
    Mutex                 // Protects shared.<br />
}<br />
go1.13版本</p><br />
<br />
<p>// Local per-P Pool appendix.<br />
type poolLocalInternal struct {<br />
    private interface{} // Can be used only by the respective P.<br />
    shared  poolChain   // Local P can pushHead/popHead; any P can popTail.<br />
}<br />
通过上面对比发现了go1.12版本的Mutex删除了。那么go1.13版本又是如何实现无锁化的呢？</p><br />
<br />
<p>先回答问题：go1.13通过poolChain实现SPMC的无锁队列来实现无锁化。</p><br />
<br />
<p>poolChain是什么东东呢？</p><br />
<br />
<p>别急，代码面前无秘密。 我们具体看一下代码就可以了。</p><br />
<br />
<p>// poolChain is a dynamically-sized version of poolDequeue.<br />
//<br />
// This is implemented as a doubly-linked list queue of poolDequeues<br />
// where each dequeue is double the size of the previous one. Once a<br />
// dequeue fills up, this allocates a new one and only ever pushes to<br />
// the latest dequeue. Pops happen from the other end of the list and<br />
// once a dequeue is exhausted, it gets removed from the list.<br />
type poolChain struct {<br />
    // head is the poolDequeue to push to. This is only accessed<br />
    // by the producer, so doesn’t need to be synchronized.<br />
    head *poolChainElt</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// tail is the poolDequeue to popTail from. This is accessed<br />
// by consumers, so reads and writes must be atomic.<br />
tail *poolChainElt }<br />
</code></pre></div></div><br />
<br />
<p>type poolChainElt struct {<br />
    poolDequeue</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// next and prev link to the adjacent poolChainElts in this<br />
// poolChain.<br />
//<br />
// next is written atomically by the producer and read<br />
// atomically by the consumer. It only transitions from nil to<br />
// non-nil.<br />
//<br />
// prev is written atomically by the consumer and read<br />
// atomically by the producer. It only transitions from<br />
// non-nil to nil.<br />
next, prev *poolChainElt } 关于poolChain是如何实现SPMC无锁队列？具体可以分析poolqueue.go的代码。 这一部分不展开说明，要点如下：<br />
</code></pre></div></div><br />
<br />
<p>无锁队列是SPMC<br />
无锁队列是可以灵活调整大小，调整大小的方法：slice+double-list实现（根据这个思路来阅读代码也是容易理解 ）<br />
无锁队列的实现基础是CAS<br />
好处<br />
避免锁的开销，mutex变成atomic<br />
GC策略<br />
相比较于go1.12版本，go1.13版本中增加了victim cache。具体作法是：</p><br />
<br />
<p>GC处理过程直接回收oldPools的对象<br />
GC处理并不直接将allPools的object直接进行GC处理，而是保存到oldPools，等到下一个GC周期到了再处理<br />
具体代码如下：</p><br />
<br />
<p>var (<br />
    allPoolsMu Mutex<br />
    allPools   []*Pool<br />
)<br />
var (<br />
    allPoolsMu Mutex</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// allPools is the set of pools that have non-empty primary<br />
// caches. Protected by either 1) allPoolsMu and pinning or 2)<br />
// STW.<br />
allPools []*Pool<br />
<br />
// oldPools is the set of pools that may have non-empty victim<br />
// caches. Protected by STW.<br />
oldPools []*Pool ) func poolCleanup() {<br />
// This function is called with the world stopped, at the beginning of a garbage collection.<br />
// It must not allocate and probably should not call any runtime functions.<br />
<br />
// Because the world is stopped, no pool user can be in a<br />
// pinned section (in effect, this has all Ps pinned).<br />
<br />
// Drop victim caches from all pools.<br />
for _, p := range oldPools {<br />
    p.victim = nil<br />
    p.victimSize = 0<br />
}<br />
<br />
// Move primary cache to victim cache.<br />
for _, p := range allPools {<br />
    p.victim = p.local<br />
    p.victimSize = p.localSize<br />
    p.local = nil<br />
    p.localSize = 0<br />
}<br />
<br />
// The pools with non-empty primary caches now have non-empty<br />
// victim caches and no pools have primary caches.<br />
oldPools, allPools = allPools, nil } 这样可导致Get的实现有变化，原来的实现是：<br />
</code></pre></div></div><br />
<br />
<p>先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象<br />
上一步没有成功获取对象，再从其他P的shared池获取对象<br />
上一步没有成功获取对象，则从Heap申请对象<br />
引入victim cache，Get实现变成如下：</p><br />
<br />
<p>先从本P绑定的poolLocal获取对象：先从本poolLocal的private池获取对象，再从本poolLocal的shared池获取对象<br />
上一步没有成功获取对象，再从其他P的shared池获取对象<br />
上一步没有成功，则从victim cache获取对象<br />
上一步没有成功获取对象，则从Heap申请对象<br />
具体代码如下：</p><br />
<br />
<p>func (p *Pool) getSlow(pid int) interface{} {<br />
    // See the comment in pin regarding ordering of the loads.<br />
    size := atomic.LoadUintptr(&amp;p.localSize) // load-acquire<br />
    locals := p.local                        // load-consume<br />
    // Try to steal one element from other procs.<br />
    for i := 0; i &lt; int(size); i++ {<br />
        l := indexLocal(locals, (pid+i+1)%int(size))<br />
        if x, _ := l.shared.popTail(); x != nil {<br />
            return x<br />
        }<br />
    }</p><br />
<br />
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// Try the victim cache. We do this after attempting to steal<br />
// from all primary caches because we want objects in the<br />
// victim cache to age out if at all possible.<br />
// 尝试从victim cache获取<br />
size = atomic.LoadUintptr(&amp;p.victimSize)<br />
if uintptr(pid) &gt;= size {<br />
    return nil<br />
}<br />
locals = p.victim<br />
l := indexLocal(locals, pid)<br />
if x := l.private; x != nil {<br />
    l.private = nil<br />
    return x<br />
}<br />
for i := 0; i &lt; int(size); i++ {<br />
    l := indexLocal(locals, (pid+i)%int(size))<br />
    if x, _ := l.shared.popTail(); x != nil {<br />
        return x<br />
    }<br />
}<br />
<br />
// Mark the victim cache as empty for future gets don't bother<br />
// with it.<br />
atomic.StoreUintptr(&amp;p.victimSize, 0)<br />
<br />
return nil } 好处 空间上通过引入victim cache增加了Get获取内存的选项，增加了对象复用的概率 时间上通过延迟GC，增加了对象复用的时间长度 上面这个两个方面降低了GC开销，增加了对象使用效率<br />
</code></pre></div></div><br />

					 <span class='st_sharethis_large' displayText='ShareThis'></span>
						<span class='st_facebook_large' displayText='Facebook'></span>
						<span class='st_twitter_large' displayText='Tweet'></span>
						<span class='st_linkedin_large' displayText='LinkedIn'></span>
						<span class='st_pinterest_large' displayText='Pinterest'></span>
						<span class='st_email_large' displayText='Email'></span>
                </div>
                Category golang
        </div>
	</div>
  
  
       <!--赞-->
    	  <div class="row">
            <div class="col-lg-6">
                <img src="https://xiazemin.github.io/MyBlog/img/webwxgetmsgimg.jpeg"  height="400" width="auto" />
            </div>
          </div>

        <div class="row">
                <div class="col-md-12">
			<div id="disqus_thread"></div>

<div id="gitmentContainer"></div>
<link rel="stylesheet" href="/MyBlog/css/default.css">
<script src="/MyBlog/js/gitment.browser.js"></script>
<script type="text/javascript" src="/MyBlog/js/json2.js"></script>
<script>
var gitment = new Gitment({
    owner: 'xiazemin',
    repo: 'MyBlogComment',
    oauth: {
        client_id: '981ba8c916c262631ea0',
        client_secret: 'a52260ef92de69011ccd1cf355b973ef11d6da0e',
    },
});

var MyGitmentContainer=gitment.render('gitmentContainer');
window.setTimeout(MyGitMentBtnclick,1000); 
//document.ready(function(){ 
//window.onload=function(){}

function MyGitMentBtnclick(){
//var MyGitmentContainer=document.getElementById('gitmentContainer');
	var ele=[],all=MyGitmentContainer.getElementsByTagName("*");
	for(var i=0;i<all.length;i++){
	  if(all[i].className=='gitment-comments-init-btn'){
		MyGitMentBtn=all[i];
		console.log(MyGitMentBtn);
		MyGitMentBtn.click();
	  }
	}
}

</script>



			<!--script>
			/**
			* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
			* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
			*/
			/*
			var disqus_config = function () {
			this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
			this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
			};
			*/
			(function() { // DON'T EDIT BELOW THIS LINE
			var d = document, s = d.createElement('script');

			s.src = '//airrayagroup.disqus.com/embed.js';

			s.setAttribute('data-timestamp', +new Date());
			(d.head || d.body).appendChild(s);
			})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			<script id="dsq-count-scr" src="//airrayagroup.disqus.com/count.js" async></script-->
          </div>
       </div>

</div>
<hr>
     <footer>
        <div class="container">
             <a href="/MyBlog/" style="color: green; font-size: 2em; font-family: 'Schoolbell', cursive;">首页</a>
            <div class="row">
                <div class="col-lg-6">
                    <p>Copyright &copy; 2017 465474307@qq.com <p>
                </div>
                <div class="col-lg-6">
                    <p style="float: right;">Jekyll theme by <a href="https://github.com/xiazemin/">夏泽民</a></p>
                </div>
            </div>
        </div>
    </footer>
	
    <!-- jQuery -->
    <script src="/MyBlog/js/jquery-1.12.0.min.js"></script>
    <script src="/MyBlog/js/jquery-migrate-1.2.1.min.js"></script>

    <!-- Latest compiled and minified JavaScript -->
    <script src="/MyBlog/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
        <!-- Menu Toggle Script -->
    <script>
    $("#menu-toggle").click(function(e) {
        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
    </script>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"6","bdPos":"right","bdTop":"100"},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/MyBlog/shareapi/js/share.js?v=89860593.js?'];</script>


<!-- 2d  -->
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.0.min.js"></script>
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.min.js"></script>
<script type="text/javascript">
 setTimeout(()=> {
/*L2Dwidget.init({"display": {
        "superSample": 2,
        "width": 200,
        "height": 400,
             "position": "right",
                 "hOffset": 0,
        "vOffset": 0
          }
     });
*/
 L2Dwidget
        .on('*', (name) => {
          console.log('%c EVENT ' + '%c -> ' + name, 'background: #222; color: yellow', 'background: #fff; color: #000')
        })
        .init({
          dialog: {
            // 开启对话框
            enable: true,
            script: {
              // 每空闲 10 秒钟，显示一条一言
              'every idle 10s': '$hitokoto$',
              // 当触摸到星星图案
              'hover .star': '星星在天上而你在我心里 (*/ω＼*)',
              // 当触摸到角色身体
              'tap body': '哎呀！别碰我！',
              // 当触摸到角色头部
              'tap face': '人家已经不是小孩子了！'
            }
          }
        });

})
</script>



    <!--html xmlns:wb="http://open.weibo.com/wb">
    <script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
    <wb:follow-button uid="2165491993" type="red_1" width="67" height="24" ></wb:follow-button-->

      <!--本文来自-->
     <script type="text/javascript">
      /* 仅IE
     document.body.oncopy = function(){
        setTimeout( 
            function () { 
        var text =window.clipboardData.getData("text"); 
        if (text) { 
            text = text + "/r/n本篇文章来源于 xiazemin 的 泽民博客|https://xiazemin.github.io/MyBlog/index.html 原文链接："+location.href; clipboardData.setData("text", text); 
          }
       },
     100 )
    }
     */
     //绑定在了body上，也可以绑定在其他可用元素行，但是不是所有元素都支持copy和past事件。

     /*
$(document.body).bind({
    copy: function(event) {//copy事件
        //var cpTxt = "复制的数据";
        var clipboardData = window.clipboardData; //for IE
        if (!clipboardData) { // for chrome
            clipboardData = event.originalEvent.clipboardData;
        }

        if (event.clipboardData != null/false/undefined) { //ignore the incorrectness of the truncation
        clipboarddata = event.clipboardData;
        } else if (window.clipboardData != null/false/undefined) {
         clipboarddata = window.clipboardData;
        } else { //default to the last option even if it is null/false/undefined
         clipboarddata = event.originalEvent.clipboardData;
        }

        //e.clipboardData.getData('text');//可以获取用户选中复制的数据
        //clipboardData.setData('Text', cpTxt);
        alert(clipboarddata.getData('text'));
        //$('#message').text('Copy Data : ' + cpTxt);
        return false;//否则设不生效
    },paste: function(e) {//paste事件
        var eve = e.originalEvent
        var cp = eve.clipboardData;
        var data = null;
        var clipboardData = window.clipboardData; // IE
        if (!clipboardData) { //chrome
            clipboardData = e.originalEvent.clipboardData
        }
        data = clipboardData.getData('Text');
        //$('#message').html(data);
    }
});     
*/
function addLink() {
    var body_element = document.getElementsByTagName('body')[0];
    var selection;
    selection = window.getSelection();
    var pagelink = "<br /><br />本文来源：xiazemin 的 泽民博客 <a href='"+document.location.href+"'>"+document.location.href+"</a>";
//+document.location.href+当前页面链接
    var copy_text = selection + pagelink;
    console.log(copy_text);
    var new_div = document.createElement('div');
    new_div.style.left='-99999px';
    new_div.style.position='absolute';
    body_element.appendChild(new_div );
    new_div.innerHTML = copy_text ;
    selection.selectAllChildren(new_div );
    window.setTimeout(function() {
        body_element.removeChild(new_div );
    },0);
}
document.oncopy = addLink;
     </script>
    <!--本文来自-->

</div>
  </body>

</html>