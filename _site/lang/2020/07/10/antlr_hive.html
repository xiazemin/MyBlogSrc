<!DOCTYPE html>
<html>

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Sci blog jekyll theme">
    <meta name="author" content="AIR RAYA Group">
    <link href='/MyBlog/img/favicon.ico' type='image/icon' rel='shortcut icon'/>

    <title>泽民博客 | Jekyll theme</title>

    <link rel="stylesheet" href="/MyBlog/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="/MyBlog/css/font-awesome.min.css">
    <link href="/MyBlog/css/simple-sidebar.css" rel="stylesheet">
	<link href="/MyBlog/css/classic-10_7.css" rel="stylesheet" type="text/css">
    <!-- Custom CSS -->
    <link href="/MyBlog/css/style.css" rel="stylesheet">
    <link href="/MyBlog/css/pygments.css" rel="stylesheet">
    <!-- Fonts -->
 <link href="/MyBlog/css/front.css" rel="stylesheet" type="text/css">
 <link href="/MyBlog/css/Josefin_Slab.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Architects_Daughter.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Schoolbell.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Codystar.css" rel="stylesheet" type="text/css">

 <script type="text/javascript" src="/MyBlog/js/jquery-1.12.0.min.js"></script>	

<link href="/MyBlog/css/calendar/common.css" type="text/css"  rel="stylesheet">
<script type="text/javascript" src="/MyBlog/js/calendar/calendar.js"></script>
	<!-- share this -->
	<script type="text/javascript">var switchTo5x=true;</script>
	<script type="text/javascript" src="/MyBlog/js/buttons.js"></script>
	<script type="text/javascript">stLight.options({publisher: "b28464c3-d287-4257-ad18-058346dd35f7", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="/MyBlog/js/html5shiv.js"></script>
        <script src="/MyBlog/js/respond.min.js"></script>
    <![endif]-->
   
   <!--百度统计-->
    <script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e965cab8c73512b8b23939e7051d93bd";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <script async src="/MyBlog/katex/katex.js"></script>
    <link rel="stylesheet" href="/MyBlog/katex/katex.css">

    <!--轮播图片-->
    <!--script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.stripesrotator.js"></script>
    <script type="text/javascript">
                    $(document).ready(function() {
                    alert($('#rotator_xzm'));
                     alert($('#rotator_xzm').fn);
                    $('#rotator_xzm').stripesRotator({ images: [ "https://xiazemin.github.io/MyBlog/img/BPlusTree.png", "https://xiazemin.github.io/MyBlog/img/linuxMMap.jpeg"] });
                    });
    </script-->

    <!--水印-->
    <script type="text/javascript" src="/MyBlog/js/waterMark.js"></script>
    <script type="text/javascript">
    $(document).ready(function(){
    watermark({watermark_txt0:'泽民博客',watermark_txt1:'zemin',watermark_txt2:(new Date()).Format("yyyy-MM-dd hh:mm:ss.S")});
    })
    </script>
     <!--水印-->
     <!--adscene-->
    <script data-ad-client="ca-pub-6672721494777557" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

</head>

 <body>
<div id="wrapper">
 <!-- Navigation -->
    <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="/MyBlog">
                        Home
                    </a>
                </li>
                <li>
                    <a href="#">About</a>
                </li>
                <li>
                    <a href="#">Services</a>
                </li>
                <li>
                    <a href="#">Portfolio</a>
                </li>
                <li>
                    <a href="#">Events</a>
                </li>
                <li>
                    <a href="#">Blog</a>
                </li>
                <li>
                    <a href="#">FAQ</a>
                </li>
                <li>
                    <a href="#">Contact</a>
                </li>
            </ul>
        </div>


    <header class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="heading text-center">
                        <a href="https://xiazemin.github.io/MyBlog/" style="color: #fff; font-size: 4em; font-family: 'Schoolbell', cursive;">泽民博客</a>
                        <a href="#menu-toggle" class="btn btn-default sciblog" id="menu-toggle" style="font-weight: bold;">&#9776; Menu</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

     <script async src="/MyBlog/js/busuanzi.pure.mini.js"></script>

    <script type="text/javascript" src="/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="/MyBlog/js/jquery.stripesrotator.js"></script>


 <div class="container">
	<div class="row">
        <div class="box">
                <div class="col-lg-12">
                    <div class="intro-text text-center">
					<h1 class="post-title" itemprop="name headline">antlr hive</h1>
					<p class="post-meta"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">by 夏泽民</span></span> <time datetime="2020-07-10T00:00:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Jul 10, 2020</time></p>
					</div>
					 <p>hive是使用antlr来解析的</p><br />
<br />
<p>parser要做的事情，是从无结构的字符串里面，解码产生有结构的数据结构（a parser is a function accepting strings as input and returning some structure as output），参考 Parser_combinator wiki</p><br />
<br />
<p>parser分成两种，一种是parser combinator，一种是parser generator</p><br />
<br />
<p>parser combinator是需要手写parser，a parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output</p><br />
<br />
<p>parser generator是需要你用某种指定的描述语言来表示出语法，然后自动把他们转换成parser的代码，比如Antlr里面的g4语法文件，以及calcite的ftl语法文件，缺点是由于代码是生成的，排错比较困难</p><br />
<br />
<p>使用了Antlr的parser有Hive，Presto，Spark SQL</p><br />
<br />
<p>美团点评的文章</p><br />
<br />
<p>1<br />
https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html<br />
以及hive源码的测试用例</p><br />
<br />
<p>1<br />
https://github.com/apache/hive/blob/branch-1.1/ql/src/test/org/apache/hadoop/hive/ql/parse/TestHiveDecimalParse.java<br />
hive的g4文件如下</p><br />
<br />
<p>老版本的hive</p><br />
<br />
<p>1<br />
https://github.com/apache/hive/blob/59d8665cba4fe126df026f334d35e5b9885fc42c/parser/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g<br />
新版本的hive</p><br />
<br />
<p>1<br />
https://github.com/apache/hive/blob/master/hplsql/src/main/antlr4/org/apache/hive/hplsql/Hplsql.g4<br />
spark的g4文件如下</p><br />
<br />
<p>1<br />
https://github.com/apache/spark/blob/master/sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4<br />
Presto的g4文件如下</p><br />
<br />
<p>1<br />
https://github.com/prestodb/presto/blob/master/presto-parser/src/main/antlr4/com/facebook/presto/sql/parser/SqlBase.g4<br />
使用了Apache Calcite的parser有Apache Flink，Mybatis，Apache Storm等</p><br />
<br />
<p>https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html</p><br />
<br />
<p>https://www.cnblogs.com/tonglin0325/p/12212866.html</p><br />
<br />
<p>https://www.yinwang.org/blog-cn/2015/09/19/parser<br />
<!-- more --><br />
用python+antlr解析hive sql获得数据血缘关系（一）<br />
系列目标<br />
编程获得数据血缘关系的需求对数据仓库来说并不普遍，只有数据规模达到很大的程度，或者存在复杂数据生产关系的报表数量增加到很大的程度，单独的数据血缘关系工作才有必要。<br />
在规模没达到之前，人工的识别和管理是更经济有效的。</p><br />
<br />
<p>本系列想要做到的目标是这个uber的 queryparser的一个子集，在有限知道目标数据表结构的前提下，发现并记录目标字段与来源表和字段的关系。</p><br />
<br />
<p>这种功能queryparser应该是已经具备的，并且它本身是开源的，但queryparser的主体是Haskell写的，为这么一个边缘功能学门新的编程范式，学习代价太大了点。</p><br />
<br />
<p>还是选择python作为开发工具比较靠谱。</p><br />
<br />
<p>可选项比较<br />
自己从头写字符串处理是不可能的，就算是用正则辅助，搞那些语法边角的工作量也难以估计。</p><br />
<br />
<p>于是祭出搜索大法，在各处寻摸一遍后，拿到了这么几个可能的选择项：</p><br />
<br />
<p>queryparser<br />
就是前面说的uber放出的开源项目，因为编程语言的壁垒，最早放弃。</p><br />
<br />
<p>sqlparse<br />
pypi上可以搜索到的模块，github地址https://github.com/andialbrecht/sqlparse<br />
网上也有一些材料，</p><br />
<br />
<p>拿来做了简单试验后，放弃。</p><br />
<br />
<p>放弃主要原因是因为它的功能集合相比要做的hive sql解析，感觉太小了。sqlparse从sql语句解析出来的是 statements tuple，每个statement上会有一个识别出的类型，而在我要解析的sql集合里，大概有三分之一sql语句，识别出的statement类型是UNKNOWN，这个比例太大不能接受。</p><br />
<br />
<p>pyparsing<br />
也是pypi上可以搜索到的模块，github地址https://github.com/pyparsing/pyparsing/ 这是python版本的通用解析工具。</p><br />
<br />
<p>如果有人基于这个pyparsing做过hive sql解析就好了，然而没有。如果要用pyparsing，就要从头写语法文件。python项目用它做表达式解析，或者做新配置语法还好，用来解析hive sql这种量级的，工作量也太大，放弃。</p><br />
<br />
<p>antlr<br />
在找到pyparsing时我已经同时在找antlr相关信息了，因为要解析hive sql，最权威的解析器肯定是hive自己用的那个，经过确认，这个工具就是antlr，更具体的说，是antlr 3系列。</p><br />
<br />
<p>antlr自己的历史不是本系列重点，感兴趣的可以自行到https://www.antlr.org/上去查阅</p><br />
<br />
<p>grammar文件<br />
要用hive自身的解析，就要拿到hive的语法文件定义，对于开源的hive来说，这个事还是挺容易的，github上可以很容易按版本访问到历史文件，以hive 1.1.0版本的文件为例，语法文件定义所在的文件夹是<br />
https://github.com/apache/hive/tree/release-1.1.0/ql/src/java/org/apache/hadoop/hive/ql/parse</p><br />
<br />
<p>网上也提到过，hive的语法文件经历过分拆，在1.1.0版本中，一共有5个文件，都是.g后缀名，分别是</p><br />
<br />
<p>FromClauseParser.g<br />
HiveLexer.g<br />
HiveParser.g<br />
IdentifiersParser.g<br />
SelectClauseParser.g<br />
把它们从github上下载回来，或者从页面上复制粘贴到编辑器里，再保存为对应名字的文本文件也可以，主要文件名要严格一样，antlr对文件名和语法文件内容有检查。</p><br />
<br />
<p>antlr版本<br />
antlr有 v2 v3 v4多个版本并存，中文文档多数是v2的， hive 1.1.0版本在注释中提到了antlr 3.4，最新的3.x版本是3.5.2，我选择用3.4版本的。</p><br />
<br />
<p>antlr自己发布的下载地址是在github 上的 ，能下载，但由于美帝的”封锁”，下载速度很难保证，<br />
这是另外一个能下载antlr的网站</p><br />
<br />
<p>java版本<br />
antlr的运行需要jdk版本的java，具体是jdk里面的javac来编译代码，具体支持的最低版本我没确认。</p><br />
<br />
<p>如果环境里没有javac，需要自行安装，在centos下可以这样安装jdk8</p><br />
<br />
<h1 id="yum-install--y-java-180-openjdk-devel">yum install -y java-1.8.0-openjdk-devel</h1><br />
<p>1<br />
pyjnius<br />
antlr这个工具，可以产出多种target语言，这其中也包括了python，不过查阅列表后发现，对python target的有效性验证只持续到antlr 3.1.3 ，到antlr 3.4 版本就很难讲了。继续一番搜索<br />
大法，决定使用pyjnius作为python到java之间的桥梁。</p><br />
<br />
<p>桥接python和java的方案,更具体来说，是在python里调用java代码的方案，其实也有好几个，</p><br />
<br />
<p>pyjnius<br />
Jpype<br />
javabridge<br />
py4j<br />
jcc<br />
其他的方案其实我都还没试，pyjnius的尝试几乎是一次通过，就优先选这个了</p><br />
<br />
<p>安装<br />
通过pip安装，过程很顺利<br />
如果网速慢，推荐使用清华的镜像</p><br />
<br />
<p>pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pyjnius<br />
1<br />
如果之前没有装过cython，会连带需要安装这个依赖。<br />
安装cython可能要连带安装gcc</p><br />
<br />
<p>yum install gcc gcc-++<br />
pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple cython<br />
1<br />
2<br />
编译grammar<br />
前面下载的5个hive grammar文件，最好集中保存到一个目录下，推荐命名为带层次的 grammar/hive110， 原因是grammar文件经过antlr解析后会生成对应的java源代码，然后要再编译为class文件，而java在搜索类时会根据package名和路径名做匹配，一开始就做下目录规划，可以节省后续扩展调整的功夫。</p><br />
<br />
<p>修订 HiveLexer.g<br />
在编译前，要修改一下HiveLexer.g文件，否则会因为找不到hive的相关文件报错</p><br />
<br />
<p>/**<br />
注释掉下面这两段<br />
@lexer::header {<br />
package org.apache.hadoop.hive.ql.parse;</p><br />
<br />
<p>import org.apache.hadoop.conf.Configuration;<br />
import org.apache.hadoop.hive.conf.HiveConf;<br />
}</p><br />
<br />
<p>@lexer::members {<br />
  private Configuration hiveConf;</p><br />
<br />
<p>public void setHiveConf(Configuration hiveConf) {<br />
    this.hiveConf = hiveConf;<br />
  }</p><br />
<br />
<p>protected boolean allowQuotedId() {<br />
    String supportedQIds = HiveConf.getVar(hiveConf, HiveConf.ConfVars.HIVE_QUOTEDID_SUPPORT);<br />
    return !”none”.equals(supportedQIds);<br />
  }<br />
}<br />
增加下面这段<br />
<em>/<br />
@lexer::header {<br />
package grammar.hive110;<br />
}<br />
/</em><br />
中间部分省略<br />
下面这行要修改<br />
    | {allowQuotedId()}? QuotedIdentifier<br />
*/<br />
    | {true}? QuotedIdentifier</p><br />
<br />
<p>@lexer::header和@lexer::member都是会被antlr添加到目标文件里的内容，注释掉的部分是对hive里其他部分的引用，因为我只需要lexer和parser，其他部分就不要了。<br />
注释掉的内容里有一个allowQuotedId()的方法，语法文件里有对它的调用，也要一起修改掉。</p><br />
<br />
<p>编译HiveLexer.g成.java文件<br />
需要有下载好的antlr的jar文件，我把它放到和.g文件同一目录下，执行</p><br />
<br />
<p>$ java -jar antlr-3.4-complete.jar HiveLexer.g<br />
1<br />
顺利的话，应该没有报错信息，并且生成HiveLexer.tokens和HiveLexer.java文件。</p><br />
<br />
<p>这个HiveLexer.java，就是antlr自动生成的，可以处理hive sql词法规则的源代码。</p><br />
<br />
<p>词法规则只校验”sql应该怎么写”，处理这部分工作的程序一般叫lexer<br />
还有另外一半”sql应该怎么执行”的工作，一般由叫parser的程序做，也就是前面的HiveParser.g</p><br />
<br />
<p>编译.java文件到.class文件<br />
下一步是把生成的java源代码编译成.class的字节码</p><br />
<br />
<p>$ javac -cp antlr-3.4-complete.jar HiveLexer.java<br />
1<br />
顺利的话，也应该没有报错信息，并且生成HiveLexer.java文件，可能还会同时生成 HiveLexerDFA25.class,HiveLexerDFA25.class, HiveLexerDFA25.class,HiveLexerDFA21.class 这样的文件。</p><br />
<br />
<p>编写测试代码<br />
从pyjnius和antlr的示例代码两个各取一部分，移花接木一番，得到的简单测试代码如下,</p><br />
<br />
<p>保存为antlrtest.py</p><br />
<br />
<p>#antlrtest.py<br />
import jnius_config<br />
jnius_config.set_classpath(‘./’,’./grammar/hive110/antlr-3.4-complete.jar’)<br />
import jnius<br />
StringStream = jnius.autoclass(‘org.antlr.runtime.ANTLRStringStream’)<br />
Lexer  = jnius.autoclass(‘grammar.hive110.HiveLexer’)<br />
TokenStream  = jnius.autoclass(‘org.antlr.runtime.CommonTokenStream’)</p><br />
<br />
<p>cstream = StringStream(“select * from new_table;”)<br />
inst = Lexer(cstream)<br />
ts = TokenStream()<br />
ts.setTokenSource(inst)<br />
ts.fill()</p><br />
<br />
<p>jlist = ts.getTokens()<br />
tsize = jlist.size()<br />
for i in range(tsize):<br />
    print(jlist.get(i).getText())</p><br />
<br />
<p>确认目录结构<br />
上面的代码是经过多次调试才得到的，一次运行可能不成功。最有可能的是目录结构不对。能成功运行的目录结构是这样的</p><br />
<br />
<p>antlrtest.py<br />
grammar/<br />
└── hive110<br />
    ├── antlr-3.4-complete.jar<br />
    ├── FromClauseParser.g<br />
    ├── HiveLexer.class<br />
    ├── HiveLexer$DFA21.class<br />
    ├── HiveLexer$DFA25.class<br />
    ├── HiveLexer.g<br />
    ├── HiveLexer.java<br />
    ├── HiveLexer.tokens<br />
    ├── HiveParser.g<br />
    ├── IdentifiersParser.g<br />
    ├── SelectClauseParser.g</p><br />
<br />
<p>运行结果和代码简介<br />
antlrtest.py的输出应该是下面这样的多行文本，每行是被HiveLexer这个类识别出的一个Token</p><br />
<br />
<p>select</p><br />
<br />
<p>*</p><br />
<br />
<p>from</p><br />
<br />
<p>new_table<br />
;</p><br />
<EOF><br />
<br />
用注释解释代码用途<br />
<br />
#antlrtest.py<br />
import jnius_config<br />
#这里是设置java的classpath，必须在import jnius之前做，设置后进程内不能修改了<br />
jnius_config.set_classpath('./','./grammar/hive110/antlr-3.4-complete.jar')<br />
import jnius<br />
#这3个是利用autoclass的自动装载，把java里的类定义反射到python里<br />
#StringStream对应的是是HiveLexer构造函数必须的输入参数类型之一，ANTLRStringStream<br />
StringStream = jnius.autoclass('org.antlr.runtime.ANTLRStringStream')<br />
#注意这里的类名，和前面.g文件里定义的package名要有对应，和HiveLexer.class所在的目录也要有对应<br />
Lexer  = jnius.autoclass('grammar.hive110.HiveLexer')<br />
#TokenStream是要取出token时，保存token的容器类型CommonTokenStream<br />
TokenStream  = jnius.autoclass('org.antlr.runtime.CommonTokenStream')<br />
<br />
cstream = StringStream("select * from new_table;")<br />
inst = Lexer(cstream)<br />
ts = TokenStream()<br />
# antlr 3增加的步骤，Lexer和Parser之间用CommonTokenStream为接口<br />
ts.setTokenSource(inst)<br />
#调用fill来消费掉cstream里的所有token<br />
ts.fill()<br />
<br />
# jlist不能直接在python里迭代，<br />
jlist = ts.getTokens()<br />
tsize = jlist.size()<br />
for i in range(tsize):<br />
    print(jlist.get(i).getText())<br />
    <br />
 https://blog.csdn.net/bigdataolddriver/article/details/103826702<br />
 <br />
 https://eng.uber.com/queryparser/<br />
 <br />
 https://github.com/uber/queryparser<br />
 <br />
 https://github.com/andialbrecht/sqlparse<br />
 <br />
 https://github.com/pyparsing/pyparsing/<br />
 <br />
 SQL转化为MapReduce的过程<br />
了解了MapReduce实现SQL基本操作之后，我们来看看Hive是如何将SQL转化为MapReduce任务的，整个编译过程分为六个阶段：<br />
<br />
Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树AST Tree<br />
遍历AST Tree，抽象出查询的基本组成单元QueryBlock<br />
遍历QueryBlock，翻译为执行操作树OperatorTree<br />
逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量<br />
遍历OperatorTree，翻译为MapReduce任务<br />
物理层优化器进行MapReduce任务的变换，生成最终的执行计划<br />
<br />
https://www.cnblogs.com/yaojingang/p/5446310.html<br />
<br />
https://blog.csdn.net/fover717/article/details/69367545<br />
https://www.it610.com/article/4610072.htm<br />
https://www.jianshu.com/p/1a09ead6df21<br />
<br />
http://ixiaosi.art/2019/01/28/hive/hive-sql%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/<br />
<br />
https://code-examples.net/zh-CN/keyword/122735<br />
<br />
https://www.xuebuyuan.com/2181078.html<br />
http://www.itkeyword.com/doc/2100804199580563x913<br />
https://www.icode9.com/content-2-615877.html<br />
<br />
https://www.cnblogs.com/drawwindows/p/4584326.html<br />
https://blog.csdn.net/bigdataolddriver/article/details/103867682<br />
https://blog.csdn.net/bigdataolddriver/article/details/104000719<br />
<br />
ANTLR是一款强大的语法分析器生成工具，可用于读取、处理、执行和翻译结构化的文本或二进制文件。它被广泛应用于学术领域和工业生产实践，是众多语言、工具和框架的基石。Twitter搜索使用ANTLR进行语法分析，每天处理超过20亿次查询；Hadoop生态系统中的Hive、Pig、数据仓库和分析系统所使用的语言都用到了ANTLR；Lex Machina将ANTLR用于分析法律文本；Oracle公司在SQL开发者IDE和迁移工具中使用了ANTLR；NetBeans公司的IDE使用ANTLR来解析C++；Hibernate对象-关系映射框架（ORM）使用ANTLR来处理HQL语言。<br />
<br />
除了这些鼎鼎大名的项目之外，还可以利用ANTLR构建各种各样的实用工具，如配置文件读取器、遗留代码转换器、维基文本渲染器，以及JSON解析器。我编写了一些工具，用于创建数据库的对象-关系映射、描述三维可视化以及在Java源代码中插入性能监控代码。我甚至为一次演讲编写了一个简单的DNA模式匹配程序。<br />
<br />
一门语言的正式描述称为语法（grammar），ANTLR能够为该语言生成一个语法分析器，并自动建立语法分析树——一种描述语法与输入文本匹配关系的数据结构。ANTLR也能够自动生成树的遍历器，这样你就可以访问树中的节点，执行自定义的业务逻辑代码。<br />
<br />
本书既是ANTLR 4的参考手册，也是解决语言识别问题的指南。你会学到如下知识：<br />
<br />
识别语言样例和参考手册中的语法模式，从而编写自定义的语法。<br />
<br />
循序渐进地为从简单的JSON到复杂的R语言编写语法。同时还能学会解决XML和Python中棘手的识别问题。<br />
<br />
基于语法，通过遍历自动生成的语法分析树，实现自己的语言类应用程序。<br />
<br />
在特定的应用领域中，自定义识别过程的错误处理机制和错误报告机制。<br />
<br />
通过在语法中嵌入Java动作（action），对语法分析过程进行完全的掌控。<br />
<br />
本书并非教科书，所有的讨论都是基于实例的，旨在令你巩固所学的知识，并提供语言类应用程序的基本范例。<br />
<br />
https://www.jb51.net/books/634176.html<br />
</EOF><br />

					 <span class='st_sharethis_large' displayText='ShareThis'></span>
						<span class='st_facebook_large' displayText='Facebook'></span>
						<span class='st_twitter_large' displayText='Tweet'></span>
						<span class='st_linkedin_large' displayText='LinkedIn'></span>
						<span class='st_pinterest_large' displayText='Pinterest'></span>
						<span class='st_email_large' displayText='Email'></span>
                </div>
                Category lang
        </div>
	</div>
  
  
       <!--赞-->
    	  <div class="row">
            <div class="col-lg-6">
                <img src="https://xiazemin.github.io/MyBlog/img/webwxgetmsgimg.jpeg"  height="400" width="auto" />
            </div>
          </div>

        <div class="row">
                <div class="col-md-12">
			<div id="disqus_thread"></div>

<div id="gitmentContainer"></div>
<link rel="stylesheet" href="/MyBlog/css/default.css">
<script src="/MyBlog/js/gitment.browser.js"></script>
<script type="text/javascript" src="/MyBlog/js/json2.js"></script>
<script>
var gitment = new Gitment({
    owner: 'xiazemin',
    repo: 'MyBlogComment',
    oauth: {
        client_id: '981ba8c916c262631ea0',
        client_secret: 'a52260ef92de69011ccd1cf355b973ef11d6da0e',
    },
});

var MyGitmentContainer=gitment.render('gitmentContainer');
window.setTimeout(MyGitMentBtnclick,1000); 
//document.ready(function(){ 
//window.onload=function(){}

function MyGitMentBtnclick(){
//var MyGitmentContainer=document.getElementById('gitmentContainer');
	var ele=[],all=MyGitmentContainer.getElementsByTagName("*");
	for(var i=0;i<all.length;i++){
	  if(all[i].className=='gitment-comments-init-btn'){
		MyGitMentBtn=all[i];
		console.log(MyGitMentBtn);
		MyGitMentBtn.click();
	  }
	}
}

</script>



			<!--script>
			/**
			* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
			* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
			*/
			/*
			var disqus_config = function () {
			this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
			this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
			};
			*/
			(function() { // DON'T EDIT BELOW THIS LINE
			var d = document, s = d.createElement('script');

			s.src = '//airrayagroup.disqus.com/embed.js';

			s.setAttribute('data-timestamp', +new Date());
			(d.head || d.body).appendChild(s);
			})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			<script id="dsq-count-scr" src="//airrayagroup.disqus.com/count.js" async></script-->
          </div>
       </div>

</div>
<hr>
     <footer>
        <div class="container">
             <a href="/MyBlog/" style="color: green; font-size: 2em; font-family: 'Schoolbell', cursive;">首页</a>
            <div class="row">
                <div class="col-lg-6">
                    <p>Copyright &copy; 2017 465474307@qq.com <p>
                </div>
                <div class="col-lg-6">
                    <p style="float: right;">Jekyll theme by <a href="https://github.com/xiazemin/">夏泽民</a></p>
                </div>
            </div>
        </div>
    </footer>
	
    <!-- jQuery -->
    <script src="/MyBlog/js/jquery-1.12.0.min.js"></script>
    <script src="/MyBlog/js/jquery-migrate-1.2.1.min.js"></script>

    <!-- Latest compiled and minified JavaScript -->
    <script src="/MyBlog/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
        <!-- Menu Toggle Script -->
    <script>
    $("#menu-toggle").click(function(e) {
        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
    </script>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"6","bdPos":"right","bdTop":"100"},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/MyBlog/shareapi/js/share.js?v=89860593.js?'];</script>


<!-- 2d  -->
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.0.min.js"></script>
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.min.js"></script>
<script type="text/javascript">
 setTimeout(()=> {
/*L2Dwidget.init({"display": {
        "superSample": 2,
        "width": 200,
        "height": 400,
             "position": "right",
                 "hOffset": 0,
        "vOffset": 0
          }
     });
*/
 L2Dwidget
        .on('*', (name) => {
          console.log('%c EVENT ' + '%c -> ' + name, 'background: #222; color: yellow', 'background: #fff; color: #000')
        })
        .init({
          dialog: {
            // 开启对话框
            enable: true,
            script: {
              // 每空闲 10 秒钟，显示一条一言
              'every idle 10s': '$hitokoto$',
              // 当触摸到星星图案
              'hover .star': '星星在天上而你在我心里 (*/ω＼*)',
              // 当触摸到角色身体
              'tap body': '哎呀！别碰我！',
              // 当触摸到角色头部
              'tap face': '人家已经不是小孩子了！'
            }
          }
        });

})
</script>



    <!--html xmlns:wb="http://open.weibo.com/wb">
    <script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
    <wb:follow-button uid="2165491993" type="red_1" width="67" height="24" ></wb:follow-button-->

      <!--本文来自-->
     <script type="text/javascript">
      /* 仅IE
     document.body.oncopy = function(){
        setTimeout( 
            function () { 
        var text =window.clipboardData.getData("text"); 
        if (text) { 
            text = text + "/r/n本篇文章来源于 xiazemin 的 泽民博客|https://xiazemin.github.io/MyBlog/index.html 原文链接："+location.href; clipboardData.setData("text", text); 
          }
       },
     100 )
    }
     */
     //绑定在了body上，也可以绑定在其他可用元素行，但是不是所有元素都支持copy和past事件。

     /*
$(document.body).bind({
    copy: function(event) {//copy事件
        //var cpTxt = "复制的数据";
        var clipboardData = window.clipboardData; //for IE
        if (!clipboardData) { // for chrome
            clipboardData = event.originalEvent.clipboardData;
        }

        if (event.clipboardData != null/false/undefined) { //ignore the incorrectness of the truncation
        clipboarddata = event.clipboardData;
        } else if (window.clipboardData != null/false/undefined) {
         clipboarddata = window.clipboardData;
        } else { //default to the last option even if it is null/false/undefined
         clipboarddata = event.originalEvent.clipboardData;
        }

        //e.clipboardData.getData('text');//可以获取用户选中复制的数据
        //clipboardData.setData('Text', cpTxt);
        alert(clipboarddata.getData('text'));
        //$('#message').text('Copy Data : ' + cpTxt);
        return false;//否则设不生效
    },paste: function(e) {//paste事件
        var eve = e.originalEvent
        var cp = eve.clipboardData;
        var data = null;
        var clipboardData = window.clipboardData; // IE
        if (!clipboardData) { //chrome
            clipboardData = e.originalEvent.clipboardData
        }
        data = clipboardData.getData('Text');
        //$('#message').html(data);
    }
});     
*/
function addLink() {
    var body_element = document.getElementsByTagName('body')[0];
    var selection;
    selection = window.getSelection();
    var pagelink = "<br /><br />本文来源：xiazemin 的 泽民博客 <a href='"+document.location.href+"'>"+document.location.href+"</a>";
//+document.location.href+当前页面链接
    var copy_text = selection + pagelink;
    console.log(copy_text);
    var new_div = document.createElement('div');
    new_div.style.left='-99999px';
    new_div.style.position='absolute';
    body_element.appendChild(new_div );
    new_div.innerHTML = copy_text ;
    selection.selectAllChildren(new_div );
    window.setTimeout(function() {
        body_element.removeChild(new_div );
    },0);
}
document.oncopy = addLink;
     </script>
    <!--本文来自-->

</div>
  </body>

</html>