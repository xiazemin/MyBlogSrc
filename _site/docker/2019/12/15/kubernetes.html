<!DOCTYPE html>
<html>

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Sci blog jekyll theme">
    <meta name="author" content="AIR RAYA Group">
    <link href='/MyBlog/img/favicon.ico' type='image/icon' rel='shortcut icon'/>

    <title>泽民博客 | Jekyll theme</title>

    <link rel="stylesheet" href="/MyBlog/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="/MyBlog/css/font-awesome.min.css">
    <link href="/MyBlog/css/simple-sidebar.css" rel="stylesheet">
	<link href="/MyBlog/css/classic-10_7.css" rel="stylesheet" type="text/css">
    <!-- Custom CSS -->
    <link href="/MyBlog/css/style.css" rel="stylesheet">
    <link href="/MyBlog/css/pygments.css" rel="stylesheet">
    <!-- Fonts -->
 <link href="/MyBlog/css/front.css" rel="stylesheet" type="text/css">
 <link href="/MyBlog/css/Josefin_Slab.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Architects_Daughter.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Schoolbell.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Codystar.css" rel="stylesheet" type="text/css">

 <script type="text/javascript" src="/MyBlog/js/jquery-1.12.0.min.js"></script>	

<link href="/MyBlog/css/calendar/common.css" type="text/css"  rel="stylesheet">
<script type="text/javascript" src="/MyBlog/js/calendar/calendar.js"></script>
	<!-- share this -->
	<script type="text/javascript">var switchTo5x=true;</script>
	<script type="text/javascript" src="/MyBlog/js/buttons.js"></script>
	<script type="text/javascript">stLight.options({publisher: "b28464c3-d287-4257-ad18-058346dd35f7", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="/MyBlog/js/html5shiv.js"></script>
        <script src="/MyBlog/js/respond.min.js"></script>
    <![endif]-->
   
   <!--百度统计-->
    <script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e965cab8c73512b8b23939e7051d93bd";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <script async src="/MyBlog/katex/katex.js"></script>
    <link rel="stylesheet" href="/MyBlog/katex/katex.css">

    <!--轮播图片-->
    <!--script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.stripesrotator.js"></script>
    <script type="text/javascript">
                    $(document).ready(function() {
                    alert($('#rotator_xzm'));
                     alert($('#rotator_xzm').fn);
                    $('#rotator_xzm').stripesRotator({ images: [ "https://xiazemin.github.io/MyBlog/img/BPlusTree.png", "https://xiazemin.github.io/MyBlog/img/linuxMMap.jpeg"] });
                    });
    </script-->

    <!--水印-->
    <script type="text/javascript" src="/MyBlog/js/waterMark.js"></script>
    <script type="text/javascript">
    $(document).ready(function(){
    watermark({watermark_txt0:'泽民博客',watermark_txt1:'zemin',watermark_txt2:(new Date()).Format("yyyy-MM-dd hh:mm:ss.S")});
    })
    </script>
     <!--水印-->
     <!--adscene-->
    <script data-ad-client="ca-pub-6672721494777557" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

</head>

 <body>
<div id="wrapper">
 <!-- Navigation -->
    <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="/MyBlog">
                        Home
                    </a>
                </li>
                <li>
                    <a href="#">About</a>
                </li>
                <li>
                    <a href="#">Services</a>
                </li>
                <li>
                    <a href="#">Portfolio</a>
                </li>
                <li>
                    <a href="#">Events</a>
                </li>
                <li>
                    <a href="#">Blog</a>
                </li>
                <li>
                    <a href="#">FAQ</a>
                </li>
                <li>
                    <a href="#">Contact</a>
                </li>
            </ul>
        </div>


    <header class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="heading text-center">
                        <a href="https://xiazemin.github.io/MyBlog/" style="color: #fff; font-size: 4em; font-family: 'Schoolbell', cursive;">泽民博客</a>
                        <a href="#menu-toggle" class="btn btn-default sciblog" id="menu-toggle" style="font-weight: bold;">&#9776; Menu</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

     <script async src="/MyBlog/js/busuanzi.pure.mini.js"></script>

    <script type="text/javascript" src="/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="/MyBlog/js/jquery.stripesrotator.js"></script>


 <div class="container">
	<div class="row">
        <div class="box">
                <div class="col-lg-12">
                    <div class="intro-text text-center">
					<h1 class="post-title" itemprop="name headline">kubernetes 网络</h1>
					<p class="post-meta"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">by 夏泽民</span></span> <time datetime="2019-12-15T00:00:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Dec 15, 2019</time></p>
					</div>
					 <p>K8S 底层网络所需要解决的两个问题</p><br />
<br />
<p>协助 k8s , 给每个 NODE上的 docker 容器都分配互相不冲突的 IP<br />
在这些 IP 地址之间建立一个覆盖网络(overlay Network), 通过这个覆盖网络, 将数据包原封不动地传递到目标容器内.<br />
<!-- more --><br />
Open vSwitch<br />
Open vSwitch 可以建立多钟通信隧道, 例如Open vswitch with GRE/VXALN. 在K8S 场景下, 我们主要建立 L3 到 L3 的隧道.</p><br />
<br />
<p>需要完成的步骤如下:</p><br />
<br />
<p>删除docker daemon 创建的网桥 docker0 已避免 docker0地址冲突.</p><br />
<br />
<p>手工创建一个linux网桥, 手动配置网桥的 IP</p><br />
<br />
<p>建立 Open vswitch 网桥 ovs-bridge, 使用 ovs-vsctl 给ovs-bridge 添加gre端口, 在添加端口是, 需要将目标 NODE 的 IP 地址设置为对端 IP 地址. 每个对端 IP 地址都需要这么操作.</p><br />
<br />
<p>将 ovs-bridge 作为网络接口, 加入docker 的网桥上(docker0 或自己手工创建的网桥)</p><br />
<br />
<p>重启 ovs-bridge 网桥 和 docker 的网桥, 并添加一个docker 的网段到docker 网桥的路由规则中</p><br />
<br />
<p>网络通信过程<br />
当容器内的应用访问另一个容器地址时, 数据包会通过容器内的默认路由发送给docker0网桥, ovs的网桥是作为docker0 网桥的端口存在的, 它会将数据发送给ovs 网桥, ovs 通过gre隧道 送达对端的node.<br />
配置步骤<br />
在两个节点都安装ovs<br />
安装ovs<br />
yum install openvswitch<br />
复制代码禁用selinux 并重启<br />
#vi /etc/selinux/conifg<br />
SELINUX=disabled<br />
复制代码查看ovs状态<br />
systemctl status openvswtich<br />
复制代码创建网桥和 gre 隧道<br />
在每个node上创建ovs 网桥 br0 然后在网桥上创建 gre 隧道<br />
#创建ovs网桥<br />
ovs-vsctl add-br br0</p><br />
<h1 id="创建-gre-隧道连接对端-remote_ip-为对端-eth0-的-ip-注意在另一台机器上设置对端的时候ip-要改为当前这台机器的-ip">创建 GRE 隧道连接对端, remote_ip 为对端 eth0 的 IP, 注意在另一台机器上设置对端的时候,IP 要改为当前这台机器的 IP</h1><br />
<p>ovs-vsctl add-port br0 gre1 – set interface gre1 type gre option:remote_ip=192.168.18.128</p><br />
<h1 id="添加br0-到本地-docker0-网桥-使得容器流量通过-ovs-进入-tunnel">添加br0 到本地 docker0 网桥, 使得容器流量通过 ovs 进入 tunnel</h1><br />
<p>brctl addif docker0 br0<br />
#启动br0 docker0 网桥<br />
ip link set dev br0 up<br />
ip link set dev docker0 up<br />
复制代码由于128, 131 ip的两台机器docker0 网段分别是172.17.43.0/24, 172.17.42.0/24, 这两个网段的路由都需要经过本机docker0网桥.其中一个24网段通过ovs的gre 隧道到达对端. 因此需要在每个node上配置通过docker0 网桥的路由规则<br />
ip route add 172.17.0.0/16 dev docker0<br />
复制代码清空 docker 自带的iptables 规则及linux 的规则, 后者存在拒绝ICMP 保温通过防火墙的规则<br />
iptables -t nat -F; iptalbes -F<br />
复制代码直接路由<br />
网络模型<br />
在默认情况下docker0 的IP 在node 网络是没法感知到的, 通过手工设置路由, 可以让pod 在不同node 之间互通.<br />
实现方式<br />
通过部署multilayer switch (MLS) 来实现<br />
假设 POD1 所在的 docker0 网桥的 IP 网段是 10.1.10.0 , NODE1 地址为 192. 168.1.128; 而 POD2 所在 docker0 ip 网段为 10.1.20.0 NODE2 地址为 192.168.1.129<br />
1 在NODE 1 上添加一条到node2 上 docker0 的静态路由规则<br />
route add -net 10.1.20.0 netmask 255.255.255.0 gw 192.168.1.129<br />
复制代码2 在 NODE 2 上添加一条到 NODE 1 上 docker0 的静态路由规则<br />
route add -net 10.1.10.0 netmask 255.255.255.0 gw 192.168.1.128<br />
复制代码3 验证连通性, 在 NODE1 上 ping node2 上的 docker0 网络<br />
ping 10.1.20.1<br />
复制代码大规模集群下的实现方式, 手工建立 linux bridge 已避免 docker daemon 建立docker0 造成 IP 段冲突, 然后使用docker 的–bridge 命令来指定网桥.<br />
然后在每个节点运行quagga 路由学习软件.<br />
calico<br />
Calico 工作方式<br />
Calico可以创建并管理一个3层平面网络，为每个工作负载分配一个完全可路由的IP地址。 工作负载可以在没有IP封装或网络地址转换的情况下进行通信，以实现裸机性能，简化故障排除和提供更好的互操作性。 在需要使用overlay网络的环境中，Calico提供了IP-in-IP隧道技术，或者也可以与flannel等其他overlay网络配合使用。<br />
Calico还提供网络安全规则的动态配置。 使用Calico的简单策略语言，就可以实现对容器、虚拟机工作负载和裸机主机各节点之间通信的细粒度控制。<br />
Calico v3.4于2018.12.10号发布，可与Kubernetes、OpenShift和OpenStack良好地集成使用。</p><br />
<br />
<p>注意: 在Mesos, DC/OS和Docker orchestrators中使用Calico时，目前只支持到了 Calico v2.6.</p><br />
<br />
<p>Calico的IPIP与BGP模式</p><br />
<br />
<p>IPIP是一种将各Node的路由之间做一个tunnel，再把两个网络连接起来的模式。启用IPIP模式时，Calico将在各Node上创建一个名为”tunl0″的虚拟网络接口。如下图所示。<br />
BGP模式则直接使用物理机作为虚拟路由路（vRouter），不再创建额外的tunnel</p><br />
<br />
<p>calico  在linux 内核中实现一个vRouter来负责数据转发, 通过 BGP 协议,将node 节点上的路由信息在整个calico 网络中广播, 并自动设置到达其他节点的路由转发规则.</p><br />
<br />
<p>Calico BGP模式在小规模集群中可以直接互联，在大规模集群中可以通过额外的BGP route reflector来完成。<br />
Calico主要组件<br />
Calico利用了Linux内核原生的路由和iptables防火墙功能。 进出各个容器、虚拟机和物理主机的所有流量都会在路由到目标之前遍历这些内核规则。</p><br />
<br />
<p>Felix：主要的Calico代理agent，运行每台计算机上管理endpoints资源。<br />
calicoctl：允许从命令行界面配置实现高级策略和网络。<br />
orchestrator plugins：提供与各种流行的云计算编排工具的紧密集成和同步支持。<br />
key/value store：存储Calico的策略配置和网络状态信息，目前主要使用etcdv3或k8s api。<br />
calico/node：在每个主机上运行，从key/value存储中读取相关的策略和网络配置信息，并在Linux内核中实现它。<br />
Dikastes/Envoy：可选的Kubernetes sidecars，可以通过相互TLS身份验证保护工作负载到工作负载的通信，并增加应用层控制策略。</p><br />
<br />
<p>Felix<br />
Felix是一个守护程序，它在每个提供endpoints资源的计算机上运行。在大多数情况下，这意味着它需要在托管容器或VM的宿主机节点上运行。 Felix 负责编制路由和ACL规则以及在该主机上所需的任何其他内容，以便为该主机上的endpoints资源正常运行提供所需的网络连接。<br />
根据特定的编排环境，Felix负责以下任务：</p><br />
<br />
<p>管理网络接口，Felix将有关接口的一些信息编程到内核中，以使内核能够正确处理该endpoint发出的流量。 特别是，它将确保主机正确响应来自每个工作负载的ARP请求，并将为其管理的接口启用IP转发支持。它还监视网络接口的出现和消失，以便确保针对这些接口的编程得到了正确的应用。<br />
编写路由，Felix负责将到其主机上endpoints的路由编写到Linux内核FIB（转发信息库）中。 这可以确保那些发往目标主机的endpoints的数据包被正确地转发。<br />
编写ACLs，Felix还负责将ACLs编程到Linux内核中。 这些ACLs用于确保只能在endpoints之间发送有效的网络流量，并确保endpoints无法绕过Calico的安全措施。<br />
报告状态，Felix负责提供有关网络健康状况的数据。 特别是，它将报告配置其主机时发生的错误和问题。 该数据会被写入etcd，以使其对网络中的其他组件和操作才可见。</p><br />
<br />
<p>Orchestrator Plugin<br />
每个主要的云编排平台都有单独的Calico网络插件（例如OpenStack，Kubernetes）。 这些插件的目的是将Calico更紧密地绑定到编排工具中，允许用户管理Calico网络，就像他们管理编排工具中内置的网络工具一样。<br />
一个好的Orchestrator插件示例是Calico Neutron ML2 驱动程序。 该插件与Neutron的ML2插件集成，允许用户通过Neutron API调用来配置Calico网络，实现了与Neutron的无缝集成。<br />
Orchestrator插件负责以下任务：</p><br />
<br />
<p>API Translation，每个云编排工具都不可避免地拥有自己的一套用于管理网络的API接口规范， Orchestrator插件的主要工作就是将这些API转换为Calico的数据模型，然后将其存储在Calico的数据存储区中。这种转换中的一些工作将非常简单，其他一部分可能更复杂，以便将单个复杂操作（例如，实时迁移）转换为Calico网络期望的一系列更简单的操作。<br />
Feedback，如有需要，orchestrator插件将从Calico网络向编排器提供管理命令的反馈信息。 包括提供有关Felix存活的信息，以及如果网络配置失败则将某些endpoints标记为失败。</p><br />
<br />
<p>etcd<br />
etcd是一个分布式键值存储数据库，专注于实现数据存储一致性。 Calico使用etcd提供组件之间的数据通信，并作为可以保证一致性的数据存储，以确保Calico始终可以构建出一个准确的网络。<br />
根据orchestrator插件的不同，etcd既可以是作为主数据存储使用，也可以是一个单独数据存储的轻量级镜像。例如，在OpenStack部署中，OpenStack数据库被认为是“真实配置信息的来源”，而etcd用于镜像其中有关网络配置的信息，并用于服务其他Calico组件。<br />
etcd组件穿插在整个部署中。它可以被分为两组主机节点：核心集群和代理。<br />
对于小型部署，核心集群可以是一个节点的etcd集群（通常与orchestrator插件组件位于同一节点上）。这种部署模型很简单但没有为etcd提供冗余。在etcd失败的情况下，orchstrator插件必须重建数据库，例如OpenStack，它需要插件从OpenStack数据库重新同步状态到etcd。<br />
在较大的部署中，核心群集可以根据etcd管理指南进行扩展。<br />
此外，在运行Felix或orchstrator插件的每台计算机上，会运行一个etcd代理服务。这减少了etcd核心集群上的负载，并为主机节点屏蔽了etcd服务集群的细节。在etcd集群与orchstrator插件在同一台机器上都有成员的情况下，可以放弃在该机器上使用etcd代理。<br />
etcd负责执行以下任务：</p><br />
<br />
<p>Data Storage，etcd以分布式、一致和容错的方式存储Calico网络的数据（对于至少三个etcd节点的cluster大小）。 这确保Calico网络始终处于已知良好状态，同时允许运行etcd的个别机器节点失败或无法访问。Calico网络数据的这种分布式存储提高了Calico组件从数据库读取的能力。<br />
Communication，etcd也用作组件之间的通信服务。 我们通过让非etcd组件监视键值空间中的某些点来确保他们看到已经做出的任何更改，从而允许他们及时响应这些更改。 该功能允许将状态信息提交到数据库，然后触发基于该状态数据的进一步网络配置管理。</p><br />
<br />
<p>BGP Client (BIRD)<br />
Calico在每个运行Felix服务的节点上都部署一个BGP客户端。 BGP客户端的作用是读取Felix程序编写到内核中并在数据中心内分发的路由信息。<br />
BGP客户端负责执行以下任务：</p><br />
<br />
<p>路由信息分发，当Felix将路由插入Linux内核FIB时，BGP客户端将接收它们并将它们分发到集群中的其他工作节点。</p><br />
<br />
<p>BGP Route Reflector (BIRD)<br />
对于较大规模的部署，简单的BGP可能成为限制因素，因为它要求每个BGP客户端连接到网状拓扑中的每一个其他BGP客户端。这需要越来越多的连接，迅速变得难以维护，甚至会让一些设备的路由表撑满。<br />
因此，在较大规模的部署中，Calico建议部署BGP Route Reflector。通常是在Internet中使用这样的组件充当BGP客户端连接的中心点，从而防止它们需要与群集中的每个BGP客户端进行通信。为了实现冗余，也可以同时部署多个BGP Route Reflector服务。Route Reflector仅仅是协助管理BGP网络，并没有endpoint数据会通过它们。<br />
在Calico中，此BGP组件也是使用的最常见的BIRD，配置为Route Reflector运行，而不是标准BGP客户端。<br />
BGP Route Reflector负责以下任务：</p><br />
<br />
<p>集中式的路由信息分发，当Calico BGP客户端将路由从其FIB通告到Route Reflector时，Route Reflector会将这些路由通告给部署集群中的其他节点。</p><br />
<br />
<p>BIRD是什么<br />
BIRD是布拉格查理大学数学与物理学院的一个学校项目，项目名是BIRD Internet Routing Daemon的缩写。 目前，它由CZ.NIC实验室开发和支持。<br />
BIRD项目旨在开发一个功能齐全的动态IP路由守护进程，主要针对（但不限于）Linux，FreeBSD和其他类UNIX系统，并在GNU通用公共许可证下分发。详细信息参照官网https://bird.network.cz/。<br />
作为一个开源的网络路由守护进程项目，BRID设计并支持了以下功能：</p><br />
<br />
<p>both IPv4 and IPv6 protocols<br />
multiple routing tables<br />
the Border Gateway Protocol (BGPv4)<br />
the Routing Information Protocol (RIPv2, RIPng)<br />
the Open Shortest Path First protocol (OSPFv2, OSPFv3)<br />
the Babel Routing Protocol<br />
the Router Advertisements for IPv6 hosts<br />
a virtual protocol for exchange of routes between different routing tables on a single host<br />
a command-line interface allowing on-line control and inspection of status of the daemon<br />
soft reconfiguration (no need to use complex online commands to change the configuration, just edit the configuration file and notify BIRD to re-read it and it will smoothly switch itself to the new configuration, not disturbing routing protocols unless they are affected by the configuration changes)<br />
a powerful language for route filtering</p><br />
<br />
<p>K8S 中部署 calico</p><br />
<br />
<p>修改kube-api server 启动参数<br />
–allow-priviledge=true (calico 需要特权模式)<br />
复制代码</p><br />
<br />
<p>修改kubelet 启动参数 –network-plugin=cni</p><br />
<br />
<p>假设K8S 环境包含两个node节点 node1 (192,168.18.3) , node2 (192.168.18.4)<br />
创建calico 服务, 主要包括calico-node 和 calico policy controller, 需要的K8S 资源对象如下</p><br />
<br />
<p>configmap: calico-config 包含calico的配置参数<br />
secret: calico-etcd-secrets 用于TLS 连接etcd<br />
在每个节点以daemonset的形式 部署calico/node 容器<br />
在每个节点都安装calico cni 二进制文件和网络配置参数(由install-cni 容器完成)<br />
部署一个名为calico/kube-policy-controller的deployment, 为K8S 集群中的POD 设置network policy</p><br />
<br />
<p>官方 calico k8s 安装 yaml 文件如下<br />
calico-etcd.yaml<br />
—</p><br />
<h1 id="source-calicotemplatescalico-etcd-secretsyaml">Source: calico/templates/calico-etcd-secrets.yaml</h1><br />
<h1 id="the-following-contains-k8s-secrets-for-use-with-a-tls-enabled-etcd-cluster">The following contains k8s Secrets for use with a TLS enabled etcd cluster.</h1><br />
<h1 id="for-information-on-populating-secrets-see-httpkubernetesiodocsuser-guidesecrets">For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/</h1><br />
<p>apiVersion: v1<br />
kind: Secret<br />
type: Opaque<br />
metadata:<br />
  name: calico-etcd-secrets<br />
  namespace: kube-system<br />
data:<br />
  # Populate the following with etcd TLS configuration if desired, but leave blank if<br />
  # not using TLS for etcd.<br />
  # The keys below should be uncommented and the values populated with the base64<br />
  # encoded contents of each file that would be associated with the TLS data.<br />
  # Example command for encoding a file contents: cat <file> | base64 -w 0<br />
  # etcd-key: null<br />
  # etcd-cert: null<br />
  # etcd-ca: null<br />
---</file></p><br />
<h1 id="source-calicotemplatescalico-configyaml">Source: calico/templates/calico-config.yaml</h1><br />
<h1 id="this-configmap-is-used-to-configure-a-self-hosted-calico-installation">This ConfigMap is used to configure a self-hosted Calico installation.</h1><br />
<p>kind: ConfigMap<br />
apiVersion: v1<br />
metadata:<br />
  name: calico-config<br />
  namespace: kube-system<br />
data:<br />
  # Configure this with the location of your etcd cluster.<br />
  #ETCD的服务地址<br />
  etcd_endpoints: “http://<ETCD_IP>:<ETCD_PORT>"<br />
  # If you're using TLS enabled etcd uncomment the following.<br />
  # You must also populate the Secret below with these files.<br />
  etcd_ca: ""   # "/calico-secrets/etcd-ca"<br />
  etcd_cert: "" # "/calico-secrets/etcd-cert"<br />
  etcd_key: ""  # "/calico-secrets/etcd-key"<br />
  # Typha is disabled.<br />
  typha_service_name: "none"<br />
  # Configure the backend to use.<br />
  calico_backend: "bird"</ETCD_PORT></ETCD_IP></p><br />
<br />
<p># Configure the MTU to use<br />
  veth_mtu: “1440”</p><br />
<br />
<p># The CNI network configuration to install on each node.  The special<br />
  # values in this config will be automatically populated.<br />
  cni_network_config: |-<br />
    {<br />
      “name”: “k8s-pod-network”,<br />
      “cniVersion”: “0.3.1”,<br />
      “plugins”: [<br />
        {<br />
          “type”: “calico”,<br />
          “log_level”: “info”,<br />
          “etcd_endpoints”: “<strong>ETCD_ENDPOINTS</strong>”,<br />
          “etcd_key_file”: “<strong>ETCD_KEY_FILE</strong>”,<br />
          “etcd_cert_file”: “<strong>ETCD_CERT_FILE</strong>”,<br />
          “etcd_ca_cert_file”: “<strong>ETCD_CA_CERT_FILE</strong>”,<br />
          “mtu”: <strong>CNI_MTU</strong>,<br />
          “ipam”: {<br />
              “type”: “calico-ipam”<br />
          },<br />
          “policy”: {<br />
              “type”: “k8s”<br />
          },<br />
          “kubernetes”: {<br />
              “kubeconfig”: “<strong>KUBECONFIG_FILEPATH</strong>”<br />
          }<br />
        },<br />
        {<br />
          “type”: “portmap”,<br />
          “snat”: true,<br />
          “capabilities”: {“portMappings”: true}<br />
        }<br />
      ]<br />
    }</p><br />
<br />
<hr /><br />
<h1 id="source-calicotemplatesrbacyaml">Source: calico/templates/rbac.yaml</h1><br />
<br />
<h1 id="include-a-clusterrole-for-the-kube-controllers-component">Include a clusterrole for the kube-controllers component,</h1><br />
<h1 id="and-bind-it-to-the-calico-kube-controllers-serviceaccount">and bind it to the calico-kube-controllers serviceaccount.</h1><br />
<p>kind: ClusterRole<br />
apiVersion: rbac.authorization.k8s.io/v1<br />
metadata:<br />
  name: calico-kube-controllers<br />
rules:<br />
  # Pods are monitored for changing labels.<br />
  # The node controller monitors Kubernetes nodes.<br />
  # Namespace and serviceaccount labels are used for policy.</p><br />
<ul><br />
  <li>apiGroups: [””]<br />
resources:<br />
    <ul><br />
      <li>pods</li><br />
      <li>nodes</li><br />
      <li>namespaces</li><br />
      <li>serviceaccounts<br />
verbs:</li><br />
      <li>watch</li><br />
      <li>list<br />
  # Watch for changes to Kubernetes NetworkPolicies.</li><br />
    </ul><br />
  </li><br />
  <li>apiGroups: [“networking.k8s.io”]<br />
resources:<br />
    <ul><br />
      <li>networkpolicies<br />
verbs:</li><br />
      <li>watch</li><br />
      <li><br />
        <h2 id="list">list</h2><br />
        <p>kind: ClusterRoleBinding<br />
apiVersion: rbac.authorization.k8s.io/v1<br />
metadata:<br />
  name: calico-kube-controllers<br />
roleRef:<br />
  apiGroup: rbac.authorization.k8s.io<br />
  kind: ClusterRole<br />
  name: calico-kube-controllers<br />
subjects:</p><br />
      </li><br />
    </ul><br />
  </li><br />
  <li>kind: ServiceAccount<br />
name: calico-kube-controllers<br />
namespace: kube-system<br />
—<br />
    <h1 id="include-a-clusterrole-for-the-calico-node-daemonset">Include a clusterrole for the calico-node DaemonSet,</h1><br />
    <h1 id="and-bind-it-to-the-calico-node-serviceaccount">and bind it to the calico-node serviceaccount.</h1><br />
    <p>kind: ClusterRole<br />
apiVersion: rbac.authorization.k8s.io/v1<br />
metadata:<br />
name: calico-node<br />
rules:</p><br />
    <h1 id="the-cni-plugin-needs-to-get-pods-nodes-and-namespaces">The CNI plugin needs to get pods, nodes, and namespaces.</h1><br />
    <ul><br />
      <li>apiGroups: [””]<br />
resources:<br />
        <ul><br />
          <li>pods</li><br />
          <li>nodes</li><br />
          <li>namespaces<br />
verbs:</li><br />
          <li>get</li><br />
        </ul><br />
      </li><br />
      <li>apiGroups: [””]<br />
resources:<br />
        <ul><br />
          <li>endpoints</li><br />
          <li>services<br />
verbs:<br />
  # Used to discover service IPs for advertisement.</li><br />
          <li>watch</li><br />
          <li>list</li><br />
        </ul><br />
      </li><br />
      <li>apiGroups: [””]<br />
resources:<br />
        <ul><br />
          <li>nodes/status<br />
verbs:<br />
  # Needed for clearing NodeNetworkUnavailable flag.</li><br />
          <li><br />
            <h2 id="patch">patch</h2><br />
            <p>apiVersion: rbac.authorization.k8s.io/v1<br />
kind: ClusterRoleBinding<br />
metadata:<br />
name: calico-node<br />
roleRef:<br />
apiGroup: rbac.authorization.k8s.io<br />
kind: ClusterRole<br />
name: calico-node<br />
subjects:</p><br />
          </li><br />
        </ul><br />
      </li><br />
    </ul><br />
  </li><br />
  <li>kind: ServiceAccount<br />
name: calico-node<br />
namespace: kube-system</li><br />
</ul><br />
<br />
<hr /><br />
<h1 id="source-calicotemplatescalico-nodeyaml">Source: calico/templates/calico-node.yaml</h1><br />
<h1 id="this-manifest-installs-the-calico-node-container-as-well">This manifest installs the calico-node container, as well</h1><br />
<h1 id="as-the-cni-plugins-and-network-config-on">as the CNI plugins and network config on</h1><br />
<h1 id="each-master-and-worker-node-in-a-kubernetes-cluster">each master and worker node in a Kubernetes cluster.</h1><br />
<p>kind: DaemonSet<br />
apiVersion: apps/v1<br />
metadata:<br />
  name: calico-node<br />
  namespace: kube-system<br />
  labels:<br />
    k8s-app: calico-node<br />
spec:<br />
  selector:<br />
    matchLabels:<br />
      k8s-app: calico-node<br />
  updateStrategy:<br />
    type: RollingUpdate<br />
    rollingUpdate:<br />
      maxUnavailable: 1<br />
  template:<br />
    metadata:<br />
      labels:<br />
        k8s-app: calico-node<br />
      annotations:<br />
        # This, along with the CriticalAddonsOnly toleration below,<br />
        # marks the pod as a critical add-on, ensuring it gets<br />
        # priority scheduling and that its resources are reserved<br />
        # if it ever gets evicted.<br />
        scheduler.alpha.kubernetes.io/critical-pod: ‘’<br />
    spec:<br />
      nodeSelector:<br />
        beta.kubernetes.io/os: linux<br />
      hostNetwork: true<br />
      tolerations:<br />
        # Make sure calico-node gets scheduled on all nodes.<br />
        - effect: NoSchedule<br />
          operator: Exists<br />
        # Mark the pod as a critical add-on for rescheduling.<br />
        - key: CriticalAddonsOnly<br />
          operator: Exists<br />
        - effect: NoExecute<br />
          operator: Exists<br />
      serviceAccountName: calico-node<br />
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a “force<br />
      # deletion”: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.<br />
      terminationGracePeriodSeconds: 0<br />
      priorityClassName: system-node-critical<br />
      initContainers:<br />
        # This container installs the CNI binaries<br />
        # and CNI network config file on each node.<br />
        - name: install-cni<br />
          image: calico/cni:v3.8.0<br />
          command: [“/install-cni.sh”]<br />
          env:<br />
            # Name of the CNI config file to create.<br />
            - name: CNI_CONF_NAME<br />
              value: “10-calico.conflist”<br />
            # The CNI network config to install on each node.<br />
            - name: CNI_NETWORK_CONFIG<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: cni_network_config<br />
            # The location of the etcd cluster.<br />
            - name: ETCD_ENDPOINTS<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_endpoints<br />
            # CNI MTU Config variable<br />
            - name: CNI_MTU<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: veth_mtu<br />
            # Prevents the container from sleeping forever.<br />
            - name: SLEEP<br />
              value: “false”<br />
          volumeMounts:<br />
            - mountPath: /host/opt/cni/bin<br />
              name: cni-bin-dir<br />
            - mountPath: /host/etc/cni/net.d<br />
              name: cni-net-dir<br />
            - mountPath: /calico-secrets<br />
              name: etcd-certs<br />
        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes<br />
        # to communicate with Felix over the Policy Sync API.<br />
        - name: flexvol-driver<br />
          image: calico/pod2daemon-flexvol:v3.8.0<br />
          volumeMounts:<br />
          - name: flexvol-driver-host<br />
            mountPath: /host/driver<br />
      containers:<br />
        # Runs calico-node container on each Kubernetes node.  This<br />
        # container programs network policy and routes on each<br />
        # host.<br />
        - name: calico-node<br />
          image: calico/node:v3.8.0<br />
          env:<br />
            # The location of the etcd cluster.<br />
            - name: ETCD_ENDPOINTS<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_endpoints<br />
            # Location of the CA certificate for etcd.<br />
            - name: ETCD_CA_CERT_FILE<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_ca<br />
            # Location of the client key for etcd.<br />
            - name: ETCD_KEY_FILE<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_key<br />
            # Location of the client certificate for etcd.<br />
            - name: ETCD_CERT_FILE<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_cert<br />
            # Set noderef for node controller.<br />
            - name: CALICO_K8S_NODE_REF<br />
              valueFrom:<br />
                fieldRef:<br />
                  fieldPath: spec.nodeName<br />
            # Choose the backend to use.<br />
            - name: CALICO_NETWORKING_BACKEND<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: calico_backend<br />
            # Cluster type to identify the deployment type<br />
            - name: CLUSTER_TYPE<br />
              value: “k8s,bgp”<br />
            # Auto-detect the BGP IP address.<br />
            - name: IP<br />
              value: “autodetect”<br />
            # Enable IPIP<br />
            - name: CALICO_IPV4POOL_IPIP<br />
              value: “Always”<br />
            # Set MTU for tunnel device used if ipip is enabled<br />
            - name: FELIX_IPINIPMTU<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: veth_mtu<br />
            # The default IPv4 pool to create on startup if none exists. Pod IPs will be<br />
            # chosen from this range. Changing this value after installation will have<br />
            # no effect. This should fall within <code class="language-plaintext highlighter-rouge">--cluster-cidr</code>.<br />
            - name: CALICO_IPV4POOL_CIDR<br />
              value: “192.168.0.0/16”<br />
            # Disable file logging so <code class="language-plaintext highlighter-rouge">kubectl logs</code> works.<br />
            - name: CALICO_DISABLE_FILE_LOGGING<br />
              value: “true”<br />
            # Set Felix endpoint to host default action to ACCEPT.<br />
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION<br />
              value: “ACCEPT”<br />
            # Disable IPv6 on Kubernetes.<br />
            - name: FELIX_IPV6SUPPORT<br />
              value: “false”<br />
            # Set Felix logging to “info”<br />
            - name: FELIX_LOGSEVERITYSCREEN<br />
              value: “info”<br />
            - name: FELIX_HEALTHENABLED<br />
              value: “true”<br />
          securityContext:<br />
            privileged: true<br />
          resources:<br />
            requests:<br />
              cpu: 250m<br />
          livenessProbe:<br />
            httpGet:<br />
              path: /liveness<br />
              port: 9099<br />
              host: localhost<br />
            periodSeconds: 10<br />
            initialDelaySeconds: 10<br />
            failureThreshold: 6<br />
          readinessProbe:<br />
            exec:<br />
              command:<br />
              - /bin/calico-node<br />
              - -bird-ready<br />
              - -felix-ready<br />
            periodSeconds: 10<br />
          volumeMounts:<br />
            - mountPath: /lib/modules<br />
              name: lib-modules<br />
              readOnly: true<br />
            - mountPath: /run/xtables.lock<br />
              name: xtables-lock<br />
              readOnly: false<br />
            - mountPath: /var/run/calico<br />
              name: var-run-calico<br />
              readOnly: false<br />
            - mountPath: /var/lib/calico<br />
              name: var-lib-calico<br />
              readOnly: false<br />
            - mountPath: /calico-secrets<br />
              name: etcd-certs<br />
            - name: policysync<br />
              mountPath: /var/run/nodeagent<br />
      volumes:<br />
        # Used by calico-node.<br />
        - name: lib-modules<br />
          hostPath:<br />
            path: /lib/modules<br />
        - name: var-run-calico<br />
          hostPath:<br />
            path: /var/run/calico<br />
        - name: var-lib-calico<br />
          hostPath:<br />
            path: /var/lib/calico<br />
        - name: xtables-lock<br />
          hostPath:<br />
            path: /run/xtables.lock<br />
            type: FileOrCreate<br />
        # Used to install CNI.<br />
        - name: cni-bin-dir<br />
          hostPath:<br />
            path: /opt/cni/bin<br />
        - name: cni-net-dir<br />
          hostPath:<br />
            path: /etc/cni/net.d<br />
        # Mount in the etcd TLS secrets with mode 400.<br />
        # See https://kubernetes.io/docs/concepts/configuration/secret/<br />
        - name: etcd-certs<br />
          secret:<br />
            secretName: calico-etcd-secrets<br />
            defaultMode: 0400<br />
        # Used to create per-pod Unix Domain Sockets<br />
        - name: policysync<br />
          hostPath:<br />
            type: DirectoryOrCreate<br />
            path: /var/run/nodeagent<br />
        # Used to install Flex Volume Driver<br />
        - name: flexvol-driver-host<br />
          hostPath:<br />
            type: DirectoryOrCreate<br />
            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds<br />
—</p><br />
<br />
<p>apiVersion: v1<br />
kind: ServiceAccount<br />
metadata:<br />
  name: calico-node<br />
  namespace: kube-system</p><br />
<br />
<hr /><br />
<h1 id="source-calicotemplatescalico-kube-controllersyaml">Source: calico/templates/calico-kube-controllers.yaml</h1><br />
<br />
<h1 id="see-httpsgithubcomprojectcalicokube-controllers">See https://github.com/projectcalico/kube-controllers</h1><br />
<p>apiVersion: apps/v1<br />
kind: Deployment<br />
metadata:<br />
  name: calico-kube-controllers<br />
  namespace: kube-system<br />
  labels:<br />
    k8s-app: calico-kube-controllers<br />
spec:<br />
  # The controllers can only have a single active instance.<br />
  replicas: 1<br />
  selector:<br />
    matchLabels:<br />
      k8s-app: calico-kube-controllers<br />
  strategy:<br />
    type: Recreate<br />
  template:<br />
    metadata:<br />
      name: calico-kube-controllers<br />
      namespace: kube-system<br />
      labels:<br />
        k8s-app: calico-kube-controllers<br />
      annotations:<br />
        scheduler.alpha.kubernetes.io/critical-pod: ‘’<br />
    spec:<br />
      nodeSelector:<br />
        beta.kubernetes.io/os: linux<br />
      tolerations:<br />
        # Mark the pod as a critical add-on for rescheduling.<br />
        - key: CriticalAddonsOnly<br />
          operator: Exists<br />
        - key: node-role.kubernetes.io/master<br />
          effect: NoSchedule<br />
      serviceAccountName: calico-kube-controllers<br />
      priorityClassName: system-cluster-critical<br />
      # The controllers must run in the host network namespace so that<br />
      # it isn’t governed by policy that would prevent it from working.<br />
      hostNetwork: true<br />
      containers:<br />
        - name: calico-kube-controllers<br />
          image: calico/kube-controllers:v3.8.0<br />
          env:<br />
            # The location of the etcd cluster.<br />
            - name: ETCD_ENDPOINTS<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_endpoints<br />
            # Location of the CA certificate for etcd.<br />
            - name: ETCD_CA_CERT_FILE<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_ca<br />
            # Location of the client key for etcd.<br />
            - name: ETCD_KEY_FILE<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_key<br />
            # Location of the client certificate for etcd.<br />
            - name: ETCD_CERT_FILE<br />
              valueFrom:<br />
                configMapKeyRef:<br />
                  name: calico-config<br />
                  key: etcd_cert<br />
            # Choose which controllers to run.<br />
            - name: ENABLED_CONTROLLERS<br />
              value: policy,namespace,serviceaccount,workloadendpoint,node<br />
          volumeMounts:<br />
            # Mount in the etcd TLS secrets.<br />
            - mountPath: /calico-secrets<br />
              name: etcd-certs<br />
          readinessProbe:<br />
            exec:<br />
              command:<br />
              - /usr/bin/check-status<br />
              - -r<br />
      volumes:<br />
        # Mount in the etcd TLS secrets with mode 400.<br />
        # See https://kubernetes.io/docs/concepts/configuration/secret/<br />
        - name: etcd-certs<br />
          secret:<br />
            secretName: calico-etcd-secrets<br />
            defaultMode: 0400</p><br />
<br />
<hr /><br />
<br />
<p>apiVersion: v1<br />
kind: ServiceAccount<br />
metadata:<br />
  name: calico-kube-controllers<br />
  namespace: kube-system<br />
—</p><br />
<h1 id="source-calicotemplatescalico-typhayaml">Source: calico/templates/calico-typha.yaml</h1><br />
<br />
<hr /><br />
<h1 id="source-calicotemplatesconfigure-canalyaml">Source: calico/templates/configure-canal.yaml</h1><br />
<br />
<hr /><br />
<h1 id="source-calicotemplateskdd-crdsyaml">Source: calico/templates/kdd-crds.yaml</h1><br />
<br />
<p>复制代码kubectl apply -f calico-etcd.yaml<br />
复制代码<br />
注意修改参数</p><br />
<br />
<p>更多calico设置<br />
coredns<br />
启用 coredns 需要在kubelet 上添加两个参数<br />
–cluster-dns=169.169.0.100 IP 为DNS服务的cluster ip<br />
–cluster-domain=cluster.local 为dns服务设置的域名<br />
需要部署的coredns yaml文件<br />
apiVersion: v1<br />
kind: ServiceAccount<br />
metadata:<br />
  name: coredns<br />
  namespace: kube-system<br />
—<br />
apiVersion: rbac.authorization.k8s.io/v1<br />
kind: ClusterRole<br />
metadata:<br />
  labels:<br />
    kubernetes.io/bootstrapping: rbac-defaults<br />
  name: system:coredns<br />
rules:</p><br />
<ul><br />
  <li>apiGroups:<br />
    <ul><br />
      <li>””<br />
resources:</li><br />
      <li>endpoints</li><br />
      <li>services</li><br />
      <li>pods</li><br />
      <li>namespaces<br />
verbs:</li><br />
      <li>list</li><br />
      <li>watch</li><br />
    </ul><br />
  </li><br />
  <li>apiGroups:<br />
    <ul><br />
      <li>””<br />
resources:</li><br />
      <li>nodes<br />
verbs:</li><br />
      <li><br />
        <h2 id="get">get</h2><br />
        <p>apiVersion: rbac.authorization.k8s.io/v1<br />
kind: ClusterRoleBinding<br />
metadata:<br />
annotations:<br />
rbac.authorization.kubernetes.io/autoupdate: “true”<br />
labels:<br />
kubernetes.io/bootstrapping: rbac-defaults<br />
name: system:coredns<br />
roleRef:<br />
apiGroup: rbac.authorization.k8s.io<br />
kind: ClusterRole<br />
name: system:coredns<br />
subjects:</p><br />
      </li><br />
    </ul><br />
  </li><br />
  <li>kind: ServiceAccount<br />
name: coredns<br />
namespace: kube-system<br />
—<br />
apiVersion: v1<br />
kind: ConfigMap<br />
metadata:<br />
name: coredns<br />
namespace: kube-system<br />
data:<br />
Corefile: |<br />
  .:53 {<br />
      errors<br />
      health<br />
      ready<br />
      kubernetes CLUSTER_DOMAIN REVERSE_CIDRS {<br />
        pods insecure<br />
        fallthrough in-addr.arpa ip6.arpa<br />
      }FEDERATIONS<br />
      prometheus :9153<br />
      forward . UPSTREAMNAMESERVER<br />
      cache 30<br />
      loop<br />
      reload<br />
      loadbalance<br />
  }STUBDOMAINS<br />
—<br />
apiVersion: apps/v1<br />
kind: Deployment<br />
metadata:<br />
name: coredns<br />
namespace: kube-system<br />
labels:<br />
  k8s-app: kube-dns<br />
  kubernetes.io/name: “CoreDNS”<br />
spec:<br />
replicas: 2<br />
strategy:<br />
  type: RollingUpdate<br />
  rollingUpdate:<br />
    maxUnavailable: 1<br />
selector:<br />
  matchLabels:<br />
    k8s-app: kube-dns<br />
template:<br />
  metadata:<br />
    labels:<br />
      k8s-app: kube-dns<br />
  spec:<br />
    priorityClassName: system-cluster-critical<br />
    serviceAccountName: coredns<br />
    tolerations:<br />
      - key: “CriticalAddonsOnly”<br />
        operator: “Exists”<br />
    nodeSelector:<br />
      beta.kubernetes.io/os: linux<br />
    containers:<br />
    - name: coredns<br />
      image: coredns/coredns:1.5.0<br />
      imagePullPolicy: IfNotPresent<br />
      resources:<br />
        limits:<br />
          memory: 170Mi<br />
        requests:<br />
          cpu: 100m<br />
          memory: 70Mi<br />
      args: [ “-conf”, “/etc/coredns/Corefile” ]<br />
      volumeMounts:<br />
      - name: config-volume<br />
        mountPath: /etc/coredns<br />
        readOnly: true<br />
      ports:<br />
      - containerPort: 53<br />
        name: dns<br />
        protocol: UDP<br />
      - containerPort: 53<br />
        name: dns-tcp<br />
        protocol: TCP<br />
      - containerPort: 9153<br />
        name: metrics<br />
        protocol: TCP<br />
      securityContext:<br />
        allowPrivilegeEscalation: false<br />
        capabilities:<br />
          add:<br />
          - NET_BIND_SERVICE<br />
          drop:<br />
          - all<br />
        readOnlyRootFilesystem: true<br />
      livenessProbe:<br />
        httpGet:<br />
          path: /health<br />
          port: 8080<br />
          scheme: HTTP<br />
        initialDelaySeconds: 60<br />
        timeoutSeconds: 5<br />
        successThreshold: 1<br />
        failureThreshold: 5<br />
      readinessProbe:<br />
        httpGet:<br />
          path: /ready<br />
          port: 8181<br />
          scheme: HTTP<br />
    dnsPolicy: Default<br />
    volumes:<br />
      - name: config-volume<br />
        configMap:<br />
          name: coredns<br />
          items:<br />
          - key: Corefile<br />
            path: Corefile<br />
—<br />
apiVersion: v1<br />
kind: Service<br />
metadata:<br />
name: kube-dns<br />
namespace: kube-system<br />
annotations:<br />
  prometheus.io/port: “9153”<br />
  prometheus.io/scrape: “true”<br />
labels:<br />
  k8s-app: kube-dns<br />
  kubernetes.io/cluster-service: “true”<br />
  kubernetes.io/name: “CoreDNS”<br />
spec:<br />
selector:<br />
  k8s-app: kube-dns<br />
  #这里要和kubelet 参数对应上<br />
clusterIP: 169.169.0.100<br />
ports:<br />
    <ul><br />
      <li>name: dns<br />
port: 53<br />
protocol: UDP</li><br />
      <li>name: dns-tcp<br />
port: 53<br />
protocol: TCP</li><br />
      <li>name: metrics<br />
port: 9153<br />
protocol: TCP<br />
复制代码如果想知道现有集群中使用的配置项可以使用如下命令进行查看<br />
kubectl -n kube-system get configmap coredns -o yaml</li><br />
    </ul><br />
  </li><br />
</ul><br />

					 <span class='st_sharethis_large' displayText='ShareThis'></span>
						<span class='st_facebook_large' displayText='Facebook'></span>
						<span class='st_twitter_large' displayText='Tweet'></span>
						<span class='st_linkedin_large' displayText='LinkedIn'></span>
						<span class='st_pinterest_large' displayText='Pinterest'></span>
						<span class='st_email_large' displayText='Email'></span>
                </div>
                Category docker
        </div>
	</div>
  
  
       <!--赞-->
    	  <div class="row">
            <div class="col-lg-6">
                <img src="https://xiazemin.github.io/MyBlog/img/webwxgetmsgimg.jpeg"  height="400" width="auto" />
            </div>
          </div>

        <div class="row">
                <div class="col-md-12">
			<div id="disqus_thread"></div>

<div id="gitmentContainer"></div>
<link rel="stylesheet" href="/MyBlog/css/default.css">
<script src="/MyBlog/js/gitment.browser.js"></script>
<script type="text/javascript" src="/MyBlog/js/json2.js"></script>
<script>
var gitment = new Gitment({
    owner: 'xiazemin',
    repo: 'MyBlogComment',
    oauth: {
        client_id: '981ba8c916c262631ea0',
        client_secret: 'a52260ef92de69011ccd1cf355b973ef11d6da0e',
    },
});

var MyGitmentContainer=gitment.render('gitmentContainer');
window.setTimeout(MyGitMentBtnclick,1000); 
//document.ready(function(){ 
//window.onload=function(){}

function MyGitMentBtnclick(){
//var MyGitmentContainer=document.getElementById('gitmentContainer');
	var ele=[],all=MyGitmentContainer.getElementsByTagName("*");
	for(var i=0;i<all.length;i++){
	  if(all[i].className=='gitment-comments-init-btn'){
		MyGitMentBtn=all[i];
		console.log(MyGitMentBtn);
		MyGitMentBtn.click();
	  }
	}
}

</script>



			<!--script>
			/**
			* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
			* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
			*/
			/*
			var disqus_config = function () {
			this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
			this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
			};
			*/
			(function() { // DON'T EDIT BELOW THIS LINE
			var d = document, s = d.createElement('script');

			s.src = '//airrayagroup.disqus.com/embed.js';

			s.setAttribute('data-timestamp', +new Date());
			(d.head || d.body).appendChild(s);
			})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			<script id="dsq-count-scr" src="//airrayagroup.disqus.com/count.js" async></script-->
          </div>
       </div>

</div>
<hr>
     <footer>
        <div class="container">
             <a href="/MyBlog/" style="color: green; font-size: 2em; font-family: 'Schoolbell', cursive;">首页</a>
            <div class="row">
                <div class="col-lg-6">
                    <p>Copyright &copy; 2017 465474307@qq.com <p>
                </div>
                <div class="col-lg-6">
                    <p style="float: right;">Jekyll theme by <a href="https://github.com/xiazemin/">夏泽民</a></p>
                </div>
            </div>
        </div>
    </footer>
	
    <!-- jQuery -->
    <script src="/MyBlog/js/jquery-1.12.0.min.js"></script>
    <script src="/MyBlog/js/jquery-migrate-1.2.1.min.js"></script>

    <!-- Latest compiled and minified JavaScript -->
    <script src="/MyBlog/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
        <!-- Menu Toggle Script -->
    <script>
    $("#menu-toggle").click(function(e) {
        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
    </script>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"6","bdPos":"right","bdTop":"100"},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/MyBlog/shareapi/js/share.js?v=89860593.js?'];</script>


<!-- 2d  -->
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.0.min.js"></script>
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.min.js"></script>
<script type="text/javascript">
 setTimeout(()=> {
/*L2Dwidget.init({"display": {
        "superSample": 2,
        "width": 200,
        "height": 400,
             "position": "right",
                 "hOffset": 0,
        "vOffset": 0
          }
     });
*/
 L2Dwidget
        .on('*', (name) => {
          console.log('%c EVENT ' + '%c -> ' + name, 'background: #222; color: yellow', 'background: #fff; color: #000')
        })
        .init({
          dialog: {
            // 开启对话框
            enable: true,
            script: {
              // 每空闲 10 秒钟，显示一条一言
              'every idle 10s': '$hitokoto$',
              // 当触摸到星星图案
              'hover .star': '星星在天上而你在我心里 (*/ω＼*)',
              // 当触摸到角色身体
              'tap body': '哎呀！别碰我！',
              // 当触摸到角色头部
              'tap face': '人家已经不是小孩子了！'
            }
          }
        });

})
</script>



    <!--html xmlns:wb="http://open.weibo.com/wb">
    <script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
    <wb:follow-button uid="2165491993" type="red_1" width="67" height="24" ></wb:follow-button-->

      <!--本文来自-->
     <script type="text/javascript">
      /* 仅IE
     document.body.oncopy = function(){
        setTimeout( 
            function () { 
        var text =window.clipboardData.getData("text"); 
        if (text) { 
            text = text + "/r/n本篇文章来源于 xiazemin 的 泽民博客|https://xiazemin.github.io/MyBlog/index.html 原文链接："+location.href; clipboardData.setData("text", text); 
          }
       },
     100 )
    }
     */
     //绑定在了body上，也可以绑定在其他可用元素行，但是不是所有元素都支持copy和past事件。

     /*
$(document.body).bind({
    copy: function(event) {//copy事件
        //var cpTxt = "复制的数据";
        var clipboardData = window.clipboardData; //for IE
        if (!clipboardData) { // for chrome
            clipboardData = event.originalEvent.clipboardData;
        }

        if (event.clipboardData != null/false/undefined) { //ignore the incorrectness of the truncation
        clipboarddata = event.clipboardData;
        } else if (window.clipboardData != null/false/undefined) {
         clipboarddata = window.clipboardData;
        } else { //default to the last option even if it is null/false/undefined
         clipboarddata = event.originalEvent.clipboardData;
        }

        //e.clipboardData.getData('text');//可以获取用户选中复制的数据
        //clipboardData.setData('Text', cpTxt);
        alert(clipboarddata.getData('text'));
        //$('#message').text('Copy Data : ' + cpTxt);
        return false;//否则设不生效
    },paste: function(e) {//paste事件
        var eve = e.originalEvent
        var cp = eve.clipboardData;
        var data = null;
        var clipboardData = window.clipboardData; // IE
        if (!clipboardData) { //chrome
            clipboardData = e.originalEvent.clipboardData
        }
        data = clipboardData.getData('Text');
        //$('#message').html(data);
    }
});     
*/
function addLink() {
    var body_element = document.getElementsByTagName('body')[0];
    var selection;
    selection = window.getSelection();
    var pagelink = "<br /><br />本文来源：xiazemin 的 泽民博客 <a href='"+document.location.href+"'>"+document.location.href+"</a>";
//+document.location.href+当前页面链接
    var copy_text = selection + pagelink;
    console.log(copy_text);
    var new_div = document.createElement('div');
    new_div.style.left='-99999px';
    new_div.style.position='absolute';
    body_element.appendChild(new_div );
    new_div.innerHTML = copy_text ;
    selection.selectAllChildren(new_div );
    window.setTimeout(function() {
        body_element.removeChild(new_div );
    },0);
}
document.oncopy = addLink;
     </script>
    <!--本文来自-->

</div>
  </body>

</html>