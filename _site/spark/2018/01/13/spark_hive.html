<!DOCTYPE html>
<html>

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Sci blog jekyll theme">
    <meta name="author" content="AIR RAYA Group">
    <link href='/MyBlog/img/favicon.ico' type='image/icon' rel='shortcut icon'/>

    <title>泽民博客 | Jekyll theme</title>

    <link rel="stylesheet" href="/MyBlog/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="/MyBlog/css/font-awesome.min.css">
    <link href="/MyBlog/css/simple-sidebar.css" rel="stylesheet">
	<link href="/MyBlog/css/classic-10_7.css" rel="stylesheet" type="text/css">
    <!-- Custom CSS -->
    <link href="/MyBlog/css/style.css" rel="stylesheet">
    <link href="/MyBlog/css/pygments.css" rel="stylesheet">
    <!-- Fonts -->
 <link href="/MyBlog/css/front.css" rel="stylesheet" type="text/css">
 <link href="/MyBlog/css/Josefin_Slab.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Architects_Daughter.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Schoolbell.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Codystar.css" rel="stylesheet" type="text/css">

 <script type="text/javascript" src="/MyBlog/js/jquery-1.12.0.min.js"></script>	

<link href="/MyBlog/css/calendar/common.css" type="text/css"  rel="stylesheet">
<script type="text/javascript" src="/MyBlog/js/calendar/calendar.js"></script>
	<!-- share this -->
	<script type="text/javascript">var switchTo5x=true;</script>
	<script type="text/javascript" src="/MyBlog/js/buttons.js"></script>
	<script type="text/javascript">stLight.options({publisher: "b28464c3-d287-4257-ad18-058346dd35f7", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="/MyBlog/js/html5shiv.js"></script>
        <script src="/MyBlog/js/respond.min.js"></script>
    <![endif]-->
   
   <!--百度统计-->
    <script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e965cab8c73512b8b23939e7051d93bd";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <script async src="/MyBlog/katex/katex.js"></script>
    <link rel="stylesheet" href="/MyBlog/katex/katex.css">

    <!--轮播图片-->
    <!--script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.stripesrotator.js"></script>
    <script type="text/javascript">
                    $(document).ready(function() {
                    alert($('#rotator_xzm'));
                     alert($('#rotator_xzm').fn);
                    $('#rotator_xzm').stripesRotator({ images: [ "https://xiazemin.github.io/MyBlog/img/BPlusTree.png", "https://xiazemin.github.io/MyBlog/img/linuxMMap.jpeg"] });
                    });
    </script-->

    <!--水印-->
    <script type="text/javascript" src="/MyBlog/js/waterMark.js"></script>
    <script type="text/javascript">
    $(document).ready(function(){
    watermark({watermark_txt0:'泽民博客',watermark_txt1:'zemin',watermark_txt2:(new Date()).Format("yyyy-MM-dd hh:mm:ss.S")});
    })
    </script>
     <!--水印-->
     <!--adscene-->
    <script data-ad-client="ca-pub-6672721494777557" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

</head>

 <body>
<div id="wrapper">
 <!-- Navigation -->
    <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="/MyBlog">
                        Home
                    </a>
                </li>
                <li>
                    <a href="#">About</a>
                </li>
                <li>
                    <a href="#">Services</a>
                </li>
                <li>
                    <a href="#">Portfolio</a>
                </li>
                <li>
                    <a href="#">Events</a>
                </li>
                <li>
                    <a href="#">Blog</a>
                </li>
                <li>
                    <a href="#">FAQ</a>
                </li>
                <li>
                    <a href="#">Contact</a>
                </li>
            </ul>
        </div>


    <header class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="heading text-center">
                        <a href="https://xiazemin.github.io/MyBlog/" style="color: #fff; font-size: 4em; font-family: 'Schoolbell', cursive;">泽民博客</a>
                        <a href="#menu-toggle" class="btn btn-default sciblog" id="menu-toggle" style="font-weight: bold;">&#9776; Menu</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

     <script async src="/MyBlog/js/busuanzi.pure.mini.js"></script>

    <script type="text/javascript" src="/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="/MyBlog/js/jquery.stripesrotator.js"></script>


 <div class="container">
	<div class="row">
        <div class="box">
                <div class="col-lg-12">
                    <div class="intro-text text-center">
					<h1 class="post-title" itemprop="name headline">spark on hive</h1>
					<p class="post-meta"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">by 夏泽民</span></span> <time datetime="2018-01-13T00:00:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Jan 13, 2018</time></p>
					</div>
					 <p>$cp hive/hive/conf/hive-site.xml spark/spark/conf/<br />
<!-- more --><br />
启动hive<br />
启动spark</p><br />
<br />
<p>import org.apache.spark.sql.SparkSession<br />
val sparkSession = SparkSession.builder.master(“local”).enableHiveSupport().getOrCreate();</p><br />
<br />
<p>Caused by: ERROR XJ040: Failed to start database ‘metastore_db’ with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@294b045b, see the next exception for details.<br />
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)<br />
	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)<br />
	… 150 more<br />
Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/didi/metastore_db.</p><br />
<br />
<p>在使用Hive on Spark模式操作hive里面的数据时，报以上错误，原因是因为HIVE采用了derby这个内嵌数据库作为数据库，它不支持多用户同时访问,解决办法就是把derby数据库换成mysql数据库即可</p><br />
<br />
<p>解决方式：</p><br />
<br />
<p>不使用默认的内嵌数据库derby，采用mysql作为统计的存储信息。</p><br />
<br />
<p>修改相关配置信息（hive-site.xml）：</p><br />
<br />
<property><br />
<br />
       <name>hive.stats.dbclass</name><br />
<br />
       <value>jdbc:mysql</value><br />
<br />
</property><br />
<br />
<property><br />
<br />
       <name>hive.stats.jdbcdriver</name><br />
<br />
       <value>com.mysql.jdbc.Driver</value><br />
<br />
</property><br />
<br />
<property><br />
<br />
       <name>hive.stats.dbconnectionstring</name><br />
<br />
       <value>jdbc:mysql://localhost:3306/TempStatsStore</value><br />
<br />
</property><br />
<br />
<p>修改完成保存。<br />
另外后面还有一个步骤就是要在mysql里创建TempStatsStore这个数据库（mysql里不会自动创建该库，在derby里会自动创建）</p><br />
<br />
<p>方式二<br />
mv  metastore_db metastore_db_bak</p><br />
<br />
<p>scala&gt; val sparkSession = SparkSession.builder.master(“local”).enableHiveSupport().getOrCreate();<br />
18/01/13 15:55:44 WARN spark.SparkContext: Using an existing SparkContext; some configuration may not take effect.<br />
18/01/13 15:55:45 WARN conf.HiveConf: HiveConf of name hive.conf.hidden.list does not exist<br />
18/01/13 15:55:47 WARN conf.HiveConf: HiveConf of name hive.conf.hidden.list does not exist<br />
18/01/13 15:55:49 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0<br />
18/01/13 15:55:50 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException<br />
18/01/13 15:55:51 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException<br />
18/01/13 15:55:51 WARN conf.HiveConf: HiveConf of name hive.conf.hidden.list does not exist<br />
sparkSession: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@14c16388</p><br />
<br />
<p>beeline&gt;  !connect jdbc:hive2://localhost:10000</p><br />
<br />
<p>0: jdbc:hive2://localhost:10000&gt; show tables;<br />
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:For direct MetaStore DB connections, we don’t support retries at the client level.) (state=08S01,code=1)</p><br />
<br />
<p>scala&gt; sparkSession.sql(“CREATE TABLE IF NOT EXISTS src (key INT, value STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\t’ “)<br />
18/01/13 16:04:23 WARN metastore.HiveMetaStore: Location: hdfs://localhost:8020/user/hive/warehouse/src specified for non-external table:src<br />
res8: org.apache.spark.sql.DataFrame = []</p><br />
<br />
<p>scala&gt; sparkSession.sql(“show tables”).collect().foreach(println)<br />
[default,src,false]</p><br />
<br />
<p>scala&gt; sparkSession.sql(“show databases”).collect().foreach(println)<br />
[default]</p><br />
<br />
<p>scala&gt; sparkSession.sql(“show create  table src”).collect().foreach(println)<br />
[CREATE TABLE <code class="language-plaintext highlighter-rouge">src</code>(<code class="language-plaintext highlighter-rouge">key</code> int, <code class="language-plaintext highlighter-rouge">value</code> string)<br />
ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe’<br />
WITH SERDEPROPERTIES (<br />
  ‘field.delim’ = ‘	‘,<br />
  ‘serialization.format’ = ‘	‘<br />
)<br />
STORED AS<br />
  INPUTFORMAT ‘org.apache.hadoop.mapred.TextInputFormat’<br />
  OUTPUTFORMAT ‘org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat’<br />
TBLPROPERTIES (<br />
  ‘transient_lastDdlTime’ = ‘1515830663’<br />
)<br />
]</p><br />
<br />
<p>hive不支持用insert语句一条一条的进行插入操作，也不支持update操作。数据是以load的方式加载到建立好的表中。数据一旦导入就不可以修改。</p><br />
<br />
<p>DML包括：INSERT插入、UPDATE更新、DELETE删除</p><br />
<br />
<p>scala&gt; sparkSession.sql(“insert into table src key=1234,value=’abc’”).collect().foreach(println)<br />
org.apache.spark.sql.catalyst.parser.ParseException:<br />
no viable alternative at input ‘key’(line 1, pos 22)</p><br />
<br />
<p>== SQL ==<br />
insert into table src key=1234,value=’abc’<br />
———————-^^^</p><br />
<br />
<p>既然Hive没有行级别的数据插入、更新和删除操作，那么往表中装载数据的唯一途径就是使用一种”大量“的数据装载操作。我们以如下格式文件演示五种数据导入Hive方式</p><br />
<br />
<p>Tom         24    NanJing   Nanjing University<br /><br />
Jack        29    NanJing   Southeast China University<br /><br />
Mary Kake   21    SuZhou    Suzhou University<br /><br />
John Doe    24    YangZhou  YangZhou University<br /><br />
Bill King   23    XuZhou    Xuzhou Normal University</p><br />
<br />
<p>数据格式以\t分隔，分别表示：姓名、年龄、地址、学校</p><br />
<br />
<p>一、从本地文件系统中导入数据<br />
 (1) 创建test1测试表<br />
scala&gt; sparkSession.sql(“CREATE TABLE test1(name STRING,age INT, address STRING,school STRING)   ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\t’  STORED AS TEXTFILE”).collect().foreach(println)<br />
18/01/13 16:20:50 WARN metastore.HiveMetaStore: Location: hdfs://localhost:8020/user/hive/warehouse/test1 specified for non-external table:test1<br />
(2) 从本地加载数据 <br />
scala&gt; sparkSession.sql(“ LOAD DATA LOCAL INPATH ‘/Users/didi/hive/testHive.txt’ INTO TABLE test1”).collect().foreach(println) <br />
(3) 查看导入结果<br />
scala&gt; sparkSession.sql(“select * from test1”).collect().foreach(println)<br />
[Tom         24    NanJing   Nanjing University  ,null,null,null]<br />
[Jack        29    NanJing   Southeast China University  ,null,null,null]<br />
[Mary Kake   21    SuZhou    Suzhou University  ,null,null,null]<br />
[John Doe    24    YangZhou  YangZhou University  ,null,null,null]<br />
[Bill King   23    XuZhou    Xuzhou Normal University,null,null,null] <br />
        注意：此处使用的是LOCAL，表示从本地文件系统中加载数据到Hive中，同时没有OVERWRITE关键字，仅仅会把新增的文件增加到目标文件夹而不会删除之前的数据。如果使用OVERWRITE关键字，那么目标文件夹中之前的数据将会被先删除掉。<br />
二、从HDFS文件系统加载数据到Hive<br />
(1) 清空之前创建的表中数据<br />
insert overwrite table test1  select * from test1 where 1=0;  //清空表，一般不推荐这样操作<br /><br />
 (2) 从HDFS加载数据<br />
hive&gt; LOAD DATA INPATH “/input/test1.txt”<br /><br />
    &gt; OVERWRITE INTO TABLE test1;<br /><br />
Loading data to table hive.test1<br /><br />
rmr: DEPRECATED: Please use ‘rm -r’ instead.<br /><br />
Deleted hdfs://secondmgt:8020/hive/warehouse/hive.db/test1<br /><br />
Table hive.test1 stats: [numFiles=1, numRows=0, totalSize=201, rawDataSize=0]<br /><br />
OK<br /><br />
Time taken: 0.355 seconds<br /><br />
 (3) 查询结果<br />
hive&gt; select * from test1;<br /><br />
OK<br /><br />
Tom     24.0    NanJing Nanjing University<br /><br />
Jack    29.0    NanJing Southeast China University<br /><br />
Mary Kake       21.0    SuZhou  Suzhou University<br /><br />
John Doe        24.0    YangZhou        YangZhou University<br /><br />
Bill King       23.0    XuZhou  Xuzhou Normal University<br /><br />
Time taken: 0.054 seconds, Fetched: 5 row(s)<br /><br />
        注意：此处没有LOCAL关键字，表示分布式文件系统中的路径，这就是和第一种方法的主要区别，同时由日志可以发现，因为此处加了OVERWRITE关键字，执行了Deleted操作，即先删除之前存储的数据，然后再执行加载操作。<br />
       同时，INPATH子句中使用的文件路径还有一个限制，那就是这个路径下不可以包含任何文件夹。</p><br />
<br />
<p>三、通过查询语句向表中插入数据<br />
(1) 创建test4测试表<br />
scala&gt; sparkSession.sql(“ CREATE TABLE test4(name STRING,age FLOAT,address STRING,school STRING)   ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\t’ STORED AS TEXTFILE”).collect().foreach(println)<br />
18/01/13 16:27:53 WARN metastore.HiveMetaStore: Location: hdfs://localhost:8020/user/hive/warehouse/test4 specified for non-external table:test4<br />
 创建表过程基本和前面一样，此处不细讲<br />
(2) 从查询结果中导入数据<br />
scala&gt; sparkSession.sql(“INSERT INTO TABLE test4 SELECT * FROM test1”).collect().foreach(println) <br />
        注意：新建表的字段数，一定要和后面SELECT中查询的字段数一样，且要注意数据类型。如test4包含四个字段：name、age、address和school，则SELECT查询出的结果也应该对应这四个字段。<br />
(3) 查看导入结果<br />
scala&gt; sparkSession.sql(“select * from test4”).collect().foreach(println)<br />
[Tom         24    NanJing   Nanjing University  ,null,null,null]<br />
[Jack        29    NanJing   Southeast China University  ,null,null,null]<br />
[Mary Kake   21    SuZhou    Suzhou University  ,null,null,null]<br />
[John Doe    24    YangZhou  YangZhou University  ,null,null,null]<br />
[Bill King   23    XuZhou    Xuzhou Normal University,null,null,null]<br />
四、分区插入<br />
        分区插入有两种，一种是静态分区，另一种是动态分区。如果混合使用静态分区和动态分区，则静态分区必须出现在动态分区之前。现分别介绍这两种分区插入<br />
(1) 静态分区插入</p><br />
<br />
<p>①创建分区表<br />
hive&gt; CREATE TABLE test2(name STRING,address STRING,school STRING)<br /><br />
    &gt; PARTITIONED BY(age float)<br /><br />
    &gt; ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\t’<br /><br />
    &gt; STORED AS TEXTFILE ;<br /><br />
OK<br /><br />
Time taken: 0.144 seconds<br /><br />
       此处创建了一个test2的分区表，以年龄分区</p><br />
<br />
<p>②从查询结果中导入数据    <br /><br />
hive&gt; INSERT INTO  TABLE test2 PARTITION (age=’24’) SELECT * FROM test1;<br /><br />
FAILED: SemanticException [Error 10044]: Line 1:19 Cannot insert into target table because column number/types are different ‘‘24’’: Table insclause-0 has 3 columns, but query has 4 columns.<br /><br />
 此处报了一个错误。是因为test2中是以age分区的，有三个字段，SELECT * 语句中包含有四个字段，所以出错。正确如下：<br />
[html] view plain copy<br />
hive&gt; INSERT INTO  TABLE test2 PARTITION (age=’24’) SELECT name,address,school FROM test1;<br /><br />
 ③ 查看插入结果<br />
hive&gt; select * from test2;<br /><br />
OK<br /><br />
Tom     NanJing Nanjing University      24.0<br /><br />
Jack    NanJing Southeast China University      24.0<br /><br />
Mary Kake       SuZhou  Suzhou University       24.0<br /><br />
John Doe        YangZhou        YangZhou University     24.0<br /><br />
Bill King       XuZhou  Xuzhou Normal University        24.0<br /><br />
Time taken: 0.079 seconds, Fetched: 5 row(s)<br /><br />
 由查询结果可知，每条记录的年龄均为24，插入成功。<br />
(2) 动态分区插入<br />
静态分区需要创建非常多的分区，那么用户就需要写非常多的SQL！Hive提供了一个动态分区功能，其可以基于查询参数推断出需要创建的分区名称。</p><br />
<br />
<p>① 创建分区表，此过程和静态分区创建表一样，此处省略</p><br />
<br />
<p>② 参数设置<br />
hive&gt; set hive.exec.dynamic.partition=true;<br /><br />
hive&gt; set hive.exec.dynamic.partition.mode=nonstrict;<br /><br />
 注意：动态分区默认情况下是没有开启的。开启后，默认是以”严格“模式执行的，在这种模式下要求至少有一列分区字段是静态的。这有助于阻止因设计错误导致查询产生大量的分区。但是此处我们不需要静态分区字段，估将其设为nonstrict。<br />
③ 数据动态插入<br />
hive&gt; insert into table test2 partition (age) select name,address,school,age from test1;<br /><br />
Total jobs = 1<br /><br />
Launching Job 1 out of 1<br /><br />
Number of reduce tasks not specified. Estimated from input data size: 1<br /><br />
In order to change the average load for a reducer (in bytes):<br /><br />
  set hive.exec.reducers.bytes.per.reducer=<number>  <br />
In order to limit the maximum number of reducers:  <br />
  set hive.exec.reducers.max=<number>  <br />
In order to set a constant number of reducers:  <br />
  set mapreduce.job.reduces=<number>  <br />
Starting Job = job_1419317102229_0029, Tracking URL = http://secondmgt:8088/proxy/application_1419317102229_0029/  <br />
Kill Command = /home/hadoopUser/cloud/hadoop/programs/hadoop-2.2.0/bin/hadoop job  -kill job_1419317102229_0029  <br />
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1  <br />
2014-12-28 20:45:07,996 Stage-1 map = 0%,  reduce = 0%  <br />
2014-12-28 20:45:21,488 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.67 sec  <br />
2014-12-28 20:45:32,926 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.32 sec  <br />
MapReduce Total cumulative CPU time: 7 seconds 320 msec  <br />
Ended Job = job_1419317102229_0029  <br />
Loading data to table hive.test2 partition (age=null)  <br />
        Loading partition {age=29.0}  <br />
        Loading partition {age=23.0}  <br />
        Loading partition {age=21.0}  <br />
        Loading partition {age=24.0}  <br />
Partition hive.test2{age=21.0} stats: [numFiles=1, numRows=1, totalSize=35, rawDataSize=34]  <br />
Partition hive.test2{age=23.0} stats: [numFiles=1, numRows=1, totalSize=42, rawDataSize=41]  <br />
Partition hive.test2{age=24.0} stats: [numFiles=1, numRows=2, totalSize=69, rawDataSize=67]  <br />
Partition hive.test2{age=29.0} stats: [numFiles=1, numRows=1, totalSize=40, rawDataSize=39]  <br />
MapReduce Jobs Launched:  <br />
Job 0: Map: 1  Reduce: 1   Cumulative CPU: 7.32 sec   HDFS Read: 415 HDFS Write: 375 SUCCESS  <br />
Total MapReduce CPU Time Spent: 7 seconds 320 msec  <br />
OK  <br />
Time taken: 41.846 seconds  <br />
 注意：查询语句select查询出来的age字段必须放在最后，和分区字段对应，不然结果会出错<br />
④ 查看插入结果<br />
[html] view plain copy<br />
hive&gt; select * from test2;  <br />
OK  <br />
Mary Kake       SuZhou  Suzhou University       21.0  <br />
Bill King       XuZhou  Xuzhou Normal University        23.0  <br />
John Doe        YangZhou        YangZhou University     24.0  <br />
Tom     NanJing Nanjing University      24.0  <br />
Jack    NanJing Southeast China University      29.0  <br />
五、单个查询语句中创建表并加载数据<br />
         在实际情况中，表的输出结果可能太多，不适于显示在控制台上，这时候，将Hive的查询输出结果直接存在一个新的表中是非常方便的，我们称这种情况为CTAS（create table .. as select）<br />
        (1) 创建表<br />
hive&gt; CREATE TABLE test3  <br />
    &gt; AS  <br />
    &gt; SELECT name,age FROM test1;  <br />
Total jobs = 3  <br />
Launching Job 1 out of 3  <br />
Number of reduce tasks is set to 0 since there's no reduce operator  <br />
Starting Job = job_1419317102229_0030, Tracking URL = http://secondmgt:8088/proxy/application_1419317102229_0030/  <br />
Kill Command = /home/hadoopUser/cloud/hadoop/programs/hadoop-2.2.0/bin/hadoop job  -kill job_1419317102229_0030  <br />
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0  <br />
2014-12-28 20:59:59,375 Stage-1 map = 0%,  reduce = 0%  <br />
2014-12-28 21:00:10,795 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.68 sec  <br />
MapReduce Total cumulative CPU time: 2 seconds 680 msec  <br />
Ended Job = job_1419317102229_0030  <br />
Stage-4 is selected by condition resolver.  <br />
Stage-3 is filtered out by condition resolver.  <br />
Stage-5 is filtered out by condition resolver.  <br />
Moving data to: hdfs://secondmgt:8020/hive/scratchdir/hive_2014-12-28_20-59-45_494_6763514583931347886-1/-ext-10001  <br />
Moving data to: hdfs://secondmgt:8020/hive/warehouse/hive.db/test3  <br />
Table hive.test3 stats: [numFiles=1, numRows=5, totalSize=63, rawDataSize=58]  <br />
MapReduce Jobs Launched:  <br />
Job 0: Map: 1   Cumulative CPU: 2.68 sec   HDFS Read: 415 HDFS Write: 129 SUCCESS  <br />
Total MapReduce CPU Time Spent: 2 seconds 680 msec  <br />
OK  <br />
Time taken: 26.583 seconds  <br />
 (2) 查看插入结果<br />
hive&gt; select * from test3;  <br />
OK  <br />
Tom     24.0  <br />
Jack    29.0  <br />
Mary Kake       21.0  <br />
John Doe        24.0  <br />
Bill King       23.0  <br />
Time taken: 0.045 seconds, Fetched: 5 row(s)</number></number></number></p><br />
<br />
<p>Exception in thread “main” java.lang.NoClassDefFoundError: scala/Product$class<br />
	at org.apache.spark.internal.config.ConfigBuilder.<init>(ConfigBuilder.scala:176)<br />
	at org.apache.spark.sql.internal.SQLConf$.buildConf(SQLConf.scala:58)<br />
	at org.apache.spark.sql.internal.SQLConf$.<init>(SQLConf.scala:67)<br />
	at org.apache.spark.sql.internal.SQLConf$.<clinit>(SQLConf.scala)<br />
	at org.apache.spark.sql.internal.StaticSQLConf$.<init>(StaticSQLConf.scala:31)<br />
	at org.apache.spark.sql.internal.StaticSQLConf$.<clinit>(StaticSQLConf.scala)<br />
	at org.apache.spark.sql.SparkSession$Builder.enableHiveSupport(SparkSession.scala:843)<br />
	at main.scala.hiveConnection$.main(hiveConnection.scala:6)<br />
	at main.scala.hiveConnection.main(hiveConnection.scala)</clinit></init></clinit></init></init></p><br />
<br />
<p>在使用Log4j时若提示如下信息：<br />
log4j:WARN No appenders could be found for logger (org.apache.ibatis.logging.LogFactory).<br /><br />
log4j:WARN Please initialize the log4j system properly. <br />
则，解决办法为：在项目的src下面新建file名为log4j.properties文件，内容如下:</p><br />
<br />
<h1 id="configure-logging-for-testing-optionally-with-log-file">Configure logging for testing: optionally with log file</h1><br />
<p>#可以设置级别：debug&gt;info&gt;error<br />
#debug:可以显式debug,info,error<br />
#info:可以显式info,error<br />
#error:可以显式error</p><br />
<br />
<p>log4j.rootLogger=debug,appender1<br />
#log4j.rootLogger=info,appender1<br />
#log4j.rootLogger=error,appender1</p><br />
<br />
<p>#输出到控制台<br />
log4j.appender.appender1=org.apache.log4j.ConsoleAppender<br />
#样式为TTCCLayout<br />
log4j.appender.appender1.layout=org.apache.log4j.TTCCLayout</p><br />
<br />
<p>然后，存盘退出。再次运行程序就会显示Log信息了。</p><br />
<br />
<p>通过配置文件可知，我们需要配置3个方面的内容：<br />
1、根目录（级别和目的地）；<br />
2、目的地（控制台、文件等等）；<br />
3、输出样式。</p><br />
<br />
<p>或者，使用下面的内容也可以：<br />
 # Configure logging for testing: optionally with log file<br />
log4j.rootLogger=WARN, stdout<br />
 # log4j.rootLogger=WARN, stdout, logfile<br />
log4j.appender.stdout=org.apache.log4j.ConsoleAppender<br />
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout<br />
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n<br />
log4j.appender.logfile=org.apache.log4j.FileAppender<br />
log4j.appender.logfile.File=target/spring.log<br />
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout<br />
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</p><br />
<br />

					 <span class='st_sharethis_large' displayText='ShareThis'></span>
						<span class='st_facebook_large' displayText='Facebook'></span>
						<span class='st_twitter_large' displayText='Tweet'></span>
						<span class='st_linkedin_large' displayText='LinkedIn'></span>
						<span class='st_pinterest_large' displayText='Pinterest'></span>
						<span class='st_email_large' displayText='Email'></span>
                </div>
                Category spark
        </div>
	</div>
  
  
       <!--赞-->
    	  <div class="row">
            <div class="col-lg-6">
                <img src="https://xiazemin.github.io/MyBlog/img/webwxgetmsgimg.jpeg"  height="400" width="auto" />
            </div>
          </div>

        <div class="row">
                <div class="col-md-12">
			<div id="disqus_thread"></div>

<div id="gitmentContainer"></div>
<link rel="stylesheet" href="/MyBlog/css/default.css">
<script src="/MyBlog/js/gitment.browser.js"></script>
<script type="text/javascript" src="/MyBlog/js/json2.js"></script>
<script>
var gitment = new Gitment({
    owner: 'xiazemin',
    repo: 'MyBlogComment',
    oauth: {
        client_id: '981ba8c916c262631ea0',
        client_secret: 'a52260ef92de69011ccd1cf355b973ef11d6da0e',
    },
});

var MyGitmentContainer=gitment.render('gitmentContainer');
window.setTimeout(MyGitMentBtnclick,1000); 
//document.ready(function(){ 
//window.onload=function(){}

function MyGitMentBtnclick(){
//var MyGitmentContainer=document.getElementById('gitmentContainer');
	var ele=[],all=MyGitmentContainer.getElementsByTagName("*");
	for(var i=0;i<all.length;i++){
	  if(all[i].className=='gitment-comments-init-btn'){
		MyGitMentBtn=all[i];
		console.log(MyGitMentBtn);
		MyGitMentBtn.click();
	  }
	}
}

</script>



			<!--script>
			/**
			* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
			* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
			*/
			/*
			var disqus_config = function () {
			this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
			this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
			};
			*/
			(function() { // DON'T EDIT BELOW THIS LINE
			var d = document, s = d.createElement('script');

			s.src = '//airrayagroup.disqus.com/embed.js';

			s.setAttribute('data-timestamp', +new Date());
			(d.head || d.body).appendChild(s);
			})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			<script id="dsq-count-scr" src="//airrayagroup.disqus.com/count.js" async></script-->
          </div>
       </div>

</div>
<hr>
     <footer>
        <div class="container">
             <a href="/MyBlog/" style="color: green; font-size: 2em; font-family: 'Schoolbell', cursive;">首页</a>
            <div class="row">
                <div class="col-lg-6">
                    <p>Copyright &copy; 2017 465474307@qq.com <p>
                </div>
                <div class="col-lg-6">
                    <p style="float: right;">Jekyll theme by <a href="https://github.com/xiazemin/">夏泽民</a></p>
                </div>
            </div>
        </div>
    </footer>
	
    <!-- jQuery -->
    <script src="/MyBlog/js/jquery-1.12.0.min.js"></script>
    <script src="/MyBlog/js/jquery-migrate-1.2.1.min.js"></script>

    <!-- Latest compiled and minified JavaScript -->
    <script src="/MyBlog/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
        <!-- Menu Toggle Script -->
    <script>
    $("#menu-toggle").click(function(e) {
        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
    </script>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"6","bdPos":"right","bdTop":"100"},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/MyBlog/shareapi/js/share.js?v=89860593.js?'];</script>


<!-- 2d  -->
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.0.min.js"></script>
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.min.js"></script>
<script type="text/javascript">
 setTimeout(()=> {
/*L2Dwidget.init({"display": {
        "superSample": 2,
        "width": 200,
        "height": 400,
             "position": "right",
                 "hOffset": 0,
        "vOffset": 0
          }
     });
*/
 L2Dwidget
        .on('*', (name) => {
          console.log('%c EVENT ' + '%c -> ' + name, 'background: #222; color: yellow', 'background: #fff; color: #000')
        })
        .init({
          dialog: {
            // 开启对话框
            enable: true,
            script: {
              // 每空闲 10 秒钟，显示一条一言
              'every idle 10s': '$hitokoto$',
              // 当触摸到星星图案
              'hover .star': '星星在天上而你在我心里 (*/ω＼*)',
              // 当触摸到角色身体
              'tap body': '哎呀！别碰我！',
              // 当触摸到角色头部
              'tap face': '人家已经不是小孩子了！'
            }
          }
        });

})
</script>



    <!--html xmlns:wb="http://open.weibo.com/wb">
    <script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
    <wb:follow-button uid="2165491993" type="red_1" width="67" height="24" ></wb:follow-button-->

      <!--本文来自-->
     <script type="text/javascript">
      /* 仅IE
     document.body.oncopy = function(){
        setTimeout( 
            function () { 
        var text =window.clipboardData.getData("text"); 
        if (text) { 
            text = text + "/r/n本篇文章来源于 xiazemin 的 泽民博客|https://xiazemin.github.io/MyBlog/index.html 原文链接："+location.href; clipboardData.setData("text", text); 
          }
       },
     100 )
    }
     */
     //绑定在了body上，也可以绑定在其他可用元素行，但是不是所有元素都支持copy和past事件。

     /*
$(document.body).bind({
    copy: function(event) {//copy事件
        //var cpTxt = "复制的数据";
        var clipboardData = window.clipboardData; //for IE
        if (!clipboardData) { // for chrome
            clipboardData = event.originalEvent.clipboardData;
        }

        if (event.clipboardData != null/false/undefined) { //ignore the incorrectness of the truncation
        clipboarddata = event.clipboardData;
        } else if (window.clipboardData != null/false/undefined) {
         clipboarddata = window.clipboardData;
        } else { //default to the last option even if it is null/false/undefined
         clipboarddata = event.originalEvent.clipboardData;
        }

        //e.clipboardData.getData('text');//可以获取用户选中复制的数据
        //clipboardData.setData('Text', cpTxt);
        alert(clipboarddata.getData('text'));
        //$('#message').text('Copy Data : ' + cpTxt);
        return false;//否则设不生效
    },paste: function(e) {//paste事件
        var eve = e.originalEvent
        var cp = eve.clipboardData;
        var data = null;
        var clipboardData = window.clipboardData; // IE
        if (!clipboardData) { //chrome
            clipboardData = e.originalEvent.clipboardData
        }
        data = clipboardData.getData('Text');
        //$('#message').html(data);
    }
});     
*/
function addLink() {
    var body_element = document.getElementsByTagName('body')[0];
    var selection;
    selection = window.getSelection();
    var pagelink = "<br /><br />本文来源：xiazemin 的 泽民博客 <a href='"+document.location.href+"'>"+document.location.href+"</a>";
//+document.location.href+当前页面链接
    var copy_text = selection + pagelink;
    console.log(copy_text);
    var new_div = document.createElement('div');
    new_div.style.left='-99999px';
    new_div.style.position='absolute';
    body_element.appendChild(new_div );
    new_div.innerHTML = copy_text ;
    selection.selectAllChildren(new_div );
    window.setTimeout(function() {
        body_element.removeChild(new_div );
    },0);
}
document.oncopy = addLink;
     </script>
    <!--本文来自-->

</div>
  </body>

</html>