<!DOCTYPE html>
<html>

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Sci blog jekyll theme">
    <meta name="author" content="AIR RAYA Group">
    <link href='/MyBlog/img/favicon.ico' type='image/icon' rel='shortcut icon'/>

    <title>泽民博客 | Jekyll theme</title>

    <link rel="stylesheet" href="/MyBlog/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
    <link rel="stylesheet" href="/MyBlog/css/font-awesome.min.css">
    <link href="/MyBlog/css/simple-sidebar.css" rel="stylesheet">
	<link href="/MyBlog/css/classic-10_7.css" rel="stylesheet" type="text/css">
    <!-- Custom CSS -->
    <link href="/MyBlog/css/style.css" rel="stylesheet">
    <link href="/MyBlog/css/pygments.css" rel="stylesheet">
    <!-- Fonts -->
 <link href="/MyBlog/css/front.css" rel="stylesheet" type="text/css">
 <link href="/MyBlog/css/Josefin_Slab.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Architects_Daughter.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Schoolbell.css" rel="stylesheet" type="text/css">
<link href="/MyBlog/css/Codystar.css" rel="stylesheet" type="text/css">

 <script type="text/javascript" src="/MyBlog/js/jquery-1.12.0.min.js"></script>	

<link href="/MyBlog/css/calendar/common.css" type="text/css"  rel="stylesheet">
<script type="text/javascript" src="/MyBlog/js/calendar/calendar.js"></script>
	<!-- share this -->
	<script type="text/javascript">var switchTo5x=true;</script>
	<script type="text/javascript" src="/MyBlog/js/buttons.js"></script>
	<script type="text/javascript">stLight.options({publisher: "b28464c3-d287-4257-ad18-058346dd35f7", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="/MyBlog/js/html5shiv.js"></script>
        <script src="/MyBlog/js/respond.min.js"></script>
    <![endif]-->
   
   <!--百度统计-->
    <script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e965cab8c73512b8b23939e7051d93bd";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
    })();
    </script>
    <script async src="/MyBlog/katex/katex.js"></script>
    <link rel="stylesheet" href="/MyBlog/katex/katex.css">

    <!--轮播图片-->
    <!--script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="https://xiazemin.github.io/MyBlog/js/jquery.stripesrotator.js"></script>
    <script type="text/javascript">
                    $(document).ready(function() {
                    alert($('#rotator_xzm'));
                     alert($('#rotator_xzm').fn);
                    $('#rotator_xzm').stripesRotator({ images: [ "https://xiazemin.github.io/MyBlog/img/BPlusTree.png", "https://xiazemin.github.io/MyBlog/img/linuxMMap.jpeg"] });
                    });
    </script-->

    <!--水印-->
    <script type="text/javascript" src="/MyBlog/js/waterMark.js"></script>
    <script type="text/javascript">
    $(document).ready(function(){
    watermark({watermark_txt0:'泽民博客',watermark_txt1:'zemin',watermark_txt2:(new Date()).Format("yyyy-MM-dd hh:mm:ss.S")});
    })
    </script>
     <!--水印-->
     <!--adscene-->
    <script data-ad-client="ca-pub-6672721494777557" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

</head>

 <body>
<div id="wrapper">
 <!-- Navigation -->
    <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="/MyBlog">
                        Home
                    </a>
                </li>
                <li>
                    <a href="#">About</a>
                </li>
                <li>
                    <a href="#">Services</a>
                </li>
                <li>
                    <a href="#">Portfolio</a>
                </li>
                <li>
                    <a href="#">Events</a>
                </li>
                <li>
                    <a href="#">Blog</a>
                </li>
                <li>
                    <a href="#">FAQ</a>
                </li>
                <li>
                    <a href="#">Contact</a>
                </li>
            </ul>
        </div>


    <header class="intro-header">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <div class="heading text-center">
                        <a href="https://xiazemin.github.io/MyBlog/" style="color: #fff; font-size: 4em; font-family: 'Schoolbell', cursive;">泽民博客</a>
                        <a href="#menu-toggle" class="btn btn-default sciblog" id="menu-toggle" style="font-weight: bold;">&#9776; Menu</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

     <script async src="/MyBlog/js/busuanzi.pure.mini.js"></script>

    <script type="text/javascript" src="/MyBlog/js/jquery.js"></script>
    <script type="text/javascript" src="/MyBlog/js/jquery.stripesrotator.js"></script>


 <div class="container">
	<div class="row">
        <div class="box">
                <div class="col-lg-12">
                    <div class="intro-text text-center">
					<h1 class="post-title" itemprop="name headline">索引原理分析</h1>
					<p class="post-meta"> <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">by 夏泽民</span></span> <time datetime="2018-11-18T00:00:00+08:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Nov 18, 2018</time></p>
					</div>
					 <p>Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎,一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎.当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:</p><br />
<br />
<p>分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。<br />
实时分析的分布式搜索引擎。<br />
可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。<br />
基本概念<br />
先说Elasticsearch的文件存储，Elasticsearch是面向文档型数据库，一条数据在这里就是一个文档，用JSON作为文档序列化的格式，比如下面这条用户数据：</p><br />
<br />
<p>{<br />
    “name” :     “John”,<br />
    “sex” :      “Male”,<br />
    “age” :      25,<br />
    “birthDate”: “1990/05/01”,<br />
    “about” :    “I love to go rock climbing”,<br />
    “interests”: [ “sports”, “music” ]<br />
}<br />
用Mysql这样的数据库存储就会容易想到建立一张User表，有balabala的字段等，在Elasticsearch里这就是一个文档，当然这个文档会属于一个User的类型，各种各样的类型存在于一个索引当中。这里有一份简易的将Elasticsearch和关系型数据术语对照表:</p><br />
<br />
<p>关系数据库     ⇒ 数据库 ⇒ 表    ⇒ 行    ⇒ 列(Columns)</p><br />
<br />
<p>Elasticsearch  ⇒ 索引(Index)   ⇒ 类型(type)  ⇒ 文档(Docments)  ⇒ 字段(Fields)<br /><br />
一个 Elasticsearch 集群可以包含多个索引(数据库)，也就是说其中包含了很多类型(表)。这些类型中包含了很多的文档(行)，然后每个文档中又包含了很多的字段(列)。Elasticsearch的交互，可以使用Java API，也可以直接使用HTTP的Restful API方式，比如我们打算插入一条记录，可以简单发送一个HTTP的请求：</p><br />
<br />
<p>PUT /megacorp/employee/1<br /><br />
{<br />
    “name” :     “John”,<br />
    “sex” :      “Male”,<br />
    “age” :      25,<br />
    “about” :    “I love to go rock climbing”,<br />
    “interests”: [ “sports”, “music” ]<br />
}<br />
<!-- more --><br />
索引<br />
Elasticsearch最关键的就是提供强大的索引能力了<br />
Elasticsearch索引的精髓：</p><br />
<br />
<p>一切设计都是为了提高搜索的性能</p><br />
<br />
<p>另一层意思：为了提高搜索的性能，难免会牺牲某些其他方面，比如插入/更新，否则其他数据库不用混了。前面看到往Elasticsearch里插入一条记录，其实就是直接PUT一个json的对象，这个对象有多个fields，比如上面例子中的name, sex, age, about, interests，那么在插入这些数据到Elasticsearch的同时，Elasticsearch还默默1的为这些字段建立索引–倒排索引，因为Elasticsearch最核心功能是搜索。<br />
Elasticsearch是如何做到快速索引的<br />
二叉树查找效率是logN，同时插入新的节点不必移动全部节点，所以用树型结构存储索引，能同时兼顾插入和查询的性能。因此在这个基础上，再结合磁盘的读取特性(顺序读/随机读)，传统关系型数据库采用了B-Tree/B+Tree这样的数据结构：<br />
为了提高查询的效率，减少磁盘寻道次数，将多个值作为一个数组通过连续区间存放，一次寻道读取多个数据，同时也降低树的高度。</p><br />
<br />
<p>什么是倒排索引?<br />
Alt text</p><br />
<br />
<p>继续上面的例子，假设有这么几条数据(为了简单，去掉about, interests这两个field):</p><br />
<br />
<p>| ID | Name | Age  |  Sex     |<br />
| – |:————:| —–:| —–:| <br />
| 1  | Kate         | 24 | Female<br />
| 2  | John         | 24 | Male<br />
| 3  | Bill         | 29 | Male<br />
ID是Elasticsearch自建的文档id，那么Elasticsearch建立的索引如下:</p><br />
<br />
<p>Name:</p><br />
<br />
<p>| Term | Posting List |<br />
| – |:—-:|<br />
| Kate | 1 |<br />
| John | 2 |<br />
| Bill | 3 |<br />
Age:</p><br />
<br />
<p>| Term | Posting List |<br />
| – |:—-:|<br />
| 24 | [1,2] |<br />
| 29 | 3 |<br />
Sex:</p><br />
<br />
<p>| Term | Posting List |<br />
| – |:—-:|<br />
| Female | 1 |<br />
| Male | [2,3] |<br />
Posting List<br />
Elasticsearch分别为每个field都建立了一个倒排索引，Kate, John, 24, Female这些叫term，而[1,2]就是Posting List。Posting list就是一个int的数组，存储了所有符合某个term的文档id。</p><br />
<br />
<p>看到这里，不要认为就结束了，精彩的部分才刚开始…</p><br />
<br />
<p>通过posting list这种索引方式似乎可以很快进行查找，比如要找age=24的同学，爱回答问题的小明马上就举手回答：我知道，id是1，2的同学。但是，如果这里有上千万的记录呢？如果是想通过name来查找呢？</p><br />
<br />
<p>Term Dictionary<br />
Elasticsearch为了能快速找到某个term，将所有的term排个序，二分法查找term，logN的查找效率，就像通过字典查找一样，这就是Term Dictionary。现在再看起来，似乎和传统数据库通过B-Tree的方式类似啊，为什么说比B-Tree的查询快呢？</p><br />
<br />
<p>Term Index<br />
B-Tree通过减少磁盘寻道次数来提高查询性能，Elasticsearch也是采用同样的思路，直接通过内存查找term，不读磁盘，但是如果term太多，term dictionary也会很大，放内存不现实，于是有了Term Index，就像字典里的索引页一样，A开头的有哪些term，分别在哪页，可以理解term index是一颗树：<br />
这棵树不会包含所有的term，它包含的是term的一些前缀。通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找。<br />
	<img src="https://xiazemin.github.io/MyBlog/img/Termindex.png" /><br />
所以term index不需要存下所有的term，而仅仅是他们的一些前缀与Term Dictionary的block之间的映射关系，再结合FST(Finite State Transducers)的压缩技术，可以使term index缓存到内存中。从term index查到对应的term dictionary的block位置之后，再去磁盘上找term，大大减少了磁盘随机读的次数<br />
FSTs are finite-state machines that map a term (byte sequence) to an arbitrary output.</p><br />
<br />
<p>假设我们现在要将mop, moth, pop, star, stop and top(term index里的term前缀)映射到序号：0，1，2，3，4，5(term dictionary的block位置)。最简单的做法就是定义个Map&lt;string, integer=””&gt;，大家找到自己的位置对应入座就好了，但从内存占用少的角度想想，有没有更优的办法呢？答案就是：FST<br />
压缩技巧<br />
Elasticsearch里除了上面说到用FST压缩term index外，对posting list也有压缩技巧。<br />
首先，Elasticsearch要求posting list是有序的(为了提高搜索的性能，再任性的要求也得满足)，这样做的一个好处是方便压缩，原理就是通过增量，将原来的大数变成小数仅存储增量值，再精打细算按bit排好队，最后通过字节存储，而不是大大咧咧的尽管是2也是用int(4个字节)来存储。</p><br />
<br />
<p>Roaring bitmaps<br />
说到Roaring bitmaps，就必须先从bitmap说起。Bitmap是一种数据结构，假设有某个posting list：</p><br />
<br />
<p>[1,3,4,7,10]</p><br />
<br />
<p>对应的bitmap就是：</p><br />
<br />
<p>[1,0,1,1,0,0,1,0,0,1]</p><br />
<br />
<p>非常直观，用0/1表示某个值是否存在，比如10这个值就对应第10位，对应的bit值是1，这样用一个字节就可以代表8个文档id，旧版本(5.0之前)的Lucene就是用这样的方式来压缩的，但这样的压缩方式仍然不够高效，如果有1亿个文档，那么需要12.5MB的存储空间，这仅仅是对应一个索引字段(我们往往会有很多个索引字段)。于是有人想出了Roaring bitmaps这样更高效的数据结构。</p><br />
<br />
<p>Bitmap的缺点是存储空间随着文档个数线性增长，Roaring bitmaps需要打破这个魔咒就一定要用到某些指数特性：</p><br />
<br />
<p>将posting list按照65535为界限分块，比如第一块所包含的文档id范围在0~65535之间，第二块的id范围是65536~131071，以此类推。再用&lt;商，余数&gt;的组合表示每一组id，这样每组里的id范围都在0~65535内了，剩下的就好办了，既然每组id不会变得无限大，那么我们就可以通过最有效的方式对这里的id存储。<br />
65535也是一个经典值，因为它=2^16-1，正好是用2个字节能表示的最大数，一个short的存储单位，注意到上图里的最后一行“If a block has more than 4096 values, encode as a bit set, and otherwise as a simple array using 2 bytes per value”，如果是大块，用节省点用bitset存，小块就豪爽点，2个字节我也不计较了，用一个short[]存着方便。</p><br />
<br />
<p>那为什么用4096来区分大块还是小块呢？</p><br />
<br />
<p>个人理解：都说程序员的世界是二进制的，4096*2bytes ＝ 8192bytes &lt; 1KB, 磁盘一次寻道可以顺序把一个小块的内容都读出来，再大一位就超过1KB了，需要两次读。<br />
上面说了半天都是单field索引，如果多个field索引的联合查询，倒排索引如何满足快速查询的要求呢？</p><br />
<br />
<p>利用跳表(Skip list)的数据结构快速做“与”运算，或者<br />
利用上面提到的bitset按位“与”<br />
先看看跳表的数据结构：<br />
将一个有序链表level0，挑出其中几个元素到level1及level2，每个level越往上，选出来的指针元素越少，查找时依次从高level往低查找，比如55，先找到level2的31，再找到level1的47，最后找到55，一共3次查找，查找效率和2叉树的效率相当，但也是用了一定的空间冗余来换取的。<br />
假设有下面三个posting list需要联合索引<br />
如果使用跳表，对最短的posting list中的每个id，逐个在另外两个posting list中查找看是否存在，最后得到交集的结果。</p><br />
<br />
<p>如果使用bitset，就很直观了，直接按位与，得到的结果就是最后的交集。<br />
将磁盘里的东西尽量搬进内存，减少磁盘随机读取次数(同时也利用磁盘顺序读特性)，结合各种奇技淫巧的压缩算法，用及其苛刻的态度使用内存。</p><br />
<br />
<p>所以，对于使用Elasticsearch进行索引时需要注意:</p><br />
<br />
<p>不需要索引的字段，一定要明确定义出来，因为默认是自动建索引的<br />
同样的道理，对于String类型的字段，不需要analysis的也需要明确定义出来，因为默认也是会analysis的<br />
选择有规律的ID很重要，随机性太大的ID(比如java的UUID)不利于查询<br />
关于最后一点，个人认为有多个因素:</p><br />
<br />
<p>其中一个(也许不是最重要的)因素: 上面看到的压缩算法，都是对Posting list里的大量ID进行压缩的，那如果ID是顺序的，或者是有公共前缀等具有一定规律性的ID，压缩比会比较高；</p><br />
<br />
<p>另外一个因素: 可能是最影响查询性能的，应该是最后通过Posting list里的ID到磁盘中查找Document信息的那步，因为Elasticsearch是分Segment存储的，根据ID这个大范围的Term定位到Segment的效率直接影响了最后查询的性能，如果ID是有规律的，可以快速跳过不包含该ID的Segment，从而减少不必要的磁盘读次数<br />
当我们不需要支持快速的更新的时候，可以用预先排序等方式换取更小的存储空间，更快的检索速度等好处，其代价就是更新慢。<br />
这样我们可以用二分查找的方式，比全遍历更快地找出目标的 term。这个就是 term dictionary。有了 term dictionary 之后，可以用 logN 次磁盘查找得到目标。但是磁盘的随机读操作仍然是非常昂贵的（一次 random access 大概需要 10ms 的时间）。所以尽量少的读磁盘，有必要把一些数据缓存到内存里。但是整个 term dictionary 本身又太大了，无法完整地放到内存里。于是就有了 term index。term index 有点像一本字典的大的章节表。<br />
为什么 Elasticsearch/Lucene 检索可以比 mysql 快了。Mysql 只有 term dictionary 这一层，是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次的 random access 的磁盘操作。而 Lucene 在 term dictionary 的基础上添加了 term index 来加速检索，term index 以树的形式缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access 次数。</p><br />
<br />
<p>如果所有的 term 都是英文字符的话，可能这个 term index 就真的是 26 个英文字符表构成的了。但是实际的情况是，term 未必都是英文字符，term 可以是任意的 byte 数组。而且 26 个英文字符也未必是每一个字符都有均等的 term，比如 x 字符开头的 term 可能一个都没有，而 s 开头的 term 又特别多。实际的 term index 是一棵 trie 树：</p><br />
<br />
<p>例子是一个包含 “A”, “to”, “tea”, “ted”, “ten”, “i”, “in”, 和 “inn” 的 trie 树。这棵树不会包含所有的 term，它包含的是 term 的一些前缀。通过 term index 可以快速地定位到 term dictionary 的某个 offset，然后从这个位置再往后顺序查找。再加上一些压缩技术（搜索 Lucene Finite State Transducers） term index 的尺寸可以只有所有 term 的尺寸的几十分之一，使得用内存缓存整个 term index 变成可能。整体上来说就是这样的效果。</p><br />
<br />
<p>现在我们可以回答“为什么 Elasticsearch/Lucene 检索可以比 mysql 快了。Mysql 只有 term dictionary 这一层，是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次的 random access 的磁盘操作。而 Lucene 在 term dictionary 的基础上添加了 term index 来加速检索，term index 以树的形式缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access 次数。</p><br />
<br />
<p>额外值得一提的两点是：term index 在内存中是以 FST（finite state transducers）的形式保存的，其特点是非常节省内存。Term dictionary 在磁盘上是以分 block 的方式保存的，一个 block 内部利用公共前缀压缩，比如都是 Ab 开头的单词就可以把 Ab 省去。这样 term dictionary 可以比 b-tree 更节约磁盘空间。</p><br />
<br />
<p>如何联合索引查询？<br />
所以给定查询过滤条件 age=18 的过程就是先从 term index 找到 18 在 term dictionary 的大概位置，然后再从 term dictionary 里精确地找到 18 这个 term，然后得到一个 posting list 或者一个指向 posting list 位置的指针。然后再查询 gender= 女 的过程也是类似的。最后得出 age=18 AND gender= 女 就是把两个 posting list 做一个“与”的合并。</p><br />
<br />
<p>这个理论上的“与”合并的操作可不容易。对于 mysql 来说，如果你给 age 和 gender 两个字段都建立了索引，查询的时候只会选择其中最 selective 的来用，然后另外一个条件是在遍历行的过程中在内存中计算之后过滤掉。那么要如何才能联合使用两个索引呢？有两种办法：</p><br />
<br />
<p>使用 skip list 数据结构。同时遍历 gender 和 age 的 posting list，互相 skip；<br />
使用 bitset 数据结构，对 gender 和 age 两个 filter 分别求出 bitset，对两个 bitset 做 AN 操作。<br />
PostgreSQL 从 8.4 版本开始支持通过 bitmap 联合使用两个索引，就是利用了 bitset 数据结构来做到的。当然一些商业的关系型数据库也支持类似的联合索引的功能。Elasticsearch 支持以上两种的联合索引方式，如果查询的 filter 缓存到了内存中（以 bitset 的形式），那么合并就是两个 bitset 的 AND。如果查询的 filter 没有缓存，那么就用 skip list 的方式去遍历两个 on disk 的 posting list。</p><br />
<br />
<p>利用 Skip List 合并<br />
以上是三个 posting list。我们现在需要把它们用 AND 的关系合并，得出 posting list 的交集。首先选择最短的 posting list，然后从小到大遍历。遍历的过程可以跳过一些元素，比如我们遍历到绿色的 13 的时候，就可以跳过蓝色的 3 了，因为 3 比 13 要小。</p><br />
<br />
<p>利用 bitset 合并<br />
Bitset 是一种很直观的数据结构，对应 posting list 如：</p><br />
<br />
<p>[1,3,4,7,10]</p><br />
<br />
<p>对应的 bitset 就是：</p><br />
<br />
<p>[1,0,1,1,0,0,1,0,0,1]</p><br />
<br />
<p>每个文档按照文档 id 排序对应其中的一个 bit。Bitset 自身就有压缩的特点，其用一个 byte 就可以代表 8 个文档。所以 100 万个文档只需要 12.5 万个 byte。但是考虑到文档可能有数十亿之多，在内存里保存 bitset 仍然是很奢侈的事情。而且对于个每一个 filter 都要消耗一个 bitset，比如 age=18 缓存起来的话是一个 bitset，18&lt;=age&lt;25 是另外一个 filter 缓存起来也要一个 bitset。</p><br />
<br />
<p>所以秘诀就在于需要有一个数据结构：</p><br />
<br />
<p>可以很压缩地保存上亿个 bit 代表对应的文档是否匹配 filter；<br />
这个压缩的 bitset 仍然可以很快地进行 AND 和 OR 的逻辑操作。<br />
Lucene 使用的这个数据结构叫做 Roaring Bitmap。</p><br />
<br />
<p>其压缩的思路其实很简单。与其保存 100 个 0，占用 100 个 bit。还不如保存 0 一次，然后声明这个 0 重复了 100 遍。</p><br />
<br />
<p>这两种合并使用索引的方式都有其用途。Elasticsearch 对其性能有详细的对比（https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps）。简单的结论是：因为 Frame of Reference 编码是如此 高效，对于简单的相等条件的过滤缓存成纯内存的 bitset 还不如需要访问磁盘的 skip list 的方式要快。</p><br />
<br />
<p>如何减少文档数？<br />
一种常见的压缩存储时间序列的方式是把多个数据点合并成一行。Opentsdb 支持海量数据的一个绝招就是定期把很多行数据合并成一行，这个过程叫 compaction。类似的 vivdcortext 使用 mysql 存储的时候，也把一分钟的很多数据点合并存储到 mysql 的一行里以减少行数。<br />
在存储的时候，无论父文档还是子文档，对于 Lucene 来说都是文档，都会有文档 Id。但是对于嵌套文档来说，可以保存起子文档和父文档的文档 id 是连续的，而且父文档总是最后一个。有这样一个排序性作为保障，那么有一个所有父文档的 posting list 就可以跟踪所有的父子关系。也可以很容易地在父子文档 id 之间做转换。把父子关系也理解为一个 filter，那么查询时检索的时候不过是又 AND 了另外一个 filter 而已。前面我们已经看到了 Elasticsearch 可以非常高效地处理多 filter 的情况，充分利用底层的索引。</p><br />
<br />
<p>使用了嵌套文档之后，对于 term 的 posting list 只需要保存父文档的 doc id 就可以了，可以比保存所有的数据点的 doc id 要少很多。如果我们可以在一个父文档里塞入 50 个嵌套文档，那么 posting list 可以变成之前的 1/50。</p><br />
<br />
<p>倒排索引是由段（Segment）组成的，段存储在硬盘（Disk）文件中。索引段不是实时更新的，这意味着，段在写入硬盘之后，就不再被更新。在删除文档时，ElasticSearch引擎把已删除的文档的信息存储在一个单独的文件中，在搜索数据时，ElasticSearch引擎首先从段中执行查询，再从查询结果中过滤被删除的文档，这意味着，段中存储着被删除的文档，这使得段中含有”正常文档“的密度降低。多个段可以通过段合并（Segment Merge）操作把“已删除”的文档将从段中物理删除，把未删除的文档合并到一个新段中，新段中没有”已删除文档“，因此，段合并操作能够提高索引的查找速度，但是，段合并是IO密集型操作，需要消耗大量的硬盘IO。</p><br />
<br />
<p>在ElasticSearch中，大多数查询都需要从硬盘文件（索引的段数据存储在硬盘文件中）中获取数据，因此，在全局配置文件elasticsearch.yml 中，把结点的路径（Path）配置为性能较高的硬盘，能够提高查询性能。默认情况下，ElasticSearch使用基于安装目录的相对路径来配置结点的路径，安装目录由属性path.home显示，在home path下，ElasticSearch自动创建config，data，logs和plugins目录，一般情况下不需要对结点路径单独配置。结点的文件路径配置项：</p><br />
<br />
<p>path.data：设置ElasticSearch结点的索引数据保存的目录，多个数据文件使用逗号隔开，例如，path.data: /path/to/data1,/path/to/data2；<br />
path.work：设置ElasticSearch的临时文件保存的目录；<br />
2，分词和原始文本的存储</p><br />
<br />
<p>映射参数index决定ElasticSearch引擎是否对文本字段执行分析操作，也就是说分析操作把文本分割成一个一个的分词，也就是标记流（Token Stream），把分词编入索引，使分词能够被搜索到：</p><br />
<br />
<p>当index为analyzed时，该字段是分析字段，ElasticSearch引擎对该字段执行分析操作，把文本分割成分词流，存储在倒排索引中，使其支持全文搜索；<br />
当index为not_analyzed时，该字段不会被分析，ElasticSearch引擎把原始文本作为单个分词存储在倒排索引中，不支持全文搜索，但是支持词条级别的搜索；也就是说，字段的原始文本不经过分析而存储在倒排索引中，把原始文本编入索引，在搜索的过程中，查询条件必须全部匹配整个原始文本；<br />
当index为no时，该字段不会被存储到倒排索引中，不会被搜索到；<br />
字段的原始值是否被存储到倒排索引，是由映射参数store决定的，默认值是false，也就是，原始值不存储到倒排索引中。</p><br />
<br />
<p>映射参数index和store的区别在于：</p><br />
<br />
<p>store用于获取（Retrieve）字段的原始值，不支持查询，可以使用投影参数fields，对stroe属性为true的字段进行过滤，只获取（Retrieve）特定的字段，减少网络负载；<br />
index用于查询（Search）字段，当index为analyzed时，对字段的分词执行全文查询；当index为not_analyzed时，字段的原始值作为一个分词，只能对字段的原始文本执行词条查询；<br />
3，单个分词的最大长度</p><br />
<br />
<p>如果设置字段的index属性为not_analyzed，原始文本将作为单个分词，其最大长度跟UTF8 编码有关，默认的最大长度是32766Bytes，如果字段的文本超过该限制，那么ElasticSearch将跳过（Skip）该文档，并在Response中抛出异常消息<br />
列式存储（doc_values）</p><br />
<br />
<p>默认情况下，大多数字段被索引之后，能够被搜索到。倒排索引是由一个有序的词条列表构成的，每一个词条在列表中都是唯一存在的，通过这种数据存储模式，你可以很快查找到包含某一个词条的文档列表。但是，排序和聚合操作采用相反的数据访问模式，这两种操作不是查找词条以发现文档，而是查找文档，以发现字段中包含的词条。ElasticSearch使用列式存储实现排序和聚合查询。</p><br />
<br />
<p>文档值（doc_values）是存储在硬盘上的数据结构，在索引时（index time）根据文档的原始值创建，文档值是一个列式存储风格的数据结构，非常适合执行存储和聚合操作，除了字符类型的分析字段之外，其他字段类型都支持文档值存储。默认情况下，字段的文档值存储是启用的，除了字符类型的分析字段之外。如果不需要对字段执行排序或聚合操作，可以禁用字段的文档值，以节省硬盘空间。<br />
顺排索引（fielddata）</p><br />
<br />
<p>字符类型的分析字段，不支持文档值（doc_values），但是，支持fielddata数据结构，fielddata数据结构存储在JVM的堆内存中。相比文档值（数据存储在硬盘上），fielddata字段（数据存储在内存中）的查询性能更高。默认情况下，ElasticSearch引擎在第一次对字段执行聚合或排序查询时（（query-time）），创建fielddata数据结构；在后续的查询请求中，ElasticSearch引擎使用fielddata数据结构以提高聚合和排序的查询性能。</p><br />
<br />
<p>在ElasticSearch中，倒排索引的各个段（segment）的数据存储在硬盘文件上，从整个倒排索引的段中读取字段数据之后，ElasticSearch引擎首先反转词条和文档之间的关系，创建文档和词条之间的关系，即创建顺排索引，然后把顺排索引存储在JVM的堆内存中。把倒排索引加载到fielddata结构是一个非常消耗硬盘IO资源的过程，因此，数据一旦被加载到内存，最好保持在内存中，直到索引段(segment)的生命周期结束。默认情况下，倒排索引的每个段(segment)，都会创建相应的fielddata结构，以存储字符类型的分析字段值，但是，需要注意的是，分配的JVM堆内存是有限的，Fileddata把数据存储在内存中，会占用过多的JVM堆内存，甚至耗尽JVM赖以正常运行的内存空间，反而会降低ElasticSearch引擎的查询性能。</p><br />
<br />
<p>Elasticsearch 的数据存储方式：<br />
Lucene 把每次生成的倒排索引，叫做一个段(segment).然后另外使用一个 commit 文件记录索引内所有的 segment，生成 segment 的数据来源，refresh到内存中的 buffer。<br />
从写入refresh到文件缓存buffer中默认设置为 1 秒。</p><br />
<br />
<p>Elasticsearch 在把数据写入到内存 buffer 的同时，其实还另外记录了一个 translog 日志。通过translog 日志真正把 segment 刷到磁盘，同时commit 文件进行更新，然后translog 文件才清空。这</p><br />
<br />
<p>一步，叫做 flush。默认设置为：每 30 分钟主动进行一次 flush。</p><br />
<br />
<p>上述两个过程保证数据实时查询和持久化数据。</p><br />
<br />
<p>注：5.0 中还提供了一个新的请求参数：?refresh=wait_for，可以在写入数据后不强制刷新但一直等到刷新才返回。对于日志记录，可以等到时间缓冲后再刷新，不需要保证实时，”refresh_interval”:</p><br />
<br />
<p>“10s”；对于归档的数据导入时，可以先设置”refresh_interval”: “-1”关闭刷新，导入完后手动刷新即可。</p><br />
<br />
<p>注：为了减小系统开销，小的segment归并成大的segment再提交保存。segment 归并的过程，需要先读取 segment，归并计算，再写一遍 segment，最后还要保证刷到磁盘。5.0后引入Lucene的CMS自动调</p><br />
<br />
<p>整机制，默认设置是 10240 MB；封装了”indices.store.throttle.max_bytes_per_sec” 该配置，不需要再设置。归并线程保持默认即可。index.merge.scheduler.max_thread_count=3</p><br />
<br />
<p>归并策略优化：<br />
index.merge.policy.floor_segment 默认 2MB，小于这个大小的 segment，优先被归并。<br />
index.merge.policy.max_merge_at_once 默认一次最多归并 10 个 segment<br />
index.merge.policy.max_merge_at_once_explicit 默认 forcemerge 时一次最多归并 30 个 segment。<br />
index.merge.policy.max_merged_segment 默认 5 GB，大于这个大小的 segment，不用参与归并。forcemerge 除外。<br />
其实我们也可以从另一个角度考虑如何减少 segment 归并的消耗以及提高响应的办法：加大 flush 间隔，尽量让每次新生成的 segment 本身大小就比较大。</p><br />
<br />
<p>路由：<br />
shard = hash(routing) % number_of_primary_shards  routing参数：_id</p><br />
<br />
<p>集群管理：<br />
1.节点下线<br />
Elasticsearch 集群就会自动把这个 IP 上的所有分片，都自动转移到其他节点上。等到转移完成，这个空节点就可以毫无影响的下线了。<br />
curl -XPUT 127.0.0.1:9200/_cluster/settings -d ‘{<br />
  “transient” :{<br />
      “cluster.routing.allocation.exclude._ip” : “10.0.0.1”<br />
   }<br />
}’</p><br />
<br />
<p>2.迁移分片<br />
例如负载过高，使用reroute接口下的指令。常用的一般是 allocate 和 move<br />
从 5.0 版本开始，Elasticsearch 新增了一个 allocation explain 接口，专门用来解释指定分片的具体失败理由</p><br />
<br />
<p>3.冷热数据的读写分离<br />
N 台机器做热数据的存储, 上面只放当天的数据。这 N 台热数据节点上面的 elasticsearc.yml 中配置 node.tag: hot；之前的数据放在另外的 M 台机器上。这 M 台冷数据节点中配置 node.tag:</p><br />
<br />
<p>stale<br />
模板中控制对新建索引添加 hot 标签：<br />
    {<br />
     “order” : 0,<br />
     “template” : “*”,<br />
     “settings” : {<br />
       “index.routing.allocation.require.tag” : “hot”<br />
     }<br />
    }<br />
每天计划任务更新索引的配置, 将 tag 更改为 stale, 索引会自动迁移到 M 台冷数据节点<br />
    # curl -XPUT http://127.0.0.1:9200/indexname/_settings -d’<br />
    {<br />
    “index”: {<br />
       “routing”: {<br />
          “allocation”: {<br />
             “require”: {<br />
                “tag”: “stale”<br />
             }<br />
          }<br />
      }<br />
    }<br />
    }’<br />
这样，写操作集中在 N 台热数据节点上，大范围的读操作集中在 M 台冷数据节点上。避免了堵塞影响。</p><br />
<br />
<ol><br />
  <li>检测参数优化<br />
discovery.zen.minimum_master_nodes: 3<br />
discovery.zen.ping_timeout: 100s    //参数仅在加入或者选举 master 主节点的时候才起作用<br />
discovery.zen.fd.ping_timeout: 100s  // fd故障检测参数则在稳定运行的集群中，master 检测所有节点，以及节点检测 master 是否畅通时长期有用。<br />
discovery.zen.fd.ping_interval: 10s  //间隔<br />
discovery.zen.fd.ping_retries: 10    //重试次数<br />
discovery.zen.ping.unicast.hosts: [“10.19.0.97”,”10.19.0.98”,”10.19.0.99”,”10.19.0.100”]  //unicast 单播</li><br />
</ol><br />
<br />
<p>5.磁盘限额：<br />
cluster.routing.allocation.disk.watermark.low (默认 85%)<br />
cluster.routing.allocation.disk.watermark.high (默认 90%)</p><br />
<br />
<p>每个节点的分片数，需要把故障迁移问题考虑进去<br />
“routing.allocation.total_shards_per_node” : “5”   //需要在创建时考虑</p><br />
<br />
<p>6.在线缩容<br />
从 5.0 版本开始，Elasticsearch 新提供了 shrink 接口，可以成倍数的合并分片数。</p><br />
<br />
<p>7.过滤器<br />
Ingest 节点是 Elasticsearch 5.0 新增的节点类型和功能。节点接收到数据之后，根据请求参数中指定的管道流 id，找到对应的已注册管道流，对数据进行处理，然后将处理过后的数据，按照</p><br />
<br />
<p>Elasticsearch 标准的 indexing 流程继续运行。</p><br />
<br />
<p>8.通过监控任务，check集群健康<br />
curl -XGET ‘localhost:9200/_cat/tasks?v’</p><br />
<br />
<p>9.支持chef、ansible、puppet自动化部署</p><br />

					 <span class='st_sharethis_large' displayText='ShareThis'></span>
						<span class='st_facebook_large' displayText='Facebook'></span>
						<span class='st_twitter_large' displayText='Tweet'></span>
						<span class='st_linkedin_large' displayText='LinkedIn'></span>
						<span class='st_pinterest_large' displayText='Pinterest'></span>
						<span class='st_email_large' displayText='Email'></span>
                </div>
                Category elasticsearch
        </div>
	</div>
  
  
       <!--赞-->
    	  <div class="row">
            <div class="col-lg-6">
                <img src="https://xiazemin.github.io/MyBlog/img/webwxgetmsgimg.jpeg"  height="400" width="auto" />
            </div>
          </div>

        <div class="row">
                <div class="col-md-12">
			<div id="disqus_thread"></div>

<div id="gitmentContainer"></div>
<link rel="stylesheet" href="/MyBlog/css/default.css">
<script src="/MyBlog/js/gitment.browser.js"></script>
<script type="text/javascript" src="/MyBlog/js/json2.js"></script>
<script>
var gitment = new Gitment({
    owner: 'xiazemin',
    repo: 'MyBlogComment',
    oauth: {
        client_id: '981ba8c916c262631ea0',
        client_secret: 'a52260ef92de69011ccd1cf355b973ef11d6da0e',
    },
});

var MyGitmentContainer=gitment.render('gitmentContainer');
window.setTimeout(MyGitMentBtnclick,1000); 
//document.ready(function(){ 
//window.onload=function(){}

function MyGitMentBtnclick(){
//var MyGitmentContainer=document.getElementById('gitmentContainer');
	var ele=[],all=MyGitmentContainer.getElementsByTagName("*");
	for(var i=0;i<all.length;i++){
	  if(all[i].className=='gitment-comments-init-btn'){
		MyGitMentBtn=all[i];
		console.log(MyGitMentBtn);
		MyGitMentBtn.click();
	  }
	}
}

</script>



			<!--script>
			/**
			* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
			* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
			*/
			/*
			var disqus_config = function () {
			this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
			this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
			};
			*/
			(function() { // DON'T EDIT BELOW THIS LINE
			var d = document, s = d.createElement('script');

			s.src = '//airrayagroup.disqus.com/embed.js';

			s.setAttribute('data-timestamp', +new Date());
			(d.head || d.body).appendChild(s);
			})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
			<script id="dsq-count-scr" src="//airrayagroup.disqus.com/count.js" async></script-->
          </div>
       </div>

</div>
<hr>
     <footer>
        <div class="container">
             <a href="/MyBlog/" style="color: green; font-size: 2em; font-family: 'Schoolbell', cursive;">首页</a>
            <div class="row">
                <div class="col-lg-6">
                    <p>Copyright &copy; 2017 465474307@qq.com <p>
                </div>
                <div class="col-lg-6">
                    <p style="float: right;">Jekyll theme by <a href="https://github.com/xiazemin/">夏泽民</a></p>
                </div>
            </div>
        </div>
    </footer>
	
    <!-- jQuery -->
    <script src="/MyBlog/js/jquery-1.12.0.min.js"></script>
    <script src="/MyBlog/js/jquery-migrate-1.2.1.min.js"></script>

    <!-- Latest compiled and minified JavaScript -->
    <script src="/MyBlog/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
        <!-- Menu Toggle Script -->
    <script>
    $("#menu-toggle").click(function(e) {
        e.preventDefault();
        $("#wrapper").toggleClass("toggled");
    });
    </script>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"6","bdPos":"right","bdTop":"100"},"image":{"viewList":["qzone","tsina","tqq","renren","weixin"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/MyBlog/shareapi/js/share.js?v=89860593.js?'];</script>


<!-- 2d  -->
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.0.min.js"></script>
<script type="text/javascript" charset="utf-8"  src="/MyBlog/js/L2Dwidget.min.js"></script>
<script type="text/javascript">
 setTimeout(()=> {
/*L2Dwidget.init({"display": {
        "superSample": 2,
        "width": 200,
        "height": 400,
             "position": "right",
                 "hOffset": 0,
        "vOffset": 0
          }
     });
*/
 L2Dwidget
        .on('*', (name) => {
          console.log('%c EVENT ' + '%c -> ' + name, 'background: #222; color: yellow', 'background: #fff; color: #000')
        })
        .init({
          dialog: {
            // 开启对话框
            enable: true,
            script: {
              // 每空闲 10 秒钟，显示一条一言
              'every idle 10s': '$hitokoto$',
              // 当触摸到星星图案
              'hover .star': '星星在天上而你在我心里 (*/ω＼*)',
              // 当触摸到角色身体
              'tap body': '哎呀！别碰我！',
              // 当触摸到角色头部
              'tap face': '人家已经不是小孩子了！'
            }
          }
        });

})
</script>



    <!--html xmlns:wb="http://open.weibo.com/wb">
    <script src="http://tjs.sjs.sinajs.cn/open/api/js/wb.js" type="text/javascript" charset="utf-8"></script>
    <wb:follow-button uid="2165491993" type="red_1" width="67" height="24" ></wb:follow-button-->

      <!--本文来自-->
     <script type="text/javascript">
      /* 仅IE
     document.body.oncopy = function(){
        setTimeout( 
            function () { 
        var text =window.clipboardData.getData("text"); 
        if (text) { 
            text = text + "/r/n本篇文章来源于 xiazemin 的 泽民博客|https://xiazemin.github.io/MyBlog/index.html 原文链接："+location.href; clipboardData.setData("text", text); 
          }
       },
     100 )
    }
     */
     //绑定在了body上，也可以绑定在其他可用元素行，但是不是所有元素都支持copy和past事件。

     /*
$(document.body).bind({
    copy: function(event) {//copy事件
        //var cpTxt = "复制的数据";
        var clipboardData = window.clipboardData; //for IE
        if (!clipboardData) { // for chrome
            clipboardData = event.originalEvent.clipboardData;
        }

        if (event.clipboardData != null/false/undefined) { //ignore the incorrectness of the truncation
        clipboarddata = event.clipboardData;
        } else if (window.clipboardData != null/false/undefined) {
         clipboarddata = window.clipboardData;
        } else { //default to the last option even if it is null/false/undefined
         clipboarddata = event.originalEvent.clipboardData;
        }

        //e.clipboardData.getData('text');//可以获取用户选中复制的数据
        //clipboardData.setData('Text', cpTxt);
        alert(clipboarddata.getData('text'));
        //$('#message').text('Copy Data : ' + cpTxt);
        return false;//否则设不生效
    },paste: function(e) {//paste事件
        var eve = e.originalEvent
        var cp = eve.clipboardData;
        var data = null;
        var clipboardData = window.clipboardData; // IE
        if (!clipboardData) { //chrome
            clipboardData = e.originalEvent.clipboardData
        }
        data = clipboardData.getData('Text');
        //$('#message').html(data);
    }
});     
*/
function addLink() {
    var body_element = document.getElementsByTagName('body')[0];
    var selection;
    selection = window.getSelection();
    var pagelink = "<br /><br />本文来源：xiazemin 的 泽民博客 <a href='"+document.location.href+"'>"+document.location.href+"</a>";
//+document.location.href+当前页面链接
    var copy_text = selection + pagelink;
    console.log(copy_text);
    var new_div = document.createElement('div');
    new_div.style.left='-99999px';
    new_div.style.position='absolute';
    body_element.appendChild(new_div );
    new_div.innerHTML = copy_text ;
    selection.selectAllChildren(new_div );
    window.setTimeout(function() {
        body_element.removeChild(new_div );
    },0);
}
document.oncopy = addLink;
     </script>
    <!--本文来自-->

</div>
  </body>

</html>